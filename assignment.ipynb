{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "4542362d-c53a-42f3-a3d8-570f1a8f3e0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TM10007_ML_g9' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!git clone https://github.com/Doesjka/TM10007_ML_g9.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "iq6XRc6xuYcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn import decomposition\n",
        "from sklearn import metrics\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils.fixes import loguniform\n",
        "from sklearn.metrics import make_scorer, accuracy_score, recall_score\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import randint\n"
      ],
      "metadata": {
        "id": "ZGpTRjZRudnE"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define functions"
      ],
      "metadata": {
        "id": "4Eqq7xOFueaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate 3 plots: the test and training learning curve, the training\n",
        "    samples vs fit times curve, the fit times vs score curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    axes : array of 3 axes, optional (default=None)\n",
        "        Axes to use for plotting the curves.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "\n",
        "    axes.set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes.set_ylim(*ylim)\n",
        "    axes.set_xlabel(\"Training examples\")\n",
        "    axes.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores  = \\\n",
        "        model_selection.learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes.grid()\n",
        "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    return plt\n",
        "\n",
        "def custom_score(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred, average='macro')\n",
        "    score = 2 * accuracy * recall / (accuracy + recall)\n",
        "    return score"
      ],
      "metadata": {
        "id": "NJtv5_0TuhEz"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEUJUe8plrxC"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "f0c37a67-827a-4af8-ed7e-4a0009fb9f66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of features: 494\n",
            "The number of samples: 115\n",
            "ID\n",
            "Lipo-001_0    liposarcoma\n",
            "Lipo-002_0    liposarcoma\n",
            "Lipo-003_0         lipoma\n",
            "Lipo-004_0    liposarcoma\n",
            "Lipo-005_0         lipoma\n",
            "Lipo-006_0         lipoma\n",
            "Lipo-007_0         lipoma\n",
            "Lipo-008_0         lipoma\n",
            "Lipo-009_0    liposarcoma\n",
            "Lipo-010_0         lipoma\n",
            "Lipo-011_0         lipoma\n",
            "Lipo-012_0    liposarcoma\n",
            "Lipo-013_0    liposarcoma\n",
            "Lipo-014_0         lipoma\n",
            "Lipo-015_0    liposarcoma\n",
            "Lipo-016_0    liposarcoma\n",
            "Lipo-017_0         lipoma\n",
            "Lipo-018_0         lipoma\n",
            "Lipo-019_0         lipoma\n",
            "Lipo-020_0    liposarcoma\n",
            "Lipo-021_0         lipoma\n",
            "Lipo-022_0    liposarcoma\n",
            "Lipo-023_0         lipoma\n",
            "Lipo-024_0    liposarcoma\n",
            "Lipo-025_0         lipoma\n",
            "Lipo-026_0    liposarcoma\n",
            "Lipo-027_0    liposarcoma\n",
            "Lipo-028_0    liposarcoma\n",
            "Lipo-029_0         lipoma\n",
            "Lipo-030_0    liposarcoma\n",
            "Lipo-031_0    liposarcoma\n",
            "Lipo-032_0         lipoma\n",
            "Lipo-033_0         lipoma\n",
            "Lipo-034_0         lipoma\n",
            "Lipo-035_0         lipoma\n",
            "Lipo-036_0         lipoma\n",
            "Lipo-037_0         lipoma\n",
            "Lipo-038_0    liposarcoma\n",
            "Lipo-039_0         lipoma\n",
            "Lipo-040_0    liposarcoma\n",
            "Lipo-041_0         lipoma\n",
            "Lipo-042_0    liposarcoma\n",
            "Lipo-043_0    liposarcoma\n",
            "Lipo-044_0    liposarcoma\n",
            "Lipo-045_0    liposarcoma\n",
            "Lipo-046_0    liposarcoma\n",
            "Lipo-047_0         lipoma\n",
            "Lipo-048_0    liposarcoma\n",
            "Lipo-049_0    liposarcoma\n",
            "Lipo-050_0    liposarcoma\n",
            "Lipo-051_0    liposarcoma\n",
            "Lipo-052_0         lipoma\n",
            "Lipo-053_0    liposarcoma\n",
            "Lipo-054_0    liposarcoma\n",
            "Lipo-055_0         lipoma\n",
            "Lipo-056_0         lipoma\n",
            "Lipo-057_0         lipoma\n",
            "Lipo-058_0    liposarcoma\n",
            "Lipo-059_0    liposarcoma\n",
            "Lipo-060_0    liposarcoma\n",
            "Lipo-061_0         lipoma\n",
            "Lipo-062_0         lipoma\n",
            "Lipo-063_0    liposarcoma\n",
            "Lipo-064_0    liposarcoma\n",
            "Lipo-065_0         lipoma\n",
            "Lipo-066_0         lipoma\n",
            "Lipo-067_0         lipoma\n",
            "Lipo-068_0    liposarcoma\n",
            "Lipo-069_0    liposarcoma\n",
            "Lipo-070_0    liposarcoma\n",
            "Lipo-071_0         lipoma\n",
            "Lipo-072_0    liposarcoma\n",
            "Lipo-073_0    liposarcoma\n",
            "Lipo-074_0    liposarcoma\n",
            "Lipo-075_0    liposarcoma\n",
            "Lipo-076_0         lipoma\n",
            "Lipo-077_0         lipoma\n",
            "Lipo-078_0    liposarcoma\n",
            "Lipo-079_0    liposarcoma\n",
            "Lipo-080_0         lipoma\n",
            "Lipo-081_0         lipoma\n",
            "Lipo-082_0         lipoma\n",
            "Lipo-083_0    liposarcoma\n",
            "Lipo-084_0         lipoma\n",
            "Lipo-085_0         lipoma\n",
            "Lipo-086_0    liposarcoma\n",
            "Lipo-087_0    liposarcoma\n",
            "Lipo-088_0    liposarcoma\n",
            "Lipo-089_0    liposarcoma\n",
            "Lipo-090_0         lipoma\n",
            "Lipo-091_0    liposarcoma\n",
            "Lipo-092_0         lipoma\n",
            "Lipo-093_0         lipoma\n",
            "Lipo-094_0         lipoma\n",
            "Lipo-095_0         lipoma\n",
            "Lipo-096_0         lipoma\n",
            "Lipo-097_0         lipoma\n",
            "Lipo-098_0         lipoma\n",
            "Lipo-099_0    liposarcoma\n",
            "Lipo-100_0    liposarcoma\n",
            "Lipo-101_0         lipoma\n",
            "Lipo-102_0         lipoma\n",
            "Lipo-103_0    liposarcoma\n",
            "Lipo-104_0         lipoma\n",
            "Lipo-105_0    liposarcoma\n",
            "Lipo-106_0    liposarcoma\n",
            "Lipo-107_0         lipoma\n",
            "Lipo-108_0    liposarcoma\n",
            "Lipo-109_0         lipoma\n",
            "Lipo-110_0         lipoma\n",
            "Lipo-111_0         lipoma\n",
            "Lipo-112_0    liposarcoma\n",
            "Lipo-113_0    liposarcoma\n",
            "Lipo-114_0         lipoma\n",
            "Lipo-115_0    liposarcoma\n",
            "Name: label, dtype: object\n",
            "Of these samples 58 are liposarcomas. That is 50 percent.\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/TM10007_ML_g9/worclipo/Lipo_radiomicFeatures.csv', index_col=0)\n",
        "print(f'The number of features: {len(data.columns)}')\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "data_punten = len(data.index) * len(data.columns)\n",
        "print(data['label'])\n",
        "ls = (data['label'] == 'liposarcoma').sum()\n",
        "\n",
        "print(f'Of these samples {ls} are liposarcomas. That is {round(ls/len(data.index)*100)} percent.')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data in train and test set\n"
      ],
      "metadata": {
        "id": "LHslq_ZZZbW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['label']\n",
        "\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "y = lb.fit_transform(y)\n",
        "y = y.flatten()\n",
        "\n",
        "X = data.drop('label', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "zero_variance = []"
      ],
      "metadata": {
        "id": "P8f1SNKeZaB7"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normaal verdeling en Variantie"
      ],
      "metadata": {
        "id": "L6CG70dYXbs-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Normaal verdeling\n",
        "Hieronder berekenen we hoe veel van de features normaal verdeeld zijn"
      ],
      "metadata": {
        "id": "BGxgrG6RXe4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aantal_normaal = 0\n",
        "\n",
        "for column in X_train.columns:\n",
        "    result = stats.shapiro(X_train[column])\n",
        "    # print(result.pvalue)\n",
        "    normaal = result.pvalue > 0.05\n",
        "    aantal_normaal += normaal\n",
        "    \n",
        "print(aantal_normaal, \" features zijn normaal verdeeld.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU5RKf7NXh0a",
        "outputId": "f73db192-138f-40a8-fd33-95b7b32a4d3b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "88  features zijn normaal verdeeld.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/scipy/stats/_morestats.py:1813: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
            "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variantie"
      ],
      "metadata": {
        "id": "BKsVP91EXh_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variantie = X_train.var(axis=0)\n",
        "variantie = variantie.sort_values()\n",
        "\n",
        "# Haal features met variantie van 0 eruit, want die zeggen dus helemaal niks\n",
        "zero_variance = variantie.keys()[variantie==0]\n",
        "X_train = X_train.drop(zero_variance, axis=1)\n",
        "print(f\"{len(zero_variance)} features have a variance of zero. These features are deleted.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i358P9yoXlkj",
        "outputId": "84c64430-7ef7-4e34-bc50-791f0ac22efa"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21 features have a variance of zero. These features are deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling missing data "
      ],
      "metadata": {
        "id": "gJLsBPlTZwAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Throwing out features\n",
        "All features that exist of at least 50% zeros are deleted from the data. "
      ],
      "metadata": {
        "id": "3MCSfSwrlshM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = (X_train == 0).sum()\n",
        "threshold = 0.5 * len(y_train)\n",
        "print('Threshold = ', threshold)\n",
        "feature_del = zeros[zeros > threshold]\n",
        "\n",
        "X_train = X_train.drop(columns=feature_del.index)\n",
        "print(f'For {len(data.columns)-len(X_train.columns)-len(zero_variance)} features the data consisted of more than 50% zeros. These features are deleted.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWcI7Y3g7eDk",
        "outputId": "6d23cc5f-dc6c-432c-9e2b-949eeeca6f06"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  43.0\n",
            "For 11 features the data consisted of more than 50% zeros. These features are deleted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "more_zeros = (X_train == 0).sum()\n",
        "columns_zeros = more_zeros[more_zeros > 0].index\n",
        "print(f'Of the remaining features, {len(columns_zeros)} features have at least one zero')\n",
        "print(f'There is a total of {more_zeros.sum()} zeros left in the data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuoOrHuMAsFY",
        "outputId": "3b8ef102-2aeb-4042-eae6-e94609fe508f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of the remaining features, 10 features have at least one zero\n",
            "There is a total of 44 zeros left in the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate number of missing values per sample"
      ],
      "metadata": {
        "id": "pkM1c0vkq1YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_r = (X_train == 0).sum(axis=1)\n",
        "threshold = 0.005 * X_train.size / len(y_train)\n",
        "print('Threshold = ', threshold)\n",
        "feature_del = zeros_r[zeros_r > threshold]\n",
        "print(feature_del)"
      ],
      "metadata": {
        "id": "4gHFgkGMm3Nm",
        "outputId": "8fe25bdb-52d7-4112-eb45-1133beef5660",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  2.31\n",
            "ID\n",
            "Lipo-090_0    5\n",
            "Lipo-095_0    3\n",
            "Lipo-076_0    3\n",
            "Lipo-003_0    3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filling remaining zeros\n",
        "All remaining zeros are replaced by the median of that feature. "
      ],
      "metadata": {
        "id": "KwXkbuDYqhoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mean = X_train\n",
        "X_train_median = X_train\n",
        "\n",
        "print(X_train[columns_zeros])\n",
        "\n",
        "for column in columns_zeros[:]:\n",
        "    print('Kolom: ', column)\n",
        "    column_mean = X_train.loc[X_train[column]!=0, column].mean()\n",
        "    column_median = X_train.loc[X_train[column]!=0, column].median()\n",
        "    # print('mean = ', column_mean)\n",
        "    # print('median = ', column_median)\n",
        "\n",
        "    # verschil2_percolumn = column_mean - column_median\n",
        "    # print('Verschil tussen mean en median = ',verschil2_percolumn)\n",
        "\n",
        "    # print('p-waarde normaalverdeling = ', stats.shapiro(X_train.loc[X_train[column]!=0, column]).pvalue)\n",
        "    # print(' ')\n",
        "\n",
        "    X_train_mean[column].replace(0, column_mean)\n",
        "    X_train_median[column].replace(0, column_median)\n",
        "\n",
        "\n",
        "verschil = abs(X_train_mean - X_train_median)\n",
        "# print('Totaal verschil = ', verschil.sum().sum())\n",
        "\n",
        "# We gaan voor de median\n",
        "X_train = X_train_median"
      ],
      "metadata": {
        "id": "EQudKLJth0sz",
        "outputId": "ecccb2ff-750c-4eb4-a6c7-14363d0e6748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            PREDICT_original_sf_area_min_2.5D  \\\n",
            "ID                                              \n",
            "Lipo-012_0                         183.736610   \n",
            "Lipo-073_0                         185.128390   \n",
            "Lipo-030_0                        1487.016678   \n",
            "Lipo-042_0                          19.850316   \n",
            "Lipo-100_0                         273.641968   \n",
            "Lipo-008_0                         243.347168   \n",
            "Lipo-034_0                        2148.103396   \n",
            "Lipo-085_0                          53.412599   \n",
            "Lipo-011_0                         109.910965   \n",
            "Lipo-023_0                         115.013026   \n",
            "Lipo-105_0                         129.150391   \n",
            "Lipo-109_0                          54.355469   \n",
            "Lipo-086_0                         558.160400   \n",
            "Lipo-106_0                        1255.136481   \n",
            "Lipo-080_0                         559.153608   \n",
            "Lipo-107_0                          70.339765   \n",
            "Lipo-066_0                        1060.228935   \n",
            "Lipo-044_0                         300.091553   \n",
            "Lipo-053_0                         229.762507   \n",
            "Lipo-031_0                         292.602055   \n",
            "Lipo-022_0                         798.532731   \n",
            "Lipo-001_0                          88.247681   \n",
            "Lipo-059_0                           1.977961   \n",
            "Lipo-072_0                         391.597552   \n",
            "Lipo-027_0                         860.546875   \n",
            "Lipo-039_0                          91.696777   \n",
            "Lipo-032_0                         165.798603   \n",
            "Lipo-043_0                        1392.500000   \n",
            "Lipo-070_0                         188.219261   \n",
            "Lipo-097_0                          61.468506   \n",
            "Lipo-054_0                         121.774664   \n",
            "Lipo-079_0                         718.880005   \n",
            "Lipo-036_0                           0.000000   \n",
            "Lipo-064_0                         513.407367   \n",
            "Lipo-090_0                          44.944336   \n",
            "Lipo-111_0                         925.540924   \n",
            "Lipo-010_0                          99.683594   \n",
            "Lipo-040_0                          50.676132   \n",
            "Lipo-098_0                         142.670501   \n",
            "Lipo-050_0                         199.813843   \n",
            "Lipo-004_0                        1593.017578   \n",
            "Lipo-060_0                          23.676553   \n",
            "Lipo-101_0                          64.142521   \n",
            "Lipo-071_0                          70.648193   \n",
            "Lipo-084_0                         183.833344   \n",
            "Lipo-048_0                         108.046057   \n",
            "Lipo-108_0                        1141.259766   \n",
            "Lipo-026_0                         166.354370   \n",
            "Lipo-112_0                           5.568745   \n",
            "Lipo-046_0                        1897.781181   \n",
            "Lipo-110_0                         632.500000   \n",
            "Lipo-025_0                         396.506104   \n",
            "Lipo-058_0                         247.851562   \n",
            "Lipo-063_0                         132.107422   \n",
            "Lipo-103_0                        3119.343282   \n",
            "Lipo-005_0                          40.647463   \n",
            "Lipo-055_0                         349.121067   \n",
            "Lipo-024_0                          91.865301   \n",
            "Lipo-093_0                          80.017298   \n",
            "Lipo-115_0                         465.791193   \n",
            "Lipo-094_0                         317.215092   \n",
            "Lipo-018_0                        1149.401665   \n",
            "Lipo-020_0                           0.000000   \n",
            "Lipo-017_0                         189.727442   \n",
            "Lipo-095_0                         649.876905   \n",
            "Lipo-033_0                        2093.966183   \n",
            "Lipo-056_0                         409.648895   \n",
            "Lipo-076_0                         114.154816   \n",
            "Lipo-003_0                         413.118512   \n",
            "Lipo-065_0                         724.726868   \n",
            "Lipo-087_0                          27.925873   \n",
            "Lipo-075_0                         320.818179   \n",
            "Lipo-102_0                         174.186859   \n",
            "Lipo-113_0                        1010.742188   \n",
            "Lipo-062_0                          30.388891   \n",
            "Lipo-045_0                         200.976573   \n",
            "Lipo-081_0                         112.197876   \n",
            "Lipo-051_0                         268.000335   \n",
            "Lipo-021_0                          79.169922   \n",
            "Lipo-067_0                          87.580843   \n",
            "Lipo-007_0                        1406.861328   \n",
            "Lipo-091_0                         556.945801   \n",
            "Lipo-049_0                          30.429077   \n",
            "Lipo-057_0                         135.255432   \n",
            "Lipo-052_0                         296.417999   \n",
            "Lipo-006_0                         581.138611   \n",
            "\n",
            "            PREDICT_original_tf_LBP_quartile_range_R8_P24  \\\n",
            "ID                                                          \n",
            "Lipo-012_0                                            3.0   \n",
            "Lipo-073_0                                           11.0   \n",
            "Lipo-030_0                                            3.0   \n",
            "Lipo-042_0                                            2.0   \n",
            "Lipo-100_0                                           13.0   \n",
            "Lipo-008_0                                            2.0   \n",
            "Lipo-034_0                                           11.0   \n",
            "Lipo-085_0                                           18.0   \n",
            "Lipo-011_0                                           12.0   \n",
            "Lipo-023_0                                            7.0   \n",
            "Lipo-105_0                                           12.0   \n",
            "Lipo-109_0                                            7.0   \n",
            "Lipo-086_0                                            7.0   \n",
            "Lipo-106_0                                           13.0   \n",
            "Lipo-080_0                                           13.0   \n",
            "Lipo-107_0                                            6.0   \n",
            "Lipo-066_0                                            3.0   \n",
            "Lipo-044_0                                            7.0   \n",
            "Lipo-053_0                                           13.0   \n",
            "Lipo-031_0                                            3.0   \n",
            "Lipo-022_0                                            1.0   \n",
            "Lipo-001_0                                           14.0   \n",
            "Lipo-059_0                                            6.0   \n",
            "Lipo-072_0                                            4.0   \n",
            "Lipo-027_0                                           13.0   \n",
            "Lipo-039_0                                           10.0   \n",
            "Lipo-032_0                                            6.0   \n",
            "Lipo-043_0                                           13.0   \n",
            "Lipo-070_0                                           15.0   \n",
            "Lipo-097_0                                           13.0   \n",
            "Lipo-054_0                                            1.0   \n",
            "Lipo-079_0                                           10.0   \n",
            "Lipo-036_0                                           12.0   \n",
            "Lipo-064_0                                            2.0   \n",
            "Lipo-090_0                                           15.0   \n",
            "Lipo-111_0                                           12.0   \n",
            "Lipo-010_0                                           13.0   \n",
            "Lipo-040_0                                            4.0   \n",
            "Lipo-098_0                                           14.0   \n",
            "Lipo-050_0                                           16.0   \n",
            "Lipo-004_0                                            2.0   \n",
            "Lipo-060_0                                            2.0   \n",
            "Lipo-101_0                                            0.0   \n",
            "Lipo-071_0                                            6.0   \n",
            "Lipo-084_0                                            7.0   \n",
            "Lipo-048_0                                           14.0   \n",
            "Lipo-108_0                                           14.0   \n",
            "Lipo-026_0                                            7.0   \n",
            "Lipo-112_0                                           12.0   \n",
            "Lipo-046_0                                           13.0   \n",
            "Lipo-110_0                                            0.0   \n",
            "Lipo-025_0                                            3.0   \n",
            "Lipo-058_0                                            1.0   \n",
            "Lipo-063_0                                           12.0   \n",
            "Lipo-103_0                                           11.0   \n",
            "Lipo-005_0                                            7.0   \n",
            "Lipo-055_0                                           14.0   \n",
            "Lipo-024_0                                            7.0   \n",
            "Lipo-093_0                                           16.0   \n",
            "Lipo-115_0                                           13.0   \n",
            "Lipo-094_0                                            5.0   \n",
            "Lipo-018_0                                           12.0   \n",
            "Lipo-020_0                                           13.0   \n",
            "Lipo-017_0                                           13.0   \n",
            "Lipo-095_0                                           13.0   \n",
            "Lipo-033_0                                            7.0   \n",
            "Lipo-056_0                                            0.0   \n",
            "Lipo-076_0                                           13.0   \n",
            "Lipo-003_0                                           13.0   \n",
            "Lipo-065_0                                           15.0   \n",
            "Lipo-087_0                                           13.0   \n",
            "Lipo-075_0                                            5.0   \n",
            "Lipo-102_0                                            9.0   \n",
            "Lipo-113_0                                           13.0   \n",
            "Lipo-062_0                                           14.0   \n",
            "Lipo-045_0                                            9.0   \n",
            "Lipo-081_0                                           14.0   \n",
            "Lipo-051_0                                            6.0   \n",
            "Lipo-021_0                                            2.0   \n",
            "Lipo-067_0                                            7.0   \n",
            "Lipo-007_0                                            1.0   \n",
            "Lipo-091_0                                           15.0   \n",
            "Lipo-049_0                                            7.0   \n",
            "Lipo-057_0                                           14.0   \n",
            "Lipo-052_0                                            4.0   \n",
            "Lipo-006_0                                           14.0   \n",
            "\n",
            "            PREDICT_original_vf_Frangi_full_quartile_range_SR(1.0, 10.0)_SS2.0  \\\n",
            "ID                                                                               \n",
            "Lipo-012_0                                       2.951306e-10                    \n",
            "Lipo-073_0                                       7.264154e-11                    \n",
            "Lipo-030_0                                       4.592091e-10                    \n",
            "Lipo-042_0                                       4.174470e-10                    \n",
            "Lipo-100_0                                       1.517338e-09                    \n",
            "Lipo-008_0                                       9.087688e-06                    \n",
            "Lipo-034_0                                       5.391448e-10                    \n",
            "Lipo-085_0                                       2.414730e-13                    \n",
            "Lipo-011_0                                       7.681949e-10                    \n",
            "Lipo-023_0                                       1.122594e-10                    \n",
            "Lipo-105_0                                       3.771574e-11                    \n",
            "Lipo-109_0                                       7.912182e-10                    \n",
            "Lipo-086_0                                       6.722079e-11                    \n",
            "Lipo-106_0                                       3.158044e-13                    \n",
            "Lipo-080_0                                       7.570978e-10                    \n",
            "Lipo-107_0                                       2.509574e-10                    \n",
            "Lipo-066_0                                       2.064063e-08                    \n",
            "Lipo-044_0                                       7.879899e-10                    \n",
            "Lipo-053_0                                       6.511409e-10                    \n",
            "Lipo-031_0                                       8.158167e-10                    \n",
            "Lipo-022_0                                       2.345716e-10                    \n",
            "Lipo-001_0                                       3.036308e-10                    \n",
            "Lipo-059_0                                       1.583436e-10                    \n",
            "Lipo-072_0                                       9.154013e-11                    \n",
            "Lipo-027_0                                       4.945373e-10                    \n",
            "Lipo-039_0                                       1.940291e-10                    \n",
            "Lipo-032_0                                       3.264208e-08                    \n",
            "Lipo-043_0                                       1.306921e-09                    \n",
            "Lipo-070_0                                       5.099805e-10                    \n",
            "Lipo-097_0                                       4.482175e-10                    \n",
            "Lipo-054_0                                       1.811530e-10                    \n",
            "Lipo-079_0                                       5.080458e-10                    \n",
            "Lipo-036_0                                       4.496049e-10                    \n",
            "Lipo-064_0                                       5.438279e-10                    \n",
            "Lipo-090_0                                       0.000000e+00                    \n",
            "Lipo-111_0                                       1.323804e-10                    \n",
            "Lipo-010_0                                       1.127354e-09                    \n",
            "Lipo-040_0                                       7.193456e-10                    \n",
            "Lipo-098_0                                       4.631859e-10                    \n",
            "Lipo-050_0                                       1.048793e-09                    \n",
            "Lipo-004_0                                       9.021890e-11                    \n",
            "Lipo-060_0                                       5.487165e-10                    \n",
            "Lipo-101_0                                       1.043641e-09                    \n",
            "Lipo-071_0                                       2.986291e-10                    \n",
            "Lipo-084_0                                       2.549203e-10                    \n",
            "Lipo-048_0                                       9.632324e-10                    \n",
            "Lipo-108_0                                       4.663410e-10                    \n",
            "Lipo-026_0                                       6.202661e-10                    \n",
            "Lipo-112_0                                       1.988157e-10                    \n",
            "Lipo-046_0                                       8.428386e-11                    \n",
            "Lipo-110_0                                       2.408744e-09                    \n",
            "Lipo-025_0                                       8.802498e-10                    \n",
            "Lipo-058_0                                       3.964630e-10                    \n",
            "Lipo-063_0                                       9.516702e-10                    \n",
            "Lipo-103_0                                       5.389165e-10                    \n",
            "Lipo-005_0                                       4.501969e-10                    \n",
            "Lipo-055_0                                       1.377551e-05                    \n",
            "Lipo-024_0                                       5.382325e-10                    \n",
            "Lipo-093_0                                       3.564739e-10                    \n",
            "Lipo-115_0                                       3.201268e-10                    \n",
            "Lipo-094_0                                       6.106639e-13                    \n",
            "Lipo-018_0                                       6.413405e-10                    \n",
            "Lipo-020_0                                       4.602205e-10                    \n",
            "Lipo-017_0                                       2.958314e-10                    \n",
            "Lipo-095_0                                       0.000000e+00                    \n",
            "Lipo-033_0                                       1.243129e-10                    \n",
            "Lipo-056_0                                       2.803915e-10                    \n",
            "Lipo-076_0                                       2.232340e-10                    \n",
            "Lipo-003_0                                       0.000000e+00                    \n",
            "Lipo-065_0                                       3.571169e-10                    \n",
            "Lipo-087_0                                       8.948190e-10                    \n",
            "Lipo-075_0                                       4.549988e-09                    \n",
            "Lipo-102_0                                       8.986840e-10                    \n",
            "Lipo-113_0                                       4.292348e-10                    \n",
            "Lipo-062_0                                       7.731359e-10                    \n",
            "Lipo-045_0                                       9.678740e-11                    \n",
            "Lipo-081_0                                       6.733101e-10                    \n",
            "Lipo-051_0                                       9.664854e-10                    \n",
            "Lipo-021_0                                       1.469184e-10                    \n",
            "Lipo-067_0                                       4.986553e-10                    \n",
            "Lipo-007_0                                       7.554602e-10                    \n",
            "Lipo-091_0                                       4.506532e-10                    \n",
            "Lipo-049_0                                       8.747005e-10                    \n",
            "Lipo-057_0                                       3.485883e-10                    \n",
            "Lipo-052_0                                       3.741907e-11                    \n",
            "Lipo-006_0                                       3.131032e-10                    \n",
            "\n",
            "            PREDICT_original_vf_Frangi_edge_quartile_range_SR(1.0, 10.0)_SS2.0  \\\n",
            "ID                                                                               \n",
            "Lipo-012_0                                       2.951306e-10                    \n",
            "Lipo-073_0                                       7.264154e-11                    \n",
            "Lipo-030_0                                       4.592091e-10                    \n",
            "Lipo-042_0                                       4.174470e-10                    \n",
            "Lipo-100_0                                       1.517338e-09                    \n",
            "Lipo-008_0                                       9.087688e-06                    \n",
            "Lipo-034_0                                       5.391448e-10                    \n",
            "Lipo-085_0                                       2.414730e-13                    \n",
            "Lipo-011_0                                       7.681949e-10                    \n",
            "Lipo-023_0                                       1.122594e-10                    \n",
            "Lipo-105_0                                       3.771574e-11                    \n",
            "Lipo-109_0                                       7.912182e-10                    \n",
            "Lipo-086_0                                       6.722079e-11                    \n",
            "Lipo-106_0                                       3.158044e-13                    \n",
            "Lipo-080_0                                       7.570978e-10                    \n",
            "Lipo-107_0                                       2.509574e-10                    \n",
            "Lipo-066_0                                       2.064063e-08                    \n",
            "Lipo-044_0                                       7.879899e-10                    \n",
            "Lipo-053_0                                       6.511409e-10                    \n",
            "Lipo-031_0                                       8.158167e-10                    \n",
            "Lipo-022_0                                       2.345716e-10                    \n",
            "Lipo-001_0                                       3.036308e-10                    \n",
            "Lipo-059_0                                       1.583436e-10                    \n",
            "Lipo-072_0                                       9.154013e-11                    \n",
            "Lipo-027_0                                       4.945373e-10                    \n",
            "Lipo-039_0                                       1.940291e-10                    \n",
            "Lipo-032_0                                       3.264208e-08                    \n",
            "Lipo-043_0                                       1.306921e-09                    \n",
            "Lipo-070_0                                       5.099805e-10                    \n",
            "Lipo-097_0                                       4.482175e-10                    \n",
            "Lipo-054_0                                       1.811530e-10                    \n",
            "Lipo-079_0                                       5.080458e-10                    \n",
            "Lipo-036_0                                       4.496049e-10                    \n",
            "Lipo-064_0                                       5.438279e-10                    \n",
            "Lipo-090_0                                       0.000000e+00                    \n",
            "Lipo-111_0                                       1.323804e-10                    \n",
            "Lipo-010_0                                       1.127354e-09                    \n",
            "Lipo-040_0                                       7.193456e-10                    \n",
            "Lipo-098_0                                       4.631859e-10                    \n",
            "Lipo-050_0                                       1.048793e-09                    \n",
            "Lipo-004_0                                       9.021890e-11                    \n",
            "Lipo-060_0                                       5.487165e-10                    \n",
            "Lipo-101_0                                       1.043641e-09                    \n",
            "Lipo-071_0                                       2.986291e-10                    \n",
            "Lipo-084_0                                       2.549203e-10                    \n",
            "Lipo-048_0                                       9.632324e-10                    \n",
            "Lipo-108_0                                       4.663410e-10                    \n",
            "Lipo-026_0                                       6.202661e-10                    \n",
            "Lipo-112_0                                       1.988157e-10                    \n",
            "Lipo-046_0                                       8.428386e-11                    \n",
            "Lipo-110_0                                       2.408744e-09                    \n",
            "Lipo-025_0                                       8.802498e-10                    \n",
            "Lipo-058_0                                       3.964630e-10                    \n",
            "Lipo-063_0                                       9.516702e-10                    \n",
            "Lipo-103_0                                       5.389165e-10                    \n",
            "Lipo-005_0                                       4.501969e-10                    \n",
            "Lipo-055_0                                       1.377551e-05                    \n",
            "Lipo-024_0                                       5.382325e-10                    \n",
            "Lipo-093_0                                       3.564739e-10                    \n",
            "Lipo-115_0                                       3.201268e-10                    \n",
            "Lipo-094_0                                       6.106639e-13                    \n",
            "Lipo-018_0                                       6.413405e-10                    \n",
            "Lipo-020_0                                       4.602205e-10                    \n",
            "Lipo-017_0                                       2.958314e-10                    \n",
            "Lipo-095_0                                       0.000000e+00                    \n",
            "Lipo-033_0                                       1.243129e-10                    \n",
            "Lipo-056_0                                       2.803915e-10                    \n",
            "Lipo-076_0                                       2.232340e-10                    \n",
            "Lipo-003_0                                       0.000000e+00                    \n",
            "Lipo-065_0                                       3.571169e-10                    \n",
            "Lipo-087_0                                       8.948190e-10                    \n",
            "Lipo-075_0                                       4.549988e-09                    \n",
            "Lipo-102_0                                       8.986840e-10                    \n",
            "Lipo-113_0                                       4.292348e-10                    \n",
            "Lipo-062_0                                       7.731359e-10                    \n",
            "Lipo-045_0                                       9.678740e-11                    \n",
            "Lipo-081_0                                       6.733101e-10                    \n",
            "Lipo-051_0                                       9.664854e-10                    \n",
            "Lipo-021_0                                       1.469184e-10                    \n",
            "Lipo-067_0                                       4.986553e-10                    \n",
            "Lipo-007_0                                       7.554602e-10                    \n",
            "Lipo-091_0                                       4.506532e-10                    \n",
            "Lipo-049_0                                       8.747005e-10                    \n",
            "Lipo-057_0                                       3.485883e-10                    \n",
            "Lipo-052_0                                       3.741907e-11                    \n",
            "Lipo-006_0                                       3.131032e-10                    \n",
            "\n",
            "            PREDICT_original_vf_Frangi_inner_quartile_range_SR(1.0, 10.0)_SS2.0  \\\n",
            "ID                                                                                \n",
            "Lipo-012_0                                       1.903265e-10                     \n",
            "Lipo-073_0                                       1.843291e-13                     \n",
            "Lipo-030_0                                       4.298072e-10                     \n",
            "Lipo-042_0                                       2.616916e-10                     \n",
            "Lipo-100_0                                       3.741505e-10                     \n",
            "Lipo-008_0                                       2.752074e-06                     \n",
            "Lipo-034_0                                       4.333570e-10                     \n",
            "Lipo-085_0                                       8.054124e-14                     \n",
            "Lipo-011_0                                       7.844320e-10                     \n",
            "Lipo-023_0                                       7.634936e-12                     \n",
            "Lipo-105_0                                       4.396575e-11                     \n",
            "Lipo-109_0                                       5.811671e-10                     \n",
            "Lipo-086_0                                       4.080318e-11                     \n",
            "Lipo-106_0                                       7.460360e-14                     \n",
            "Lipo-080_0                                       3.967055e-10                     \n",
            "Lipo-107_0                                       4.144374e-11                     \n",
            "Lipo-066_0                                       4.828631e-09                     \n",
            "Lipo-044_0                                       5.502245e-10                     \n",
            "Lipo-053_0                                       5.714453e-10                     \n",
            "Lipo-031_0                                       7.425098e-10                     \n",
            "Lipo-022_0                                       2.233010e-10                     \n",
            "Lipo-001_0                                       1.091229e-10                     \n",
            "Lipo-059_0                                       1.611116e-10                     \n",
            "Lipo-072_0                                       3.738569e-11                     \n",
            "Lipo-027_0                                       3.902852e-10                     \n",
            "Lipo-039_0                                       2.494774e-11                     \n",
            "Lipo-032_0                                       4.816914e-09                     \n",
            "Lipo-043_0                                       1.191417e-09                     \n",
            "Lipo-070_0                                       2.489941e-10                     \n",
            "Lipo-097_0                                       3.811822e-10                     \n",
            "Lipo-054_0                                       9.937685e-11                     \n",
            "Lipo-079_0                                       3.782610e-10                     \n",
            "Lipo-036_0                                       4.837005e-10                     \n",
            "Lipo-064_0                                       5.248572e-10                     \n",
            "Lipo-090_0                                       0.000000e+00                     \n",
            "Lipo-111_0                                       6.969640e-11                     \n",
            "Lipo-010_0                                       8.753866e-10                     \n",
            "Lipo-040_0                                       3.586982e-10                     \n",
            "Lipo-098_0                                       5.144719e-10                     \n",
            "Lipo-050_0                                       8.972520e-10                     \n",
            "Lipo-004_0                                       6.407486e-11                     \n",
            "Lipo-060_0                                       4.433455e-10                     \n",
            "Lipo-101_0                                       5.981397e-10                     \n",
            "Lipo-071_0                                       3.753568e-10                     \n",
            "Lipo-084_0                                       8.567671e-11                     \n",
            "Lipo-048_0                                       8.710175e-10                     \n",
            "Lipo-108_0                                       4.479629e-10                     \n",
            "Lipo-026_0                                       1.824669e-10                     \n",
            "Lipo-112_0                                       8.230441e-11                     \n",
            "Lipo-046_0                                       2.731006e-11                     \n",
            "Lipo-110_0                                       1.301536e-09                     \n",
            "Lipo-025_0                                       9.367678e-10                     \n",
            "Lipo-058_0                                       3.044889e-10                     \n",
            "Lipo-063_0                                       4.854719e-10                     \n",
            "Lipo-103_0                                       3.327281e-10                     \n",
            "Lipo-005_0                                       3.007746e-10                     \n",
            "Lipo-055_0                                       4.345543e-06                     \n",
            "Lipo-024_0                                       3.642459e-10                     \n",
            "Lipo-093_0                                       2.302801e-10                     \n",
            "Lipo-115_0                                       3.164663e-10                     \n",
            "Lipo-094_0                                       3.645387e-13                     \n",
            "Lipo-018_0                                       2.145890e-10                     \n",
            "Lipo-020_0                                       3.690297e-10                     \n",
            "Lipo-017_0                                       4.141502e-10                     \n",
            "Lipo-095_0                                       0.000000e+00                     \n",
            "Lipo-033_0                                       1.651096e-12                     \n",
            "Lipo-056_0                                       1.595913e-10                     \n",
            "Lipo-076_0                                       2.783637e-10                     \n",
            "Lipo-003_0                                       0.000000e+00                     \n",
            "Lipo-065_0                                       5.526455e-10                     \n",
            "Lipo-087_0                                       4.396726e-10                     \n",
            "Lipo-075_0                                       3.112345e-09                     \n",
            "Lipo-102_0                                       1.087615e-09                     \n",
            "Lipo-113_0                                       1.545639e-10                     \n",
            "Lipo-062_0                                       4.810002e-10                     \n",
            "Lipo-045_0                                       0.000000e+00                     \n",
            "Lipo-081_0                                       6.185548e-10                     \n",
            "Lipo-051_0                                       8.337814e-10                     \n",
            "Lipo-021_0                                       9.732013e-11                     \n",
            "Lipo-067_0                                       3.791433e-10                     \n",
            "Lipo-007_0                                       6.298023e-10                     \n",
            "Lipo-091_0                                       3.652658e-10                     \n",
            "Lipo-049_0                                       8.744914e-11                     \n",
            "Lipo-057_0                                       2.259944e-10                     \n",
            "Lipo-052_0                                       9.681863e-12                     \n",
            "Lipo-006_0                                       2.000707e-10                     \n",
            "\n",
            "            PREDICT_original_phasef_monogenic_min_WL3_N5  \\\n",
            "ID                                                         \n",
            "Lipo-012_0                                          3.00   \n",
            "Lipo-073_0                                          6.00   \n",
            "Lipo-030_0                                          4.00   \n",
            "Lipo-042_0                                          3.00   \n",
            "Lipo-100_0                                         10.00   \n",
            "Lipo-008_0                                          4.00   \n",
            "Lipo-034_0                                          4.00   \n",
            "Lipo-085_0                                          3.00   \n",
            "Lipo-011_0                                          3.00   \n",
            "Lipo-023_0                                          3.00   \n",
            "Lipo-105_0                                          1.00   \n",
            "Lipo-109_0                                          3.00   \n",
            "Lipo-086_0                                          3.00   \n",
            "Lipo-106_0                                          6.00   \n",
            "Lipo-080_0                                          0.00   \n",
            "Lipo-107_0                                          5.00   \n",
            "Lipo-066_0                                          4.00   \n",
            "Lipo-044_0                                          4.00   \n",
            "Lipo-053_0                                          4.00   \n",
            "Lipo-031_0                                          5.00   \n",
            "Lipo-022_0                                          3.00   \n",
            "Lipo-001_0                                          2.00   \n",
            "Lipo-059_0                                          3.00   \n",
            "Lipo-072_0                                          3.00   \n",
            "Lipo-027_0                                          3.00   \n",
            "Lipo-039_0                                          3.00   \n",
            "Lipo-032_0                                          2.00   \n",
            "Lipo-043_0                                          5.00   \n",
            "Lipo-070_0                                          3.00   \n",
            "Lipo-097_0                                          3.00   \n",
            "Lipo-054_0                                          3.00   \n",
            "Lipo-079_0                                          6.00   \n",
            "Lipo-036_0                                          5.00   \n",
            "Lipo-064_0                                          3.00   \n",
            "Lipo-090_0                                          2.00   \n",
            "Lipo-111_0                                          7.00   \n",
            "Lipo-010_0                                          3.00   \n",
            "Lipo-040_0                                          3.00   \n",
            "Lipo-098_0                                          1.00   \n",
            "Lipo-050_0                                          2.00   \n",
            "Lipo-004_0                                          4.00   \n",
            "Lipo-060_0                                          4.00   \n",
            "Lipo-101_0                                          2.00   \n",
            "Lipo-071_0                                          4.00   \n",
            "Lipo-084_0                                          4.00   \n",
            "Lipo-048_0                                          2.00   \n",
            "Lipo-108_0                                          5.00   \n",
            "Lipo-026_0                                          2.00   \n",
            "Lipo-112_0                                          2.00   \n",
            "Lipo-046_0                                          4.00   \n",
            "Lipo-110_0                                         18.00   \n",
            "Lipo-025_0                                          4.00   \n",
            "Lipo-058_0                                          4.00   \n",
            "Lipo-063_0                                          4.00   \n",
            "Lipo-103_0                                          4.00   \n",
            "Lipo-005_0                                          2.00   \n",
            "Lipo-055_0                                          2.00   \n",
            "Lipo-024_0                                          3.00   \n",
            "Lipo-093_0                                          2.76   \n",
            "Lipo-115_0                                          3.00   \n",
            "Lipo-094_0                                          3.00   \n",
            "Lipo-018_0                                          4.00   \n",
            "Lipo-020_0                                          3.00   \n",
            "Lipo-017_0                                          2.00   \n",
            "Lipo-095_0                                          3.00   \n",
            "Lipo-033_0                                          2.00   \n",
            "Lipo-056_0                                          6.00   \n",
            "Lipo-076_0                                          0.00   \n",
            "Lipo-003_0                                          4.00   \n",
            "Lipo-065_0                                         16.00   \n",
            "Lipo-087_0                                          7.00   \n",
            "Lipo-075_0                                          3.00   \n",
            "Lipo-102_0                                          7.00   \n",
            "Lipo-113_0                                          5.00   \n",
            "Lipo-062_0                                          4.00   \n",
            "Lipo-045_0                                          2.00   \n",
            "Lipo-081_0                                          3.00   \n",
            "Lipo-051_0                                          2.00   \n",
            "Lipo-021_0                                          3.00   \n",
            "Lipo-067_0                                          3.00   \n",
            "Lipo-007_0                                          3.00   \n",
            "Lipo-091_0                                          2.00   \n",
            "Lipo-049_0                                          5.00   \n",
            "Lipo-057_0                                          2.00   \n",
            "Lipo-052_0                                          3.00   \n",
            "Lipo-006_0                                          1.00   \n",
            "\n",
            "            PREDICT_original_phasef_monogenic_peak_WL3_N5  \\\n",
            "ID                                                          \n",
            "Lipo-012_0                                           0.00   \n",
            "Lipo-073_0                                          96.66   \n",
            "Lipo-030_0                                         146.78   \n",
            "Lipo-042_0                                          35.80   \n",
            "Lipo-100_0                                          96.66   \n",
            "Lipo-008_0                                         121.72   \n",
            "Lipo-034_0                                          60.86   \n",
            "Lipo-085_0                                          28.64   \n",
            "Lipo-011_0                                         153.94   \n",
            "Lipo-023_0                                           0.00   \n",
            "Lipo-105_0                                         175.42   \n",
            "Lipo-109_0                                          28.64   \n",
            "Lipo-086_0                                          71.60   \n",
            "Lipo-106_0                                          78.76   \n",
            "Lipo-080_0                                         175.42   \n",
            "Lipo-107_0                                          53.70   \n",
            "Lipo-066_0                                          85.92   \n",
            "Lipo-044_0                                          46.54   \n",
            "Lipo-053_0                                          28.64   \n",
            "Lipo-031_0                                          85.92   \n",
            "Lipo-022_0                                          35.80   \n",
            "Lipo-001_0                                         171.84   \n",
            "Lipo-059_0                                          21.48   \n",
            "Lipo-072_0                                         153.94   \n",
            "Lipo-027_0                                          85.92   \n",
            "Lipo-039_0                                          53.70   \n",
            "Lipo-032_0                                           3.58   \n",
            "Lipo-043_0                                          89.50   \n",
            "Lipo-070_0                                         128.88   \n",
            "Lipo-097_0                                         128.88   \n",
            "Lipo-054_0                                          21.48   \n",
            "Lipo-079_0                                          89.50   \n",
            "Lipo-036_0                                          64.44   \n",
            "Lipo-064_0                                          35.80   \n",
            "Lipo-090_0                                           0.00   \n",
            "Lipo-111_0                                          96.66   \n",
            "Lipo-010_0                                          35.80   \n",
            "Lipo-040_0                                          46.54   \n",
            "Lipo-098_0                                         171.84   \n",
            "Lipo-050_0                                         164.68   \n",
            "Lipo-004_0                                          89.50   \n",
            "Lipo-060_0                                          46.54   \n",
            "Lipo-101_0                                          10.74   \n",
            "Lipo-071_0                                         153.94   \n",
            "Lipo-084_0                                         121.72   \n",
            "Lipo-048_0                                          21.48   \n",
            "Lipo-108_0                                          85.92   \n",
            "Lipo-026_0                                          35.80   \n",
            "Lipo-112_0                                           3.58   \n",
            "Lipo-046_0                                          96.66   \n",
            "Lipo-110_0                                          89.50   \n",
            "Lipo-025_0                                         139.62   \n",
            "Lipo-058_0                                          35.80   \n",
            "Lipo-063_0                                          35.80   \n",
            "Lipo-103_0                                          96.66   \n",
            "Lipo-005_0                                         171.84   \n",
            "Lipo-055_0                                          17.90   \n",
            "Lipo-024_0                                         121.72   \n",
            "Lipo-093_0                                         157.52   \n",
            "Lipo-115_0                                         146.78   \n",
            "Lipo-094_0                                         164.68   \n",
            "Lipo-018_0                                          53.70   \n",
            "Lipo-020_0                                          85.92   \n",
            "Lipo-017_0                                         157.52   \n",
            "Lipo-095_0                                          71.60   \n",
            "Lipo-033_0                                         175.42   \n",
            "Lipo-056_0                                         128.88   \n",
            "Lipo-076_0                                           0.00   \n",
            "Lipo-003_0                                          35.80   \n",
            "Lipo-065_0                                          85.92   \n",
            "Lipo-087_0                                         110.98   \n",
            "Lipo-075_0                                           3.58   \n",
            "Lipo-102_0                                         103.82   \n",
            "Lipo-113_0                                          89.50   \n",
            "Lipo-062_0                                         103.82   \n",
            "Lipo-045_0                                         153.94   \n",
            "Lipo-081_0                                         146.78   \n",
            "Lipo-051_0                                           0.00   \n",
            "Lipo-021_0                                         157.52   \n",
            "Lipo-067_0                                          42.96   \n",
            "Lipo-007_0                                         157.52   \n",
            "Lipo-091_0                                         121.72   \n",
            "Lipo-049_0                                          53.70   \n",
            "Lipo-057_0                                         171.84   \n",
            "Lipo-052_0                                          10.74   \n",
            "Lipo-006_0                                           3.58   \n",
            "\n",
            "            PREDICT_original_phasef_monogenic_peak_position_WL3_N5  \\\n",
            "ID                                                                   \n",
            "Lipo-012_0                                                  0        \n",
            "Lipo-073_0                                                 27        \n",
            "Lipo-030_0                                                 41        \n",
            "Lipo-042_0                                                 10        \n",
            "Lipo-100_0                                                 27        \n",
            "Lipo-008_0                                                 34        \n",
            "Lipo-034_0                                                 17        \n",
            "Lipo-085_0                                                  8        \n",
            "Lipo-011_0                                                 43        \n",
            "Lipo-023_0                                                  0        \n",
            "Lipo-105_0                                                 49        \n",
            "Lipo-109_0                                                  8        \n",
            "Lipo-086_0                                                 20        \n",
            "Lipo-106_0                                                 22        \n",
            "Lipo-080_0                                                 49        \n",
            "Lipo-107_0                                                 15        \n",
            "Lipo-066_0                                                 24        \n",
            "Lipo-044_0                                                 13        \n",
            "Lipo-053_0                                                  8        \n",
            "Lipo-031_0                                                 24        \n",
            "Lipo-022_0                                                 10        \n",
            "Lipo-001_0                                                 48        \n",
            "Lipo-059_0                                                  6        \n",
            "Lipo-072_0                                                 43        \n",
            "Lipo-027_0                                                 24        \n",
            "Lipo-039_0                                                 15        \n",
            "Lipo-032_0                                                  1        \n",
            "Lipo-043_0                                                 25        \n",
            "Lipo-070_0                                                 36        \n",
            "Lipo-097_0                                                 36        \n",
            "Lipo-054_0                                                  6        \n",
            "Lipo-079_0                                                 25        \n",
            "Lipo-036_0                                                 18        \n",
            "Lipo-064_0                                                 10        \n",
            "Lipo-090_0                                                  0        \n",
            "Lipo-111_0                                                 27        \n",
            "Lipo-010_0                                                 10        \n",
            "Lipo-040_0                                                 13        \n",
            "Lipo-098_0                                                 48        \n",
            "Lipo-050_0                                                 46        \n",
            "Lipo-004_0                                                 25        \n",
            "Lipo-060_0                                                 13        \n",
            "Lipo-101_0                                                  3        \n",
            "Lipo-071_0                                                 43        \n",
            "Lipo-084_0                                                 34        \n",
            "Lipo-048_0                                                  6        \n",
            "Lipo-108_0                                                 24        \n",
            "Lipo-026_0                                                 10        \n",
            "Lipo-112_0                                                  1        \n",
            "Lipo-046_0                                                 27        \n",
            "Lipo-110_0                                                 25        \n",
            "Lipo-025_0                                                 39        \n",
            "Lipo-058_0                                                 10        \n",
            "Lipo-063_0                                                 10        \n",
            "Lipo-103_0                                                 27        \n",
            "Lipo-005_0                                                 48        \n",
            "Lipo-055_0                                                  5        \n",
            "Lipo-024_0                                                 34        \n",
            "Lipo-093_0                                                 44        \n",
            "Lipo-115_0                                                 41        \n",
            "Lipo-094_0                                                 46        \n",
            "Lipo-018_0                                                 15        \n",
            "Lipo-020_0                                                 24        \n",
            "Lipo-017_0                                                 44        \n",
            "Lipo-095_0                                                 20        \n",
            "Lipo-033_0                                                 49        \n",
            "Lipo-056_0                                                 36        \n",
            "Lipo-076_0                                                  0        \n",
            "Lipo-003_0                                                 10        \n",
            "Lipo-065_0                                                 24        \n",
            "Lipo-087_0                                                 31        \n",
            "Lipo-075_0                                                  1        \n",
            "Lipo-102_0                                                 29        \n",
            "Lipo-113_0                                                 25        \n",
            "Lipo-062_0                                                 29        \n",
            "Lipo-045_0                                                 43        \n",
            "Lipo-081_0                                                 41        \n",
            "Lipo-051_0                                                  0        \n",
            "Lipo-021_0                                                 44        \n",
            "Lipo-067_0                                                 12        \n",
            "Lipo-007_0                                                 44        \n",
            "Lipo-091_0                                                 34        \n",
            "Lipo-049_0                                                 15        \n",
            "Lipo-057_0                                                 48        \n",
            "Lipo-052_0                                                  3        \n",
            "Lipo-006_0                                                  1        \n",
            "\n",
            "            PREDICT_original_phasef_phasecong_quartile_range_WL3_N5  \\\n",
            "ID                                                                    \n",
            "Lipo-012_0                                           0.028873         \n",
            "Lipo-073_0                                           0.003799         \n",
            "Lipo-030_0                                           0.009115         \n",
            "Lipo-042_0                                           0.020983         \n",
            "Lipo-100_0                                           0.015316         \n",
            "Lipo-008_0                                           0.009533         \n",
            "Lipo-034_0                                           0.000000         \n",
            "Lipo-085_0                                           0.137505         \n",
            "Lipo-011_0                                           0.025314         \n",
            "Lipo-023_0                                           0.030800         \n",
            "Lipo-105_0                                           0.053477         \n",
            "Lipo-109_0                                           0.004672         \n",
            "Lipo-086_0                                           0.036358         \n",
            "Lipo-106_0                                           0.006977         \n",
            "Lipo-080_0                                           0.010385         \n",
            "Lipo-107_0                                           0.005025         \n",
            "Lipo-066_0                                           0.003828         \n",
            "Lipo-044_0                                           0.011208         \n",
            "Lipo-053_0                                           0.012302         \n",
            "Lipo-031_0                                           0.034289         \n",
            "Lipo-022_0                                           0.002576         \n",
            "Lipo-001_0                                           0.037968         \n",
            "Lipo-059_0                                           0.011853         \n",
            "Lipo-072_0                                           0.018494         \n",
            "Lipo-027_0                                           0.003297         \n",
            "Lipo-039_0                                           0.011959         \n",
            "Lipo-032_0                                           0.011955         \n",
            "Lipo-043_0                                           0.020217         \n",
            "Lipo-070_0                                           0.090021         \n",
            "Lipo-097_0                                           0.028307         \n",
            "Lipo-054_0                                           0.008265         \n",
            "Lipo-079_0                                           0.023099         \n",
            "Lipo-036_0                                           0.023714         \n",
            "Lipo-064_0                                           0.031938         \n",
            "Lipo-090_0                                           0.183769         \n",
            "Lipo-111_0                                           0.000409         \n",
            "Lipo-010_0                                           0.000000         \n",
            "Lipo-040_0                                           0.020123         \n",
            "Lipo-098_0                                           0.003786         \n",
            "Lipo-050_0                                           0.011297         \n",
            "Lipo-004_0                                           0.041175         \n",
            "Lipo-060_0                                           0.013629         \n",
            "Lipo-101_0                                           0.099179         \n",
            "Lipo-071_0                                           0.010776         \n",
            "Lipo-084_0                                           0.016613         \n",
            "Lipo-048_0                                           0.000000         \n",
            "Lipo-108_0                                           0.025202         \n",
            "Lipo-026_0                                           0.004269         \n",
            "Lipo-112_0                                           0.006707         \n",
            "Lipo-046_0                                           0.020196         \n",
            "Lipo-110_0                                           0.083250         \n",
            "Lipo-025_0                                           0.014488         \n",
            "Lipo-058_0                                           0.000000         \n",
            "Lipo-063_0                                           0.027426         \n",
            "Lipo-103_0                                           0.005541         \n",
            "Lipo-005_0                                           0.019277         \n",
            "Lipo-055_0                                           0.005244         \n",
            "Lipo-024_0                                           0.020491         \n",
            "Lipo-093_0                                           0.177411         \n",
            "Lipo-115_0                                           0.003660         \n",
            "Lipo-094_0                                           0.013328         \n",
            "Lipo-018_0                                           0.003660         \n",
            "Lipo-020_0                                           0.003986         \n",
            "Lipo-017_0                                           0.009059         \n",
            "Lipo-095_0                                           0.003699         \n",
            "Lipo-033_0                                           0.000000         \n",
            "Lipo-056_0                                           0.006816         \n",
            "Lipo-076_0                                           0.166006         \n",
            "Lipo-003_0                                           0.009936         \n",
            "Lipo-065_0                                           0.045057         \n",
            "Lipo-087_0                                           0.030519         \n",
            "Lipo-075_0                                           0.036775         \n",
            "Lipo-102_0                                           0.069104         \n",
            "Lipo-113_0                                           0.059569         \n",
            "Lipo-062_0                                           0.029576         \n",
            "Lipo-045_0                                           0.003140         \n",
            "Lipo-081_0                                           0.021911         \n",
            "Lipo-051_0                                           0.033644         \n",
            "Lipo-021_0                                           0.000000         \n",
            "Lipo-067_0                                           0.002903         \n",
            "Lipo-007_0                                           0.007399         \n",
            "Lipo-091_0                                           0.077306         \n",
            "Lipo-049_0                                           0.008425         \n",
            "Lipo-057_0                                           0.027979         \n",
            "Lipo-052_0                                           0.000000         \n",
            "Lipo-006_0                                           0.027552         \n",
            "\n",
            "            PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \n",
            "ID                                                                  \n",
            "Lipo-012_0                                           0.172800       \n",
            "Lipo-073_0                                           0.000000       \n",
            "Lipo-030_0                                           0.000000       \n",
            "Lipo-042_0                                           0.184326       \n",
            "Lipo-100_0                                           0.291763       \n",
            "Lipo-008_0                                           0.052566       \n",
            "Lipo-034_0                                           0.105126       \n",
            "Lipo-085_0                                           0.298320       \n",
            "Lipo-011_0                                           0.240397       \n",
            "Lipo-023_0                                           0.052585       \n",
            "Lipo-105_0                                           0.351461       \n",
            "Lipo-109_0                                           0.282876       \n",
            "Lipo-086_0                                           0.000000       \n",
            "Lipo-106_0                                           0.121532       \n",
            "Lipo-080_0                                           0.290533       \n",
            "Lipo-107_0                                           0.244726       \n",
            "Lipo-066_0                                           0.000759       \n",
            "Lipo-044_0                                           0.059252       \n",
            "Lipo-053_0                                           0.264155       \n",
            "Lipo-031_0                                           0.191414       \n",
            "Lipo-022_0                                           0.197682       \n",
            "Lipo-001_0                                           0.315148       \n",
            "Lipo-059_0                                           0.092393       \n",
            "Lipo-072_0                                           0.205459       \n",
            "Lipo-027_0                                           0.142689       \n",
            "Lipo-039_0                                           0.199847       \n",
            "Lipo-032_0                                           0.000000       \n",
            "Lipo-043_0                                           0.129139       \n",
            "Lipo-070_0                                           0.350621       \n",
            "Lipo-097_0                                           0.242394       \n",
            "Lipo-054_0                                           0.203704       \n",
            "Lipo-079_0                                           0.235223       \n",
            "Lipo-036_0                                           0.323502       \n",
            "Lipo-064_0                                           0.372071       \n",
            "Lipo-090_0                                           0.266019       \n",
            "Lipo-111_0                                           0.225207       \n",
            "Lipo-010_0                                           0.000000       \n",
            "Lipo-040_0                                           0.311027       \n",
            "Lipo-098_0                                           0.212911       \n",
            "Lipo-050_0                                           0.015460       \n",
            "Lipo-004_0                                           0.000000       \n",
            "Lipo-060_0                                           0.112317       \n",
            "Lipo-101_0                                           0.135915       \n",
            "Lipo-071_0                                           0.439963       \n",
            "Lipo-084_0                                           0.011296       \n",
            "Lipo-048_0                                           0.034994       \n",
            "Lipo-108_0                                           0.238174       \n",
            "Lipo-026_0                                           0.000000       \n",
            "Lipo-112_0                                           0.001270       \n",
            "Lipo-046_0                                           0.062305       \n",
            "Lipo-110_0                                           0.213592       \n",
            "Lipo-025_0                                           0.173810       \n",
            "Lipo-058_0                                           0.244874       \n",
            "Lipo-063_0                                           0.266126       \n",
            "Lipo-103_0                                           0.000000       \n",
            "Lipo-005_0                                           0.000000       \n",
            "Lipo-055_0                                           0.214826       \n",
            "Lipo-024_0                                           0.116921       \n",
            "Lipo-093_0                                           0.268553       \n",
            "Lipo-115_0                                           0.000000       \n",
            "Lipo-094_0                                           0.311835       \n",
            "Lipo-018_0                                           0.156739       \n",
            "Lipo-020_0                                           0.068624       \n",
            "Lipo-017_0                                           0.151798       \n",
            "Lipo-095_0                                           0.248510       \n",
            "Lipo-033_0                                           0.217548       \n",
            "Lipo-056_0                                           0.248453       \n",
            "Lipo-076_0                                           0.512815       \n",
            "Lipo-003_0                                           0.369366       \n",
            "Lipo-065_0                                           0.427551       \n",
            "Lipo-087_0                                           0.133422       \n",
            "Lipo-075_0                                           0.041455       \n",
            "Lipo-102_0                                           0.379273       \n",
            "Lipo-113_0                                           0.246028       \n",
            "Lipo-062_0                                           0.193789       \n",
            "Lipo-045_0                                           0.216498       \n",
            "Lipo-081_0                                           0.237619       \n",
            "Lipo-051_0                                           0.305264       \n",
            "Lipo-021_0                                           0.243285       \n",
            "Lipo-067_0                                           0.189764       \n",
            "Lipo-007_0                                           0.070181       \n",
            "Lipo-091_0                                           0.155919       \n",
            "Lipo-049_0                                           0.350467       \n",
            "Lipo-057_0                                           0.079629       \n",
            "Lipo-052_0                                           0.163069       \n",
            "Lipo-006_0                                           0.385779       \n",
            "Kolom:  PREDICT_original_sf_area_min_2.5D\n",
            "Kolom:  PREDICT_original_tf_LBP_quartile_range_R8_P24\n",
            "Kolom:  PREDICT_original_vf_Frangi_full_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "Kolom:  PREDICT_original_vf_Frangi_edge_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "Kolom:  PREDICT_original_vf_Frangi_inner_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "Kolom:  PREDICT_original_phasef_monogenic_min_WL3_N5\n",
            "Kolom:  PREDICT_original_phasef_monogenic_peak_WL3_N5\n",
            "Kolom:  PREDICT_original_phasef_monogenic_peak_position_WL3_N5\n",
            "Kolom:  PREDICT_original_phasef_phasecong_quartile_range_WL3_N5\n",
            "Kolom:  PREDICT_original_phasef_phasesym_quartile_range_WL3_N5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outliers eruit halen\n"
      ],
      "metadata": {
        "id": "Fui0tjwlW_9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outliers_total = 0\n",
        "\n",
        "for column in X_train.columns:\n",
        "    q1 = X_train[column].quantile(0.25)\n",
        "    q3 = X_train[column].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - (1.5 * iqr)\n",
        "    upper_bound = q3 + (1.5 * iqr)\n",
        "\n",
        "    outliers_column = (X_train[column] < lower_bound).sum() + (X_train[column] > upper_bound).sum()\n",
        "    outliers_total += outliers_column\n",
        "\n",
        "    X_train.loc[X_train[column] < lower_bound, column] = lower_bound\n",
        "    X_train.loc[X_train[column] > upper_bound, column] = upper_bound\n",
        "\n",
        "print(f\"Er zijn {outliers_total} outliers vervangen\")\n",
        "print(data_punten)\n",
        "print(f\"Dit was {outliers_total / data_punten *100}% van het totale aantal datapunten\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik_99Td7XECw",
        "outputId": "7a1349b7-614b-41ee-d777-a9bf8a6c4bf7"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Er zijn 2037 outliers vervangen\n",
            "56810\n",
            "Dit was 3.585636331631755% van het totale aantal datapunten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling"
      ],
      "metadata": {
        "id": "YQtVjjF2dX77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler().fit(X_train_median)\n",
        "X_train_scaled = scaler.transform(X_train_median)\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_median.columns)"
      ],
      "metadata": {
        "id": "iXgA9qGcc2eH"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANOVA"
      ],
      "metadata": {
        "id": "ezzBM5civZcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ANOVA feature selection for numeric input and categorical output\n",
        "fs = SelectKBest(score_func=f_classif, k='all')\n",
        "\n",
        "fit = fs.fit(X_train_scaled_df, y_train)\n",
        "fit = fit.pvalues_\n",
        "df = pd.DataFrame(fit, columns=['P-value'], index=X_train.columns)\n",
        "rslt_df = df[df['P-value'] <= 0.05]\n",
        "transpose = X_train_scaled_df.transpose()\n",
        "new_df= rslt_df.join(transpose, how='left')\n",
        "new_df = new_df.transpose()\n",
        "X_train_ANOVA = new_df.drop('P-value', axis=0)\n",
        "print(X_train_ANOVA)\n"
      ],
      "metadata": {
        "id": "09R4Nb3Mvaxj",
        "outputId": "68709708-64b3-4c99-8900-78135f944f3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    PREDICT_original_sf_compactness_std_2.5D  \\\n",
            "0                                   1.325789   \n",
            "1                                  -0.987329   \n",
            "2                                   1.044299   \n",
            "3                                   1.160053   \n",
            "4                                  -0.526039   \n",
            "5                                  -0.814986   \n",
            "6                                   0.715070   \n",
            "7                                  -0.906895   \n",
            "8                                  -1.543213   \n",
            "9                                  -0.352070   \n",
            "10                                  0.243738   \n",
            "11                                  0.101556   \n",
            "12                                  1.547984   \n",
            "13                                 -0.998933   \n",
            "14                                 -0.971318   \n",
            "15                                  0.674629   \n",
            "16                                  0.680154   \n",
            "17                                  0.439095   \n",
            "18                                  1.088633   \n",
            "19                                  0.323704   \n",
            "20                                 -0.999089   \n",
            "21                                  1.157347   \n",
            "22                                  0.509634   \n",
            "23                                  1.526253   \n",
            "24                                  0.043507   \n",
            "25                                  0.862984   \n",
            "26                                  0.316557   \n",
            "27                                  0.327202   \n",
            "28                                  0.877976   \n",
            "29                                 -1.875761   \n",
            "30                                 -0.277929   \n",
            "31                                  0.396864   \n",
            "32                                 -1.724349   \n",
            "33                                  0.875114   \n",
            "34                                 -1.424569   \n",
            "35                                  0.241665   \n",
            "36                                 -0.301985   \n",
            "37                                 -0.659542   \n",
            "38                                 -1.311955   \n",
            "39                                  0.499254   \n",
            "40                                 -0.138130   \n",
            "41                                  0.840878   \n",
            "42                                 -1.281754   \n",
            "43                                 -0.207865   \n",
            "44                                 -0.798228   \n",
            "45                                  0.650228   \n",
            "46                                  0.642694   \n",
            "47                                  0.288332   \n",
            "48                                  0.916623   \n",
            "49                                  0.056242   \n",
            "50                                 -1.504365   \n",
            "51                                 -1.013669   \n",
            "52                                 -1.636736   \n",
            "53                                 -0.198166   \n",
            "54                                  1.188806   \n",
            "55                                 -0.169967   \n",
            "56                                 -1.238109   \n",
            "57                                 -0.531965   \n",
            "58                                 -0.748566   \n",
            "59                                 -0.483274   \n",
            "60                                  1.667033   \n",
            "61                                  2.060433   \n",
            "62                                  1.320929   \n",
            "63                                  0.756284   \n",
            "64                                  0.351065   \n",
            "65                                 -0.909737   \n",
            "66                                 -0.251595   \n",
            "67                                 -0.511216   \n",
            "68                                 -0.306676   \n",
            "69                                 -0.892368   \n",
            "70                                  1.177022   \n",
            "71                                  0.879329   \n",
            "72                                 -0.154848   \n",
            "73                                 -0.145255   \n",
            "74                                  1.398662   \n",
            "75                                  0.776700   \n",
            "76                                  2.291553   \n",
            "77                                  1.253509   \n",
            "78                                 -1.548391   \n",
            "79                                 -0.239329   \n",
            "80                                  0.681173   \n",
            "81                                 -1.501027   \n",
            "82                                  0.451171   \n",
            "83                                 -1.095923   \n",
            "84                                 -1.580197   \n",
            "85                                 -1.864407   \n",
            "\n",
            "    PREDICT_original_sf_convexity_std_2.5D  PREDICT_original_sf_prax_std_2.5D  \\\n",
            "0                                 1.367673                           1.731379   \n",
            "1                                -1.139143                          -1.100325   \n",
            "2                                 0.092638                           1.424767   \n",
            "3                                 0.601431                           0.435570   \n",
            "4                                -0.928955                          -0.382675   \n",
            "5                                -0.979759                          -1.157702   \n",
            "6                                 0.233218                           0.284807   \n",
            "7                                -1.434111                           0.405911   \n",
            "8                                -1.495044                          -0.806217   \n",
            "9                                 0.521484                           0.825886   \n",
            "10                               -0.962836                           1.535134   \n",
            "11                               -0.195302                           1.408483   \n",
            "12                                0.912296                           0.392081   \n",
            "13                               -1.447006                           0.921814   \n",
            "14                               -0.657114                          -1.692087   \n",
            "15                                1.327406                           0.670021   \n",
            "16                                0.694622                           0.769316   \n",
            "17                               -0.239714                          -0.325466   \n",
            "18                                1.090044                          -1.334873   \n",
            "19                                0.331672                          -0.307991   \n",
            "20                               -1.151816                          -0.514564   \n",
            "21                                0.837258                          -0.339758   \n",
            "22                                1.437012                           1.821581   \n",
            "23                                1.350590                           0.553148   \n",
            "24                               -0.776314                           2.192890   \n",
            "25                                0.478851                           2.359527   \n",
            "26                               -0.409251                           0.367422   \n",
            "27                                0.401915                          -0.306535   \n",
            "28                                0.435623                          -0.115255   \n",
            "29                               -0.669688                          -0.833597   \n",
            "30                               -0.496286                           0.323788   \n",
            "31                                0.544587                          -0.301783   \n",
            "32                               -1.614214                           0.268050   \n",
            "33                                0.964739                           0.191333   \n",
            "34                               -1.558708                           0.068783   \n",
            "35                                0.863664                          -0.992687   \n",
            "36                                0.620017                          -1.235779   \n",
            "37                               -1.477371                           2.366842   \n",
            "38                               -1.381987                          -1.084611   \n",
            "39                                0.870682                           0.070335   \n",
            "40                                0.351146                          -0.892991   \n",
            "41                                1.012522                           0.570307   \n",
            "42                               -1.473656                          -0.199849   \n",
            "43                               -0.579184                          -1.349589   \n",
            "44                               -1.027351                           0.057634   \n",
            "45                                0.574334                           0.387845   \n",
            "46                                1.080522                          -0.240637   \n",
            "47                               -0.083267                          -0.371972   \n",
            "48                                1.482514                           0.564943   \n",
            "49                               -0.192529                          -0.637480   \n",
            "50                                0.385490                          -1.673784   \n",
            "51                               -1.137945                          -0.539589   \n",
            "52                               -1.292929                          -1.334345   \n",
            "53                               -0.440931                           0.670131   \n",
            "54                                1.323896                           1.032674   \n",
            "55                                0.426066                          -0.933110   \n",
            "56                               -1.590059                          -0.929709   \n",
            "57                               -0.663921                           0.873382   \n",
            "58                               -0.776639                          -0.159141   \n",
            "59                               -0.684280                          -0.135101   \n",
            "60                                0.982917                           1.542735   \n",
            "61                                2.437252                          -0.960290   \n",
            "62                                1.257260                          -0.384883   \n",
            "63                                0.155733                          -0.340075   \n",
            "64                                1.418075                           2.151718   \n",
            "65                               -0.805902                          -0.519674   \n",
            "66                               -0.637423                          -0.156354   \n",
            "67                                0.148494                          -1.587057   \n",
            "68                               -0.226109                          -0.648717   \n",
            "69                               -0.941446                          -1.324004   \n",
            "70                                1.330877                           1.677922   \n",
            "71                                0.082904                           0.695281   \n",
            "72                                0.327603                          -0.987172   \n",
            "73                                0.222476                           0.900028   \n",
            "74                                0.361821                           1.220206   \n",
            "75                                1.037100                          -0.135123   \n",
            "76                                1.889296                           0.918129   \n",
            "77                                1.356687                          -0.132458   \n",
            "78                               -1.394284                          -0.971492   \n",
            "79                                0.395071                           0.208846   \n",
            "80                                0.206275                          -0.727766   \n",
            "81                                0.094687                          -0.858269   \n",
            "82                                0.866957                           0.233360   \n",
            "83                               -1.027562                          -1.340735   \n",
            "84                               -1.555825                          -0.180733   \n",
            "85                               -1.639538                          -1.610004   \n",
            "\n",
            "    PREDICT_original_sf_area_avg_2.5D  PREDICT_original_sf_area_max_2.5D  \\\n",
            "0                            0.577930                           0.686782   \n",
            "1                            1.053895                           0.842663   \n",
            "2                            0.029669                          -0.162760   \n",
            "3                            0.175720                           0.574885   \n",
            "4                           -0.995073                          -1.032578   \n",
            "5                           -1.012094                          -1.057401   \n",
            "6                            1.080876                           0.846270   \n",
            "7                           -1.227416                          -1.218679   \n",
            "8                           -0.951789                          -0.977023   \n",
            "9                           -0.363220                          -0.313443   \n",
            "10                          -0.772833                          -0.717144   \n",
            "11                          -0.481382                          -0.545209   \n",
            "12                           0.437038                           0.647917   \n",
            "13                          -0.033417                          -0.266771   \n",
            "14                          -0.388853                          -0.448409   \n",
            "15                          -1.034508                          -1.013361   \n",
            "16                           1.837130                           1.814143   \n",
            "17                          -0.492309                          -0.460200   \n",
            "18                          -0.782204                          -0.817339   \n",
            "19                           2.471677                           2.590632   \n",
            "20                           1.038775                           1.100209   \n",
            "21                          -0.903175                          -0.906672   \n",
            "22                           0.393480                           0.588856   \n",
            "23                           0.408749                           0.324781   \n",
            "24                           0.926742                           0.465234   \n",
            "25                          -0.838982                          -0.740365   \n",
            "26                          -0.681029                          -0.716754   \n",
            "27                           2.471677                           2.166079   \n",
            "28                          -0.794801                          -0.755189   \n",
            "29                          -1.113287                          -1.083055   \n",
            "30                           0.111783                           0.262875   \n",
            "31                           2.471677                           2.590632   \n",
            "32                          -1.128022                          -1.100545   \n",
            "33                          -0.236162                          -0.352824   \n",
            "34                          -1.141494                          -1.130327   \n",
            "35                           0.069982                          -0.024678   \n",
            "36                          -0.675290                          -0.617407   \n",
            "37                          -0.796589                          -0.726274   \n",
            "38                          -0.583917                          -0.602970   \n",
            "39                          -0.539746                          -0.571431   \n",
            "40                           2.146553                           1.748058   \n",
            "41                          -0.224536                           0.333545   \n",
            "42                          -0.703351                          -0.632082   \n",
            "43                          -1.122233                          -1.126570   \n",
            "44                          -0.299104                          -0.403388   \n",
            "45                           0.661941                           0.787650   \n",
            "46                           0.686599                           0.516087   \n",
            "47                          -0.836226                          -0.850805   \n",
            "48                          -0.825718                          -0.828138   \n",
            "49                           2.471677                           2.590632   \n",
            "50                           0.453592                           0.377534   \n",
            "51                          -0.384355                          -0.514105   \n",
            "52                          -0.501409                          -0.541783   \n",
            "53                          -0.924485                          -0.875432   \n",
            "54                           2.471677                           2.590632   \n",
            "55                          -0.464407                          -0.384218   \n",
            "56                          -0.769436                          -0.772379   \n",
            "57                          -0.467137                          -0.248536   \n",
            "58                          -1.201100                          -1.206767   \n",
            "59                           0.918038                           0.812904   \n",
            "60                          -0.109868                           0.163831   \n",
            "61                          -0.380080                          -0.574969   \n",
            "62                           2.471677                           2.590632   \n",
            "63                          -0.593368                          -0.571055   \n",
            "64                           0.856898                           0.895101   \n",
            "65                           1.509526                           1.267999   \n",
            "66                          -0.060438                          -0.137739   \n",
            "67                          -1.043046                          -1.002747   \n",
            "68                          -0.618400                          -0.660572   \n",
            "69                          -0.917681                          -1.015793   \n",
            "70                           0.498783                           0.831488   \n",
            "71                           0.579837                           0.832084   \n",
            "72                          -0.523441                          -0.383208   \n",
            "73                           0.609886                           0.422626   \n",
            "74                          -1.041046                          -1.042347   \n",
            "75                           0.967100                           0.918254   \n",
            "76                          -0.929684                          -0.959642   \n",
            "77                           0.366716                           0.820262   \n",
            "78                           0.398840                           0.296222   \n",
            "79                           0.174919                          -0.010481   \n",
            "80                          -0.013126                          -0.242538   \n",
            "81                           0.255550                           0.372129   \n",
            "82                          -0.390768                          -0.376318   \n",
            "83                          -0.499270                          -0.548929   \n",
            "84                           0.527986                           0.497614   \n",
            "85                          -0.773292                          -0.897898   \n",
            "\n",
            "    PREDICT_original_sf_area_std_2.5D  PREDICT_original_sf_volume_2.5D  \\\n",
            "0                            0.780195                         1.151130   \n",
            "1                            0.840029                         0.525260   \n",
            "2                           -0.530156                        -0.056397   \n",
            "3                            0.856215                         1.509047   \n",
            "4                           -1.015330                        -1.028769   \n",
            "5                           -1.043489                        -1.003911   \n",
            "6                            0.473714                        -0.513299   \n",
            "7                           -1.152080                        -1.063119   \n",
            "8                           -0.924086                        -0.907423   \n",
            "9                           -0.133067                        -0.299405   \n",
            "10                          -0.592438                        -0.744094   \n",
            "11                          -0.519950                        -0.416806   \n",
            "12                           0.565650                        -0.117772   \n",
            "13                          -0.588523                        -0.506569   \n",
            "14                          -0.586404                        -0.697338   \n",
            "15                          -0.941050                        -0.940048   \n",
            "16                           1.761235                         1.238533   \n",
            "17                          -0.471624                        -0.085614   \n",
            "18                          -0.799683                        -0.774099   \n",
            "19                           2.774738                         2.346211   \n",
            "20                           0.906370                         2.616769   \n",
            "21                          -0.876924                        -0.575819   \n",
            "22                           0.635484                         0.950295   \n",
            "23                           0.307031                         0.716476   \n",
            "24                           0.372368                         2.256271   \n",
            "25                          -0.610384                        -0.694193   \n",
            "26                          -0.654423                        -0.705228   \n",
            "27                           1.282468                        -0.179734   \n",
            "28                          -0.792224                        -0.503289   \n",
            "29                          -1.008929                        -1.024813   \n",
            "30                           0.452547                         1.289519   \n",
            "31                           2.774738                         2.616769   \n",
            "32                          -0.993325                        -0.999190   \n",
            "33                          -0.567596                         0.141371   \n",
            "34                          -1.068108                        -0.970140   \n",
            "35                          -0.251457                        -0.165708   \n",
            "36                          -0.612304                        -0.222825   \n",
            "37                          -0.594838                        -0.704493   \n",
            "38                          -0.544611                        -0.637308   \n",
            "39                          -0.485725                        -0.464698   \n",
            "40                           1.502309                         0.749708   \n",
            "41                           0.678562                         0.098259   \n",
            "42                          -0.527802                        -0.817415   \n",
            "43                          -1.063532                        -0.987681   \n",
            "44                          -0.386877                        -0.201440   \n",
            "45                           1.105925                         2.540307   \n",
            "46                           0.305991                         0.151793   \n",
            "47                          -0.798069                        -0.827034   \n",
            "48                          -0.745668                        -0.690313   \n",
            "49                           2.739966                         1.103218   \n",
            "50                           0.227054                        -0.072694   \n",
            "51                          -0.520091                        -0.567143   \n",
            "52                          -0.538600                        -0.070073   \n",
            "53                          -0.845904                        -0.862719   \n",
            "54                           2.774738                         0.755693   \n",
            "55                          -0.321547                        -0.436431   \n",
            "56                          -0.811186                        -0.883370   \n",
            "57                          -0.220732                        -0.070953   \n",
            "58                          -1.161867                        -1.041031   \n",
            "59                           0.775549                         1.852148   \n",
            "60                           0.207729                        -0.245809   \n",
            "61                          -0.857367                        -0.749192   \n",
            "62                           2.774738                         2.616769   \n",
            "63                          -0.511425                        -0.645206   \n",
            "64                           1.069613                        -0.251922   \n",
            "65                           0.942710                         1.179699   \n",
            "66                          -0.182507                         0.633022   \n",
            "67                          -0.949079                        -0.981395   \n",
            "68                          -0.660547                        -0.676076   \n",
            "69                          -1.145787                        -1.011862   \n",
            "70                           1.010770                        -0.233495   \n",
            "71                           0.760600                         0.010136   \n",
            "72                          -0.209949                        -0.531860   \n",
            "73                           0.527390                        -0.347131   \n",
            "74                          -0.946438                        -1.030011   \n",
            "75                           0.655480                         1.397859   \n",
            "76                          -0.915524                        -0.927776   \n",
            "77                           0.981830                         1.623550   \n",
            "78                           0.298990                         0.762691   \n",
            "79                          -0.020459                        -0.168071   \n",
            "80                          -0.585186                        -0.231725   \n",
            "81                           0.372105                         0.008604   \n",
            "82                          -0.319665                         0.499802   \n",
            "83                          -0.542076                        -0.599812   \n",
            "84                           0.643564                         0.739398   \n",
            "85                          -0.991786                        -0.918568   \n",
            "\n",
            "    PREDICT_original_hf_min  PREDICT_original_hf_median  \\\n",
            "0                 -1.440458                   -0.588706   \n",
            "1                 -0.563643                   -0.366549   \n",
            "2                 -0.487393                   -0.828921   \n",
            "3                 -0.141535                   -0.298076   \n",
            "4                  0.288629                    0.831386   \n",
            "5                 -1.401399                   -1.507569   \n",
            "6                 -0.341932                   -0.398326   \n",
            "7                 -0.665394                   -1.408009   \n",
            "8                 -1.229629                   -1.043198   \n",
            "9                 -1.096730                   -0.659549   \n",
            "10                 0.891751                    0.305119   \n",
            "11                 1.974638                    2.245281   \n",
            "12                -1.646340                   -1.582068   \n",
            "13                -1.509792                   -1.524187   \n",
            "14                 1.412046                    2.302785   \n",
            "15                 0.097061                    0.404474   \n",
            "16                -0.512403                   -0.557888   \n",
            "17                -0.018955                   -0.255989   \n",
            "18                 0.157982                    0.199342   \n",
            "19                -0.458518                    0.005048   \n",
            "20                 1.576002                    1.193316   \n",
            "21                 0.443310                    0.667405   \n",
            "22                -1.060293                   -1.365963   \n",
            "23                -0.365455                   -0.669544   \n",
            "24                -0.028865                    0.310552   \n",
            "25                -0.377896                   -0.370029   \n",
            "26                -0.968823                   -0.617653   \n",
            "27                -1.044090                   -0.544430   \n",
            "28                 2.567580                    2.302785   \n",
            "29                 1.057598                    1.266889   \n",
            "30                 0.533298                    0.537398   \n",
            "31                 0.065740                    0.201475   \n",
            "32                 1.249776                    0.105658   \n",
            "33                 0.597767                    1.646284   \n",
            "34                -0.444980                    0.368975   \n",
            "35                 1.500414                    0.546176   \n",
            "36                -0.856187                   -1.020819   \n",
            "37                 0.390838                    1.193023   \n",
            "38                 0.894692                    0.890087   \n",
            "39                -1.123063                   -1.140623   \n",
            "40                -1.535015                   -1.967575   \n",
            "41                -1.033199                   -0.932832   \n",
            "42                -0.588897                   -0.474875   \n",
            "43                 2.787066                    2.302785   \n",
            "44                -0.648826                   -0.660519   \n",
            "45                -0.995093                   -0.558829   \n",
            "46                -0.158394                   -0.219439   \n",
            "47                -0.399484                   -0.800473   \n",
            "48                -1.034922                   -1.352991   \n",
            "49                -1.380857                   -1.102041   \n",
            "50                -0.253432                    0.258373   \n",
            "51                 0.200241                    0.028962   \n",
            "52                 0.851860                    0.063950   \n",
            "53                 0.731309                    0.115044   \n",
            "54                -1.141993                   -1.250200   \n",
            "55                -0.085453                    0.465564   \n",
            "56                 0.436030                    0.366483   \n",
            "57                -0.625165                   -0.756015   \n",
            "58                 0.200644                    0.081512   \n",
            "59                -1.100385                   -0.925734   \n",
            "60                 0.113018                   -0.379294   \n",
            "61                 0.298013                   -0.299945   \n",
            "62                -0.624438                   -0.487911   \n",
            "63                -0.703555                   -1.184282   \n",
            "64                 0.723651                    0.810886   \n",
            "65                 0.145057                   -0.359290   \n",
            "66                 0.664492                    0.182062   \n",
            "67                 2.110565                    2.302785   \n",
            "68                 0.936675                    0.487599   \n",
            "69                 2.391298                    1.698226   \n",
            "70                -0.803294                   -0.291003   \n",
            "71                -0.936183                   -0.508934   \n",
            "72                 1.672938                    2.302785   \n",
            "73                 0.054744                    0.451038   \n",
            "74                -0.147418                    0.117267   \n",
            "75                 1.053747                    0.539379   \n",
            "76                -0.158984                    0.824134   \n",
            "77                 0.057781                    0.725105   \n",
            "78                 0.848643                    0.943297   \n",
            "79                 0.437304                    0.067789   \n",
            "80                 0.149174                    0.022326   \n",
            "81                -1.049008                   -1.189442   \n",
            "82                 0.691785                    0.806715   \n",
            "83                -1.257274                   -1.550397   \n",
            "84                 1.088614                    0.435498   \n",
            "85                 0.101272                    0.077091   \n",
            "\n",
            "    PREDICT_original_hf_entropy  ...  \\\n",
            "0                      1.669022  ...   \n",
            "1                      0.337198  ...   \n",
            "2                      0.667767  ...   \n",
            "3                      0.694495  ...   \n",
            "4                     -2.100339  ...   \n",
            "5                     -1.050137  ...   \n",
            "6                     -0.747160  ...   \n",
            "7                     -2.660202  ...   \n",
            "8                     -0.278682  ...   \n",
            "9                      2.013251  ...   \n",
            "10                    -1.180667  ...   \n",
            "11                    -0.123319  ...   \n",
            "12                    -0.027654  ...   \n",
            "13                    -0.334247  ...   \n",
            "14                    -0.741376  ...   \n",
            "15                     0.437486  ...   \n",
            "16                     0.876423  ...   \n",
            "17                    -0.229927  ...   \n",
            "18                    -0.459716  ...   \n",
            "19                     1.350881  ...   \n",
            "20                     2.135733  ...   \n",
            "21                    -0.654151  ...   \n",
            "22                     1.569435  ...   \n",
            "23                     1.025804  ...   \n",
            "24                     0.926072  ...   \n",
            "25                    -0.525429  ...   \n",
            "26                     0.348979  ...   \n",
            "27                     0.806610  ...   \n",
            "28                    -0.793177  ...   \n",
            "29                     0.135345  ...   \n",
            "30                     1.762370  ...   \n",
            "31                     1.597773  ...   \n",
            "32                    -1.648542  ...   \n",
            "33                     0.010205  ...   \n",
            "34                    -1.422567  ...   \n",
            "35                     0.754876  ...   \n",
            "36                    -0.357437  ...   \n",
            "37                    -0.942550  ...   \n",
            "38                     0.067388  ...   \n",
            "39                    -1.289168  ...   \n",
            "40                     0.940838  ...   \n",
            "41                    -0.012146  ...   \n",
            "42                    -1.192934  ...   \n",
            "43                    -0.520284  ...   \n",
            "44                     1.224134  ...   \n",
            "45                     0.829364  ...   \n",
            "46                    -0.328311  ...   \n",
            "47                    -1.017030  ...   \n",
            "48                     0.523633  ...   \n",
            "49                     0.329242  ...   \n",
            "50                    -0.318867  ...   \n",
            "51                    -0.178567  ...   \n",
            "52                     0.380113  ...   \n",
            "53                    -1.008247  ...   \n",
            "54                     0.117083  ...   \n",
            "55                     1.533254  ...   \n",
            "56                    -0.227903  ...   \n",
            "57                     0.638291  ...   \n",
            "58                    -2.595817  ...   \n",
            "59                     1.826807  ...   \n",
            "60                    -0.118589  ...   \n",
            "61                     0.732904  ...   \n",
            "62                     0.732495  ...   \n",
            "63                    -0.285314  ...   \n",
            "64                     0.642455  ...   \n",
            "65                     0.618954  ...   \n",
            "66                     0.010524  ...   \n",
            "67                    -0.986790  ...   \n",
            "68                    -0.767600  ...   \n",
            "69                    -1.737668  ...   \n",
            "70                    -0.328841  ...   \n",
            "71                     0.519211  ...   \n",
            "72                    -0.711254  ...   \n",
            "73                    -0.155267  ...   \n",
            "74                    -0.583648  ...   \n",
            "75                     0.786606  ...   \n",
            "76                     0.673676  ...   \n",
            "77                     0.531196  ...   \n",
            "78                     0.823495  ...   \n",
            "79                     0.637496  ...   \n",
            "80                     0.008644  ...   \n",
            "81                    -0.652483  ...   \n",
            "82                    -0.715974  ...   \n",
            "83                    -0.949694  ...   \n",
            "84                     0.270525  ...   \n",
            "85                    -1.558377  ...   \n",
            "\n",
            "    PREDICT_original_tf_Gabor_entropy_F0.5_A0.0  \\\n",
            "0                                      1.668856   \n",
            "1                                      0.324971   \n",
            "2                                      0.707567   \n",
            "3                                      0.678483   \n",
            "4                                     -2.095902   \n",
            "5                                     -1.048285   \n",
            "6                                     -0.668761   \n",
            "7                                     -2.679412   \n",
            "8                                     -0.284502   \n",
            "9                                      1.998036   \n",
            "10                                    -1.205169   \n",
            "11                                    -0.141663   \n",
            "12                                    -0.016182   \n",
            "13                                    -0.305609   \n",
            "14                                    -0.727512   \n",
            "15                                     0.419438   \n",
            "16                                     0.853024   \n",
            "17                                    -0.237504   \n",
            "18                                    -0.468946   \n",
            "19                                     1.343799   \n",
            "20                                     2.114077   \n",
            "21                                    -0.656325   \n",
            "22                                     1.593794   \n",
            "23                                     1.012878   \n",
            "24                                     0.923733   \n",
            "25                                    -0.536947   \n",
            "26                                     0.342328   \n",
            "27                                     0.898804   \n",
            "28                                    -0.805691   \n",
            "29                                     0.128166   \n",
            "30                                     1.742543   \n",
            "31                                     1.590722   \n",
            "32                                    -1.678714   \n",
            "33                                     0.001218   \n",
            "34                                    -1.431780   \n",
            "35                                     0.731729   \n",
            "36                                    -0.366184   \n",
            "37                                    -0.952368   \n",
            "38                                     0.098210   \n",
            "39                                    -1.224706   \n",
            "40                                     0.953791   \n",
            "41                                    -0.028887   \n",
            "42                                    -1.189705   \n",
            "43                                    -0.539997   \n",
            "44                                     1.216018   \n",
            "45                                     0.886045   \n",
            "46                                    -0.222493   \n",
            "47                                    -1.035113   \n",
            "48                                     0.555366   \n",
            "49                                     0.357860   \n",
            "50                                    -0.308319   \n",
            "51                                    -0.197444   \n",
            "52                                     0.355940   \n",
            "53                                    -1.028138   \n",
            "54                                     0.121163   \n",
            "55                                     1.527644   \n",
            "56                                    -0.222694   \n",
            "57                                     0.635243   \n",
            "58                                    -2.605457   \n",
            "59                                     1.862847   \n",
            "60                                    -0.140900   \n",
            "61                                     0.715888   \n",
            "62                                     0.733038   \n",
            "63                                    -0.285327   \n",
            "64                                     0.622619   \n",
            "65                                     0.594902   \n",
            "66                                    -0.011382   \n",
            "67                                    -1.005512   \n",
            "68                                    -0.795516   \n",
            "69                                    -1.741086   \n",
            "70                                    -0.307557   \n",
            "71                                     0.521927   \n",
            "72                                    -0.713325   \n",
            "73                                    -0.159200   \n",
            "74                                    -0.574866   \n",
            "75                                     0.767026   \n",
            "76                                     0.670924   \n",
            "77                                     0.523143   \n",
            "78                                     0.804693   \n",
            "79                                     0.622814   \n",
            "80                                    -0.012630   \n",
            "81                                    -0.631175   \n",
            "82                                    -0.727589   \n",
            "83                                    -0.917311   \n",
            "84                                     0.249099   \n",
            "85                                    -1.536587   \n",
            "\n",
            "    PREDICT_original_tf_Gabor_mean_F0.5_A0.79  \\\n",
            "0                                   -0.539833   \n",
            "1                                   -0.199318   \n",
            "2                                   -2.492832   \n",
            "3                                    0.032469   \n",
            "4                                    0.940231   \n",
            "5                                   -0.800369   \n",
            "6                                   -1.530101   \n",
            "7                                    0.242974   \n",
            "8                                   -0.374348   \n",
            "9                                   -0.586306   \n",
            "10                                   0.977981   \n",
            "11                                   0.913748   \n",
            "12                                  -0.851706   \n",
            "13                                  -0.736808   \n",
            "14                                  -0.342059   \n",
            "15                                   0.235236   \n",
            "16                                  -0.318395   \n",
            "17                                  -0.728013   \n",
            "18                                   0.419704   \n",
            "19                                  -0.568587   \n",
            "20                                  -0.210263   \n",
            "21                                   0.364090   \n",
            "22                                  -1.233688   \n",
            "23                                  -0.208763   \n",
            "24                                  -0.664719   \n",
            "25                                  -0.030279   \n",
            "26                                  -1.028097   \n",
            "27                                  -1.318376   \n",
            "28                                   2.364013   \n",
            "29                                   1.304740   \n",
            "30                                  -0.302552   \n",
            "31                                  -0.270208   \n",
            "32                                   1.512245   \n",
            "33                                   1.494722   \n",
            "34                                   0.752243   \n",
            "35                                   1.032725   \n",
            "36                                  -0.189679   \n",
            "37                                   0.646620   \n",
            "38                                   0.148620   \n",
            "39                                  -0.640274   \n",
            "40                                  -1.171360   \n",
            "41                                  -0.673781   \n",
            "42                                  -0.047088   \n",
            "43                                   2.364013   \n",
            "44                                  -0.528280   \n",
            "45                                  -0.760368   \n",
            "46                                  -1.629879   \n",
            "47                                   0.082900   \n",
            "48                                  -1.159255   \n",
            "49                                  -0.852731   \n",
            "50                                  -0.052554   \n",
            "51                                  -0.260467   \n",
            "52                                   0.238727   \n",
            "53                                   1.235563   \n",
            "54                                  -1.229808   \n",
            "55                                  -0.214675   \n",
            "56                                   0.657231   \n",
            "57                                  -0.420210   \n",
            "58                                   2.364013   \n",
            "59                                  -0.633103   \n",
            "60                                   0.271888   \n",
            "61                                  -0.082933   \n",
            "62                                  -1.379397   \n",
            "63                                  -0.179876   \n",
            "64                                   0.201984   \n",
            "65                                  -1.489725   \n",
            "66                                   0.718838   \n",
            "67                                   2.364013   \n",
            "68                                   0.825578   \n",
            "69                                   2.364013   \n",
            "70                                  -1.320603   \n",
            "71                                  -0.683721   \n",
            "72                                   2.080578   \n",
            "73                                   0.553936   \n",
            "74                                   0.379231   \n",
            "75                                   0.504021   \n",
            "76                                   0.603428   \n",
            "77                                   0.508976   \n",
            "78                                   0.505798   \n",
            "79                                  -0.510005   \n",
            "80                                  -0.065704   \n",
            "81                                  -1.216283   \n",
            "82                                   1.030941   \n",
            "83                                  -0.862357   \n",
            "84                                   0.183895   \n",
            "85                                   0.167813   \n",
            "\n",
            "    PREDICT_original_tf_Gabor_entropy_F0.5_A0.79  \\\n",
            "0                                       1.668817   \n",
            "1                                       0.324069   \n",
            "2                                       0.706536   \n",
            "3                                       0.678550   \n",
            "4                                      -2.095085   \n",
            "5                                      -1.047329   \n",
            "6                                      -0.666429   \n",
            "7                                      -2.679686   \n",
            "8                                      -0.282645   \n",
            "9                                       1.997252   \n",
            "10                                     -1.209190   \n",
            "11                                     -0.141909   \n",
            "12                                     -0.013627   \n",
            "13                                     -0.304442   \n",
            "14                                     -0.715168   \n",
            "15                                      0.419376   \n",
            "16                                      0.852166   \n",
            "17                                     -0.239245   \n",
            "18                                     -0.469454   \n",
            "19                                      1.344448   \n",
            "20                                      2.114672   \n",
            "21                                     -0.656340   \n",
            "22                                      1.593067   \n",
            "23                                      1.013300   \n",
            "24                                      0.923137   \n",
            "25                                     -0.537746   \n",
            "26                                      0.346562   \n",
            "27                                      0.896552   \n",
            "28                                     -0.804698   \n",
            "29                                      0.126532   \n",
            "30                                      1.744729   \n",
            "31                                      1.589244   \n",
            "32                                     -1.684943   \n",
            "33                                     -0.005180   \n",
            "34                                     -1.423512   \n",
            "35                                      0.731612   \n",
            "36                                     -0.361038   \n",
            "37                                     -0.950404   \n",
            "38                                      0.096404   \n",
            "39                                     -1.224896   \n",
            "40                                      0.954313   \n",
            "41                                     -0.027476   \n",
            "42                                     -1.188070   \n",
            "43                                     -0.545684   \n",
            "44                                      1.214894   \n",
            "45                                      0.885780   \n",
            "46                                     -0.221343   \n",
            "47                                     -1.038471   \n",
            "48                                      0.554152   \n",
            "49                                      0.357923   \n",
            "50                                     -0.309873   \n",
            "51                                     -0.198941   \n",
            "52                                      0.355518   \n",
            "53                                     -1.034913   \n",
            "54                                      0.122081   \n",
            "55                                      1.527056   \n",
            "56                                     -0.218512   \n",
            "57                                      0.634087   \n",
            "58                                     -2.609307   \n",
            "59                                      1.862099   \n",
            "60                                     -0.142745   \n",
            "61                                      0.716139   \n",
            "62                                      0.734106   \n",
            "63                                     -0.286048   \n",
            "64                                      0.627551   \n",
            "65                                      0.600832   \n",
            "66                                     -0.017039   \n",
            "67                                     -1.004541   \n",
            "68                                     -0.792492   \n",
            "69                                     -1.740657   \n",
            "70                                     -0.307367   \n",
            "71                                      0.524693   \n",
            "72                                     -0.723572   \n",
            "73                                     -0.157591   \n",
            "74                                     -0.575816   \n",
            "75                                      0.765227   \n",
            "76                                      0.671158   \n",
            "77                                      0.521985   \n",
            "78                                      0.805669   \n",
            "79                                      0.622611   \n",
            "80                                     -0.018319   \n",
            "81                                     -0.630612   \n",
            "82                                     -0.729831   \n",
            "83                                     -0.913725   \n",
            "84                                      0.250080   \n",
            "85                                     -1.529067   \n",
            "\n",
            "    PREDICT_original_tf_Gabor_entropy_F0.5_A1.57  \\\n",
            "0                                       1.668587   \n",
            "1                                       0.324277   \n",
            "2                                       0.707639   \n",
            "3                                       0.679630   \n",
            "4                                      -2.093109   \n",
            "5                                      -1.049736   \n",
            "6                                      -0.671323   \n",
            "7                                      -2.690381   \n",
            "8                                      -0.284254   \n",
            "9                                       1.998141   \n",
            "10                                     -1.200579   \n",
            "11                                     -0.143708   \n",
            "12                                     -0.015991   \n",
            "13                                     -0.305054   \n",
            "14                                     -0.715339   \n",
            "15                                      0.418318   \n",
            "16                                      0.853820   \n",
            "17                                     -0.240345   \n",
            "18                                     -0.465710   \n",
            "19                                      1.344687   \n",
            "20                                      2.113816   \n",
            "21                                     -0.659316   \n",
            "22                                      1.593520   \n",
            "23                                      1.013112   \n",
            "24                                      0.922836   \n",
            "25                                     -0.538682   \n",
            "26                                      0.344383   \n",
            "27                                      0.898404   \n",
            "28                                     -0.803727   \n",
            "29                                      0.127057   \n",
            "30                                      1.743907   \n",
            "31                                      1.588353   \n",
            "32                                     -1.680378   \n",
            "33                                     -0.000882   \n",
            "34                                     -1.425940   \n",
            "35                                      0.727921   \n",
            "36                                     -0.360267   \n",
            "37                                     -0.952549   \n",
            "38                                      0.097231   \n",
            "39                                     -1.229638   \n",
            "40                                      0.953224   \n",
            "41                                     -0.029261   \n",
            "42                                     -1.185403   \n",
            "43                                     -0.539165   \n",
            "44                                      1.215722   \n",
            "45                                      0.886647   \n",
            "46                                     -0.225900   \n",
            "47                                     -1.037631   \n",
            "48                                      0.554176   \n",
            "49                                      0.356469   \n",
            "50                                     -0.320838   \n",
            "51                                     -0.197372   \n",
            "52                                      0.359198   \n",
            "53                                     -1.031433   \n",
            "54                                      0.120160   \n",
            "55                                      1.527249   \n",
            "56                                     -0.218298   \n",
            "57                                      0.633415   \n",
            "58                                     -2.599315   \n",
            "59                                      1.862449   \n",
            "60                                     -0.140628   \n",
            "61                                      0.716581   \n",
            "62                                      0.731907   \n",
            "63                                     -0.285373   \n",
            "64                                      0.621258   \n",
            "65                                      0.598961   \n",
            "66                                     -0.011766   \n",
            "67                                     -0.998695   \n",
            "68                                     -0.792628   \n",
            "69                                     -1.751958   \n",
            "70                                     -0.308461   \n",
            "71                                      0.521510   \n",
            "72                                     -0.715089   \n",
            "73                                     -0.162212   \n",
            "74                                     -0.574968   \n",
            "75                                      0.768012   \n",
            "76                                      0.671972   \n",
            "77                                      0.524537   \n",
            "78                                      0.806511   \n",
            "79                                      0.624770   \n",
            "80                                     -0.014381   \n",
            "81                                     -0.631507   \n",
            "82                                     -0.726976   \n",
            "83                                     -0.915558   \n",
            "84                                      0.251685   \n",
            "85                                     -1.530335   \n",
            "\n",
            "    PREDICT_original_tf_Gabor_entropy_F0.5_A2.36  \\\n",
            "0                                       1.668392   \n",
            "1                                       0.324353   \n",
            "2                                       0.708016   \n",
            "3                                       0.676672   \n",
            "4                                      -2.096054   \n",
            "5                                      -1.048433   \n",
            "6                                      -0.667188   \n",
            "7                                      -2.684183   \n",
            "8                                      -0.282389   \n",
            "9                                       1.997001   \n",
            "10                                     -1.210911   \n",
            "11                                     -0.143076   \n",
            "12                                     -0.013915   \n",
            "13                                     -0.304312   \n",
            "14                                     -0.717140   \n",
            "15                                      0.418774   \n",
            "16                                      0.854540   \n",
            "17                                     -0.238309   \n",
            "18                                     -0.472573   \n",
            "19                                      1.343791   \n",
            "20                                      2.113384   \n",
            "21                                     -0.658293   \n",
            "22                                      1.592621   \n",
            "23                                      1.014186   \n",
            "24                                      0.923272   \n",
            "25                                     -0.535736   \n",
            "26                                      0.346707   \n",
            "27                                      0.898527   \n",
            "28                                     -0.803466   \n",
            "29                                      0.127576   \n",
            "30                                      1.744918   \n",
            "31                                      1.589108   \n",
            "32                                     -1.692661   \n",
            "33                                     -0.002909   \n",
            "34                                     -1.424535   \n",
            "35                                      0.731203   \n",
            "36                                     -0.360127   \n",
            "37                                     -0.950441   \n",
            "38                                      0.097718   \n",
            "39                                     -1.221856   \n",
            "40                                      0.954087   \n",
            "41                                     -0.027399   \n",
            "42                                     -1.190806   \n",
            "43                                     -0.549054   \n",
            "44                                      1.215188   \n",
            "45                                      0.884690   \n",
            "46                                     -0.221844   \n",
            "47                                     -1.039496   \n",
            "48                                      0.554817   \n",
            "49                                      0.358836   \n",
            "50                                     -0.307169   \n",
            "51                                     -0.198473   \n",
            "52                                      0.351559   \n",
            "53                                     -1.032903   \n",
            "54                                      0.121879   \n",
            "55                                      1.527087   \n",
            "56                                     -0.221725   \n",
            "57                                      0.634644   \n",
            "58                                     -2.600482   \n",
            "59                                      1.861742   \n",
            "60                                     -0.143710   \n",
            "61                                      0.715168   \n",
            "62                                      0.733806   \n",
            "63                                     -0.284759   \n",
            "64                                      0.627668   \n",
            "65                                      0.600442   \n",
            "66                                     -0.015346   \n",
            "67                                     -0.999461   \n",
            "68                                     -0.791361   \n",
            "69                                     -1.745076   \n",
            "70                                     -0.304476   \n",
            "71                                      0.524950   \n",
            "72                                     -0.717266   \n",
            "73                                     -0.158334   \n",
            "74                                     -0.572924   \n",
            "75                                      0.764283   \n",
            "76                                      0.670927   \n",
            "77                                      0.520453   \n",
            "78                                      0.804709   \n",
            "79                                      0.621257   \n",
            "80                                     -0.015229   \n",
            "81                                     -0.629719   \n",
            "82                                     -0.726791   \n",
            "83                                     -0.914346   \n",
            "84                                      0.249240   \n",
            "85                                     -1.531537   \n",
            "\n",
            "    PREDICT_original_phasef_monogenic_entropy_WL3_N5  \\\n",
            "0                                           1.651075   \n",
            "1                                           0.384217   \n",
            "2                                           0.722784   \n",
            "3                                           0.651735   \n",
            "4                                          -1.987212   \n",
            "5                                          -0.981971   \n",
            "6                                          -0.632657   \n",
            "7                                          -2.648371   \n",
            "8                                          -0.258083   \n",
            "9                                           1.968581   \n",
            "10                                         -1.299635   \n",
            "11                                         -0.141763   \n",
            "12                                         -0.008834   \n",
            "13                                         -0.252170   \n",
            "14                                         -0.898491   \n",
            "15                                          0.429293   \n",
            "16                                          0.886853   \n",
            "17                                         -0.227976   \n",
            "18                                         -0.508946   \n",
            "19                                          1.388279   \n",
            "20                                          2.073401   \n",
            "21                                         -0.668381   \n",
            "22                                          1.578683   \n",
            "23                                          1.022620   \n",
            "24                                          0.908563   \n",
            "25                                         -0.538568   \n",
            "26                                          0.281548   \n",
            "27                                          0.937124   \n",
            "28                                         -0.789402   \n",
            "29                                          0.145088   \n",
            "30                                          1.712209   \n",
            "31                                          1.642763   \n",
            "32                                         -1.610405   \n",
            "33                                         -0.029138   \n",
            "34                                         -1.475723   \n",
            "35                                          0.819159   \n",
            "36                                         -0.406071   \n",
            "37                                         -0.954494   \n",
            "38                                          0.064832   \n",
            "39                                         -1.248677   \n",
            "40                                          0.970527   \n",
            "41                                         -0.026499   \n",
            "42                                         -1.215686   \n",
            "43                                         -0.497733   \n",
            "44                                          1.234979   \n",
            "45                                          0.808952   \n",
            "46                                         -0.181408   \n",
            "47                                         -1.066512   \n",
            "48                                          0.516813   \n",
            "49                                          0.377512   \n",
            "50                                         -0.178270   \n",
            "51                                         -0.156102   \n",
            "52                                          0.330228   \n",
            "53                                         -1.016304   \n",
            "54                                          0.158227   \n",
            "55                                          1.498219   \n",
            "56                                         -0.440547   \n",
            "57                                          0.644204   \n",
            "58                                         -2.528522   \n",
            "59                                          1.841515   \n",
            "60                                         -0.119956   \n",
            "61                                          0.711936   \n",
            "62                                          0.735361   \n",
            "63                                         -0.286597   \n",
            "64                                          0.620693   \n",
            "65                                          0.582613   \n",
            "66                                          0.056601   \n",
            "67                                         -1.284131   \n",
            "68                                         -0.804280   \n",
            "69                                         -1.597310   \n",
            "70                                         -0.218324   \n",
            "71                                          0.525979   \n",
            "72                                         -0.616574   \n",
            "73                                         -0.097258   \n",
            "74                                         -0.534204   \n",
            "75                                          0.775990   \n",
            "76                                          0.674731   \n",
            "77                                          0.493875   \n",
            "78                                          0.819103   \n",
            "79                                          0.624398   \n",
            "80                                          0.023385   \n",
            "81                                         -0.639471   \n",
            "82                                         -0.717778   \n",
            "83                                         -0.938185   \n",
            "84                                          0.218454   \n",
            "85                                         -1.784481   \n",
            "\n",
            "    PREDICT_original_phasef_phasecong_energy_WL3_N5  \\\n",
            "0                                          2.043749   \n",
            "1                                         -0.644261   \n",
            "2                                         -0.183308   \n",
            "3                                          1.810801   \n",
            "4                                         -1.256417   \n",
            "5                                         -1.222087   \n",
            "6                                         -1.176490   \n",
            "7                                         -1.198235   \n",
            "8                                         -0.340121   \n",
            "9                                          2.043749   \n",
            "10                                        -0.936960   \n",
            "11                                        -0.084010   \n",
            "12                                        -0.687613   \n",
            "13                                        -0.884111   \n",
            "14                                        -1.021038   \n",
            "15                                         0.225498   \n",
            "16                                         0.557179   \n",
            "17                                        -0.442192   \n",
            "18                                        -0.810867   \n",
            "19                                         2.043749   \n",
            "20                                         2.043749   \n",
            "21                                        -0.516216   \n",
            "22                                         2.043749   \n",
            "23                                         2.043749   \n",
            "24                                         1.028791   \n",
            "25                                        -0.505952   \n",
            "26                                        -0.146497   \n",
            "27                                         0.925329   \n",
            "28                                        -0.065831   \n",
            "29                                         0.375172   \n",
            "30                                         2.043749   \n",
            "31                                         2.043749   \n",
            "32                                        -1.016950   \n",
            "33                                         0.307861   \n",
            "34                                        -0.692583   \n",
            "35                                         0.236064   \n",
            "36                                        -0.877611   \n",
            "37                                        -0.560845   \n",
            "38                                         0.053052   \n",
            "39                                        -1.109345   \n",
            "40                                         1.088022   \n",
            "41                                        -0.021853   \n",
            "42                                        -0.862186   \n",
            "43                                        -0.615147   \n",
            "44                                         1.475721   \n",
            "45                                         0.443805   \n",
            "46                                        -0.506313   \n",
            "47                                        -1.185532   \n",
            "48                                         0.167613   \n",
            "49                                        -0.275735   \n",
            "50                                        -0.408014   \n",
            "51                                        -0.415252   \n",
            "52                                         0.029467   \n",
            "53                                        -1.051803   \n",
            "54                                        -0.605884   \n",
            "55                                         1.977504   \n",
            "56                                        -0.642692   \n",
            "57                                         0.508499   \n",
            "58                                        -1.218418   \n",
            "59                                         2.043749   \n",
            "60                                        -0.052578   \n",
            "61                                         0.132224   \n",
            "62                                         0.357715   \n",
            "63                                        -0.476339   \n",
            "64                                        -0.511486   \n",
            "65                                        -0.406911   \n",
            "66                                        -0.191890   \n",
            "67                                        -0.631896   \n",
            "68                                        -0.850934   \n",
            "69                                        -0.972745   \n",
            "70                                        -0.705026   \n",
            "71                                         0.378819   \n",
            "72                                        -0.399830   \n",
            "73                                        -0.125520   \n",
            "74                                        -0.936378   \n",
            "75                                         0.312112   \n",
            "76                                         0.848976   \n",
            "77                                         1.171411   \n",
            "78                                         1.548539   \n",
            "79                                         0.321196   \n",
            "80                                        -0.075362   \n",
            "81                                        -0.741864   \n",
            "82                                        -0.903769   \n",
            "83                                        -1.131367   \n",
            "84                                        -0.199093   \n",
            "85                                        -1.173752   \n",
            "\n",
            "    PREDICT_original_phasef_phasecong_entropy_WL3_N5  \\\n",
            "0                                           2.031353   \n",
            "1                                           0.014016   \n",
            "2                                           0.685865   \n",
            "3                                           0.842969   \n",
            "4                                          -2.288554   \n",
            "5                                          -1.240348   \n",
            "6                                          -1.371499   \n",
            "7                                          -2.201987   \n",
            "8                                          -0.136683   \n",
            "9                                           2.273095   \n",
            "10                                         -0.931814   \n",
            "11                                         -0.333871   \n",
            "12                                          0.323661   \n",
            "13                                         -0.512653   \n",
            "14                                         -1.033399   \n",
            "15                                          0.239467   \n",
            "16                                          0.582851   \n",
            "17                                         -0.322281   \n",
            "18                                         -0.597352   \n",
            "19                                          1.719513   \n",
            "20                                          2.052127   \n",
            "21                                         -0.459142   \n",
            "22                                          1.754020   \n",
            "23                                          1.131562   \n",
            "24                                          0.645070   \n",
            "25                                         -0.519686   \n",
            "26                                          0.365222   \n",
            "27                                          1.096438   \n",
            "28                                         -0.402586   \n",
            "29                                          0.325584   \n",
            "30                                          1.845096   \n",
            "31                                          1.875651   \n",
            "32                                         -1.711107   \n",
            "33                                          0.182890   \n",
            "34                                         -0.858836   \n",
            "35                                          0.146713   \n",
            "36                                         -0.947419   \n",
            "37                                         -0.907349   \n",
            "38                                         -0.223421   \n",
            "39                                         -1.330947   \n",
            "40                                          1.407847   \n",
            "41                                          0.012274   \n",
            "42                                         -0.746307   \n",
            "43                                         -0.734834   \n",
            "44                                          1.369191   \n",
            "45                                          0.310904   \n",
            "46                                         -0.132037   \n",
            "47                                         -1.387595   \n",
            "48                                          0.528107   \n",
            "49                                          0.492565   \n",
            "50                                          0.256468   \n",
            "51                                         -0.331974   \n",
            "52                                         -0.432979   \n",
            "53                                         -0.976501   \n",
            "54                                         -0.186346   \n",
            "55                                          1.781400   \n",
            "56                                         -0.516122   \n",
            "57                                          0.782672   \n",
            "58                                         -1.782746   \n",
            "59                                          1.784833   \n",
            "60                                         -0.220186   \n",
            "61                                          0.269902   \n",
            "62                                          0.485484   \n",
            "63                                         -0.333105   \n",
            "64                                          0.089196   \n",
            "65                                         -0.032997   \n",
            "66                                         -0.222828   \n",
            "67                                         -0.181196   \n",
            "68                                         -0.894753   \n",
            "69                                         -1.638639   \n",
            "70                                         -0.138102   \n",
            "71                                          0.873080   \n",
            "72                                         -0.359320   \n",
            "73                                          0.246678   \n",
            "74                                         -0.407394   \n",
            "75                                          0.477698   \n",
            "76                                          0.791082   \n",
            "77                                          0.778792   \n",
            "78                                          0.573933   \n",
            "79                                          0.392876   \n",
            "80                                         -0.098475   \n",
            "81                                         -0.111299   \n",
            "82                                         -1.112234   \n",
            "83                                         -0.743908   \n",
            "84                                         -0.300405   \n",
            "85                                         -1.484930   \n",
            "\n",
            "    PREDICT_original_phasef_phasesym_skewness_WL3_N5  \\\n",
            "0                                           0.111483   \n",
            "1                                           2.680551   \n",
            "2                                           1.640629   \n",
            "3                                          -0.128244   \n",
            "4                                          -0.798312   \n",
            "5                                           0.838267   \n",
            "6                                           0.462022   \n",
            "7                                          -0.786850   \n",
            "8                                          -0.650771   \n",
            "9                                           0.834007   \n",
            "10                                         -1.572767   \n",
            "11                                         -0.876429   \n",
            "12                                          2.467155   \n",
            "13                                          0.151932   \n",
            "14                                         -0.786501   \n",
            "15                                         -0.550219   \n",
            "16                                          1.716613   \n",
            "17                                          0.761713   \n",
            "18                                         -0.660248   \n",
            "19                                         -0.189558   \n",
            "20                                         -0.351807   \n",
            "21                                         -0.971909   \n",
            "22                                          0.564843   \n",
            "23                                         -0.412373   \n",
            "24                                         -0.002680   \n",
            "25                                         -0.300933   \n",
            "26                                          2.090957   \n",
            "27                                          0.303260   \n",
            "28                                         -0.913818   \n",
            "29                                         -0.562940   \n",
            "30                                         -0.276809   \n",
            "31                                         -0.473675   \n",
            "32                                         -0.865896   \n",
            "33                                         -1.310228   \n",
            "34                                         -0.498307   \n",
            "35                                         -0.546705   \n",
            "36                                          1.519347   \n",
            "37                                         -0.929976   \n",
            "38                                         -0.440363   \n",
            "39                                          1.120335   \n",
            "40                                          1.914399   \n",
            "41                                          0.374798   \n",
            "42                                          0.143126   \n",
            "43                                         -1.477801   \n",
            "44                                          1.107647   \n",
            "45                                          1.078258   \n",
            "46                                         -0.512649   \n",
            "47                                          1.891874   \n",
            "48                                          1.429653   \n",
            "49                                          0.913899   \n",
            "50                                         -0.231921   \n",
            "51                                         -0.239433   \n",
            "52                                         -0.535980   \n",
            "53                                         -0.490718   \n",
            "54                                          1.637327   \n",
            "55                                          2.117460   \n",
            "56                                         -0.531648   \n",
            "57                                          0.281903   \n",
            "58                                         -0.763511   \n",
            "59                                          1.475675   \n",
            "60                                         -0.914333   \n",
            "61                                         -0.189251   \n",
            "62                                          0.842254   \n",
            "63                                         -0.074939   \n",
            "64                                         -0.619983   \n",
            "65                                         -0.404020   \n",
            "66                                         -0.663428   \n",
            "67                                         -1.581542   \n",
            "68                                         -1.100577   \n",
            "69                                         -1.794517   \n",
            "70                                          0.167767   \n",
            "71                                          0.910799   \n",
            "72                                         -1.246953   \n",
            "73                                         -0.351099   \n",
            "74                                         -0.250768   \n",
            "75                                         -0.413002   \n",
            "76                                         -0.519910   \n",
            "77                                         -0.750480   \n",
            "78                                         -0.870781   \n",
            "79                                         -0.194487   \n",
            "80                                          0.711240   \n",
            "81                                          0.161407   \n",
            "82                                         -0.928120   \n",
            "83                                          0.531624   \n",
            "84                                         -0.148517   \n",
            "85                                         -1.295543   \n",
            "\n",
            "    PREDICT_original_phasef_phasesym_quartile_range_WL3_N5  \n",
            "0                                           -0.096208       \n",
            "1                                           -1.492496       \n",
            "2                                           -1.492496       \n",
            "3                                           -0.003073       \n",
            "4                                            0.865064       \n",
            "5                                           -1.067743       \n",
            "6                                           -0.643037       \n",
            "7                                            0.918050       \n",
            "8                                            0.450010       \n",
            "9                                           -1.067590       \n",
            "10                                           1.347448       \n",
            "11                                           0.793255       \n",
            "12                                          -1.492496       \n",
            "13                                          -0.510471       \n",
            "14                                           0.855128       \n",
            "15                                           0.484987       \n",
            "16                                          -1.486363       \n",
            "17                                          -1.013716       \n",
            "18                                           0.641978       \n",
            "19                                           0.054207       \n",
            "20                                           0.104849       \n",
            "21                                           1.054026       \n",
            "22                                          -0.745924       \n",
            "23                                           0.167697       \n",
            "24                                          -0.339516       \n",
            "25                                           0.122343       \n",
            "26                                          -1.492496       \n",
            "27                                          -0.449004       \n",
            "28                                           1.340663       \n",
            "29                                           0.466147       \n",
            "30                                           0.153516       \n",
            "31                                           0.408199       \n",
            "32                                           1.121529       \n",
            "33                                           1.513981       \n",
            "34                                           0.657045       \n",
            "35                                           0.327262       \n",
            "36                                          -1.492496       \n",
            "37                                           1.020723       \n",
            "38                                           0.227910       \n",
            "39                                          -1.367573       \n",
            "40                                          -1.492496       \n",
            "41                                          -0.584927       \n",
            "42                                          -0.394253       \n",
            "43                                           2.062581       \n",
            "44                                          -1.401219       \n",
            "45                                          -1.209730       \n",
            "46                                           0.432040       \n",
            "47                                          -1.492496       \n",
            "48                                          -1.482231       \n",
            "49                                          -0.989046       \n",
            "50                                           0.233408       \n",
            "51                                          -0.088044       \n",
            "52                                           0.486185       \n",
            "53                                           0.657904       \n",
            "54                                          -1.492496       \n",
            "55                                          -1.492496       \n",
            "56                                           0.243380       \n",
            "57                                          -0.547725       \n",
            "58                                           0.677521       \n",
            "59                                          -1.492496       \n",
            "60                                           1.027256       \n",
            "61                                          -0.225984       \n",
            "62                                          -0.937987       \n",
            "63                                          -0.265905       \n",
            "64                                           0.515561       \n",
            "65                                           0.265374       \n",
            "66                                           0.515104       \n",
            "67                                           2.651251       \n",
            "68                                           1.492129       \n",
            "69                                           1.962284       \n",
            "70                                          -0.414393       \n",
            "71                                          -1.157520       \n",
            "72                                           1.572181       \n",
            "73                                           0.495510       \n",
            "74                                           0.073398       \n",
            "75                                           0.256891       \n",
            "76                                           0.427560       \n",
            "77                                           0.974156       \n",
            "78                                           0.473341       \n",
            "79                                           0.040868       \n",
            "80                                          -0.925410       \n",
            "81                                          -0.232611       \n",
            "82                                           1.339412       \n",
            "83                                          -0.849066       \n",
            "84                                          -0.174832       \n",
            "85                                           1.624750       \n",
            "\n",
            "[86 rows x 78 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [ 81  82  87  91  96 100] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
            "  f = msb / msw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "xOOLNJnlfLbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = decomposition.PCA()\n",
        "pca.fit(X_train_ANOVA)\n",
        "X_pca = pca.transform(X_train_ANOVA)\n",
        "\n",
        "component = 0\n",
        "total_ratio = 0\n",
        "while total_ratio < 0.95:\n",
        "    total_ratio += pca.explained_variance_ratio_[component]\n",
        "    component+=1\n",
        "\n",
        "component2=0\n",
        "while pca.explained_variance_ratio_[component2] > 0.001:\n",
        "    component2+=1\n",
        "\n",
        "print(component)\n",
        "print(component2)\n",
        "X_pca = X_pca[:,0:component]"
      ],
      "metadata": {
        "id": "dU9UMzbtfNTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06022570-9557-4fad-ba0e-b2cfc0bbd66e"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiatie classifiers"
      ],
      "metadata": {
        "id": "HxaOPXkpeOE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clsfs = list()\n",
        "scoring = make_scorer(custom_score)"
      ],
      "metadata": {
        "id": "tuwH6BJ7eNf2"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Classification"
      ],
      "metadata": {
        "id": "i0cKvUmo2Uzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the best hyperparameters and fit\n",
        "LDA_classifier = LinearDiscriminantAnalysis()\n",
        "LDA_classifier.fit(X_pca, y_train)\n",
        "clsfs.append(LDA_classifier)"
      ],
      "metadata": {
        "id": "rjbhcmWJcG0L"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quadratic Discriminant Analysis"
      ],
      "metadata": {
        "id": "5pFcjNm_2ww9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set parameters\n",
        "parameters = {'reg_param': np.arange(0, 1, 0.1)}\n",
        "\n",
        "# Specify the cross validation method to use, we use 10-fold stratified cross-validation\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# Create QDA object\n",
        "qda = model_selection.RandomizedSearchCV(QuadraticDiscriminantAnalysis(), parameters, n_iter=11,\n",
        "                                   cv=cv_10fold, scoring=scoring)\n",
        "\n",
        "# Do the search\n",
        "qda.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "qda_df = pd.DataFrame(qda.cv_results_)\n",
        "display(qda_df)\n",
        "\n",
        "# Extract the best hyperparameters and fit\n",
        "QDA_classifier = qda.best_estimator_\n",
        "QDA_classifier.fit(X_pca, y_train)\n",
        "clsfs.append(QDA_classifier)\n",
        "\n",
        "# Whole search\n",
        "# y_pred  = qda.predict(X_pca)\n",
        "\n"
      ],
      "metadata": {
        "id": "K9MLj58j2zkJ",
        "outputId": "be3797b6-e2e8-40e7-8dfc-b0f390480c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py:305: UserWarning: The total space of parameters 10 is smaller than n_iter=11. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0       0.001634      0.000511         0.004829        0.003251   \n",
              "1       0.001028      0.000112         0.001710        0.000043   \n",
              "2       0.001337      0.000386         0.002265        0.000594   \n",
              "3       0.001375      0.000488         0.002187        0.000484   \n",
              "4       0.001253      0.000287         0.002121        0.000396   \n",
              "5       0.001007      0.000027         0.001864        0.000250   \n",
              "6       0.001007      0.000040         0.001783        0.000155   \n",
              "7       0.001029      0.000065         0.001743        0.000061   \n",
              "8       0.001384      0.000446         0.002363        0.000720   \n",
              "9       0.001019      0.000035         0.001734        0.000034   \n",
              "\n",
              "  param_reg_param                              params  split0_test_score  \\\n",
              "0             0.0                  {'reg_param': 0.0}           0.776386   \n",
              "1             0.1                  {'reg_param': 0.1}           0.776386   \n",
              "2             0.2                  {'reg_param': 0.2}           0.776386   \n",
              "3             0.3  {'reg_param': 0.30000000000000004}           0.776386   \n",
              "4             0.4                  {'reg_param': 0.4}           0.776386   \n",
              "5             0.5                  {'reg_param': 0.5}           0.776386   \n",
              "6             0.6   {'reg_param': 0.6000000000000001}           0.776386   \n",
              "7             0.7   {'reg_param': 0.7000000000000001}           0.776386   \n",
              "8             0.8                  {'reg_param': 0.8}           0.776386   \n",
              "9             0.9                  {'reg_param': 0.9}           0.776386   \n",
              "\n",
              "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
              "0           0.565111           0.776386           0.565111           0.670807   \n",
              "1           0.670807           0.776386           0.670807           0.670807   \n",
              "2           0.670807           0.670807           0.670807           0.670807   \n",
              "3           0.776386           0.552764           0.670807           0.670807   \n",
              "4           0.776386           0.552764           0.670807           0.670807   \n",
              "5           0.776386           0.434505           0.776386           0.658228   \n",
              "6           0.776386           0.539846           0.881890           0.658228   \n",
              "7           0.670807           0.539846           0.881890           0.658228   \n",
              "8           0.670807           0.539846           0.881890           0.658228   \n",
              "9           0.670807           0.539846           0.881890           0.658228   \n",
              "\n",
              "   split5_test_score  split6_test_score  split7_test_score  split8_test_score  \\\n",
              "0           0.788732              0.625              0.875              0.625   \n",
              "1           0.788732              0.750              0.875              0.625   \n",
              "2           0.788732              0.750              0.875              0.625   \n",
              "3           0.788732              0.750              0.875              0.625   \n",
              "4           0.788732              0.750              0.875              0.625   \n",
              "5           0.788732              0.750              0.750              0.500   \n",
              "6           0.788732              0.875              0.750              0.750   \n",
              "7           0.788732              0.875              0.750              0.750   \n",
              "8           0.788732              0.750              0.750              0.875   \n",
              "9           0.788732              0.750              0.750              0.875   \n",
              "\n",
              "   split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
              "0              0.625         0.689253        0.101553               10  \n",
              "1              0.625         0.722893        0.078252                7  \n",
              "2              0.625         0.712335        0.077441                8  \n",
              "3              0.750         0.723588        0.088663                5  \n",
              "4              0.750         0.723588        0.088663                5  \n",
              "5              0.750         0.696062        0.120398                9  \n",
              "6              0.625         0.742147        0.101739                1  \n",
              "7              0.625         0.731589        0.103107                2  \n",
              "8              0.625         0.731589        0.103107                2  \n",
              "9              0.625         0.731589        0.103107                2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-492a47af-51c8-4214-988d-61a6d29865be\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_reg_param</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001634</td>\n",
              "      <td>0.000511</td>\n",
              "      <td>0.004829</td>\n",
              "      <td>0.003251</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'reg_param': 0.0}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.565111</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.565111</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.689253</td>\n",
              "      <td>0.101553</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001028</td>\n",
              "      <td>0.000112</td>\n",
              "      <td>0.001710</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'reg_param': 0.1}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.722893</td>\n",
              "      <td>0.078252</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001337</td>\n",
              "      <td>0.000386</td>\n",
              "      <td>0.002265</td>\n",
              "      <td>0.000594</td>\n",
              "      <td>0.2</td>\n",
              "      <td>{'reg_param': 0.2}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.712335</td>\n",
              "      <td>0.077441</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001375</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.002187</td>\n",
              "      <td>0.000484</td>\n",
              "      <td>0.3</td>\n",
              "      <td>{'reg_param': 0.30000000000000004}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.552764</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.723588</td>\n",
              "      <td>0.088663</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001253</td>\n",
              "      <td>0.000287</td>\n",
              "      <td>0.002121</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.4</td>\n",
              "      <td>{'reg_param': 0.4}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.552764</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.723588</td>\n",
              "      <td>0.088663</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.001007</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>0.001864</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>0.5</td>\n",
              "      <td>{'reg_param': 0.5}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.434505</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.658228</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.696062</td>\n",
              "      <td>0.120398</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.001007</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'reg_param': 0.6000000000000001}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.539846</td>\n",
              "      <td>0.881890</td>\n",
              "      <td>0.658228</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.742147</td>\n",
              "      <td>0.101739</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.001029</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.001743</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>0.7</td>\n",
              "      <td>{'reg_param': 0.7000000000000001}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.539846</td>\n",
              "      <td>0.881890</td>\n",
              "      <td>0.658228</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.731589</td>\n",
              "      <td>0.103107</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001384</td>\n",
              "      <td>0.000446</td>\n",
              "      <td>0.002363</td>\n",
              "      <td>0.000720</td>\n",
              "      <td>0.8</td>\n",
              "      <td>{'reg_param': 0.8}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.539846</td>\n",
              "      <td>0.881890</td>\n",
              "      <td>0.658228</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.731589</td>\n",
              "      <td>0.103107</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.001019</td>\n",
              "      <td>0.000035</td>\n",
              "      <td>0.001734</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.9</td>\n",
              "      <td>{'reg_param': 0.9}</td>\n",
              "      <td>0.776386</td>\n",
              "      <td>0.670807</td>\n",
              "      <td>0.539846</td>\n",
              "      <td>0.881890</td>\n",
              "      <td>0.658228</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.731589</td>\n",
              "      <td>0.103107</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-492a47af-51c8-4214-988d-61a6d29865be')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-492a47af-51c8-4214-988d-61a6d29865be button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-492a47af-51c8-4214-988d-61a6d29865be');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-NN"
      ],
      "metadata": {
        "id": "xdjw0bA9zOle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "# Specify the search range, this could be multiple parameters for more complex classifiers\n",
        "parameters = {'n_neighbors': randint(1, 6),\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'p': randint(1, 5),\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "\n",
        "# Specify the cross validation method to use, we use 10-fold stratified cross-validation\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# Create the grid search method, use area under ROC curve as scoring metric\n",
        "# Too learn more about metrics see: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "clf = model_selection.RandomizedSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=cv_10fold, n_iter=500, scoring=scoring)\n",
        "\n",
        "# Do the entire search\n",
        "clf.fit(X_pca, y_train)\n",
        "print(\"type = \", type(clf))\n",
        "print(clf.best_estimator_)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "# Extract the best k \n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "# optimal_k = clf_df['param_n_neighbors'].iloc[0]\n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)\n",
        "\n",
        "# Extract the best hyperparameters and fit\n",
        "knn_classifier = clf.best_estimator_\n",
        "knn_classifier.fit(X_pca, y_train)\n",
        "clsfs.append(knn_classifier)"
      ],
      "metadata": {
        "id": "F2Mc-n3yzRIP",
        "outputId": "3a84d70f-42e9-4d33-d322-33fa4eda2c0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type =  <class 'sklearn.model_selection._search.RandomizedSearchCV'>\n",
            "KNeighborsClassifier(algorithm='kd_tree')\n",
            "{'algorithm': 'kd_tree', 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
            "0.7684445896093642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gedoe"
      ],
      "metadata": {
        "id": "tgHdHwpHUaXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The scorers can be either one of the predefined metric strings or a scorer\n",
        "# callable, like the one returned by make_scorer\n",
        "scoring = {\"accuracy\": \"accuracy\", \"recall\": \"recall\"}\n",
        "\n",
        "# Setting refit='AUC', refits an estimator on the whole dataset with the\n",
        "# parameter setting that has the best cross-validated AUC score.\n",
        "# That estimator is made available at ``gs.best_estimator_`` along with\n",
        "# parameters like ``gs.best_score_``, ``gs.best_params_`` and\n",
        "# ``gs.best_index_``\n",
        "# gs = model_selection.RandomizedSearchCV(\n",
        "#     neighbors.KNeighborsClassifier(),parameters,\n",
        "#     scoring=[\"accuracy\", \"recall\"],\n",
        "#     refit=\"accuracy\",\n",
        "#     n_jobs=2,\n",
        "#     return_train_score=True,\n",
        "# )\n",
        "\n",
        "gs = model_selection.RandomizedSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=cv_10fold, n_iter=200, scoring=scoring, refit='accuracy')\n",
        "gs.fit(X, y)\n",
        "results = gs.cv_results_"
      ],
      "metadata": {
        "id": "7uWCcpOKUZpP",
        "outputId": "6c1c6d4e-1c09-4731-90cb-b573e14a3670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'predict'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-f0b4db0c9c38>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_10fold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1769\u001b[0m             ParameterSampler(\n\u001b[1;32m   1770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[1;32m    765\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MultimetricScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    274\u001b[0m         \"\"\"\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod_caller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             return self._sign * self._score_func(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(cache, estimator, method, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    804\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_precomputed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mn_samples_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples_fit_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# error message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mfirst_pass_isfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst_pass_isfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sum_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m def sum(a, axis=None, dtype=None, out=None, keepdims=np._NoValue,\n\u001b[1;32m   2162\u001b[0m         initial=np._NoValue, where=np._NoValue):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(results.keys())\n",
        "\n",
        "plt.figure(figsize=(13, 13))\n",
        "plt.title(\"GridSearchCV evaluating using multiple scorers simultaneously\", fontsize=16)\n",
        "\n",
        "plt.xlabel(\"n_neighbors\")\n",
        "plt.ylabel(\"Score\")\n",
        "\n",
        "ax = plt.gca()\n",
        "# ax.set_xlim(0, 402)\n",
        "# ax.set_ylim(0.73, 1)\n",
        "\n",
        "# Get the regular numpy array from the MaskedArray\n",
        "X_axis = np.array(results[\"param_n_neighbors\"].data, dtype=float)\n",
        "\n",
        "for scorer, color in zip(sorted(scoring), [\"g\", \"k\"]):\n",
        "    sample = \"test\"\n",
        "    style = \"-\"\n",
        "    # for sample, style in ((\"test\", \"-\")):\n",
        "    sample_score_mean = results[\"mean_%s_%s\" % (sample, scorer)]\n",
        "    sample_score_std = results[\"std_%s_%s\" % (sample, scorer)]\n",
        "    ax.fill_between(\n",
        "        X_axis,\n",
        "        sample_score_mean - sample_score_std,\n",
        "        sample_score_mean + sample_score_std,\n",
        "        alpha=0.1 if sample == \"test\" else 0,\n",
        "        color=color,\n",
        "    )\n",
        "    ax.plot(\n",
        "        X_axis,\n",
        "        sample_score_mean,\n",
        "        style,\n",
        "        color=color,\n",
        "        alpha=1 if sample == \"test\" else 0.7,\n",
        "        label=\"%s (%s)\" % (scorer, sample),\n",
        "    )\n",
        "\n",
        "    best_index = np.nonzero(results[\"rank_test_%s\" % scorer] == 1)[0][0]\n",
        "    best_score = results[\"mean_test_%s\" % scorer][best_index]\n",
        "\n",
        "    # Plot a dotted vertical line at the best score for that scorer marked by x\n",
        "    ax.plot(\n",
        "        [\n",
        "            X_axis[best_index],\n",
        "        ]\n",
        "        * 2,\n",
        "        [0, best_score],\n",
        "        linestyle=\"-.\",\n",
        "        color=color,\n",
        "        marker=\"x\",\n",
        "        markeredgewidth=3,\n",
        "        ms=8,\n",
        "    )\n",
        "\n",
        "    # Annotate the best score for that scorer\n",
        "    ax.annotate(\"%0.2f\" % best_score, (X_axis[best_index], best_score + 0.005))\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ruk4lEhQV6kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "u_79CKvDLR_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'n_estimators': np.arange(50, 400, 50),\n",
        "              'max_depth': [5, 10, 15],\n",
        "              'min_samples_leaf':[2,4]}\n",
        "\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "clf = model_selection.RandomizedSearchCV(RandomForestRegressor(), parameters, cv=cv_10fold, n_iter=40, scoring=scoring)\n",
        "    \n",
        "# Fit the classifier\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)\n",
        "\n",
        "# Extract the best hyperparameters and fit\n",
        "RF_classifier = clf.best_estimator_\n",
        "RF_classifier.fit(X_pca, y_train)\n",
        "clsfs.append(RF_classifier)\n"
      ],
      "metadata": {
        "id": "rpwtmKvoLTjD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "L4WjL4FH1zT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "_O8fWaFjCSl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'C': loguniform(0.1, 100),\n",
        "              'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
        "              'degree': randint(1, 5),\n",
        "              'gamma': loguniform(1e-4, 1),\n",
        "              'class_weight':['balanced', None]}\n",
        " \n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "clf = model_selection.RandomizedSearchCV(SVC(), parameters, cv=cv_10fold, n_iter=500, scoring=scoring)\n",
        "\n",
        "# Do the entire search\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "print(clf.best_score_)\n",
        "print(clf.best_params_)\n",
        "\n",
        "# Extract the best hyperparameters and fit\n",
        "svm_classifier = clf.best_estimator_\n",
        "svm_classifier.fit(X_pca, y_train)\n",
        "clsfs.append(svm_classifier)\n"
      ],
      "metadata": {
        "id": "5MwjArCFCZmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(clf_df)"
      ],
      "metadata": {
        "id": "nZYvaxx6HvgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning curves"
      ],
      "metadata": {
        "id": "0L14bXT1R6sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(24,10))\n",
        "num = 0\n",
        "for clf in clsfs:\n",
        "    num +=1\n",
        "    ax = fig.add_subplot(2, 3, num)\n",
        "    title = str(type(clf))\n",
        "    plot_learning_curve(clf, title, X_pca, y_train, ax, ylim=(0.3, 1.01), cv=10)\n"
      ],
      "metadata": {
        "id": "1nBrCgircqK1"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}