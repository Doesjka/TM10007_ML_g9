{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "ede704ee-ec32-4fe2-cf11-7b587ac2be9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TM10007_ML_g9' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!git clone https://github.com/Doesjka/TM10007_ML_g9.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import packages"
      ],
      "metadata": {
        "id": "iq6XRc6xuYcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn import decomposition\n",
        "from sklearn import metrics\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import randint\n"
      ],
      "metadata": {
        "id": "ZGpTRjZRudnE"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define functions"
      ],
      "metadata": {
        "id": "4Eqq7xOFueaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(estimator, title, X, y, axes, ylim=None, cv=None,\n",
        "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Generate 3 plots: the test and training learning curve, the training\n",
        "    samples vs fit times curve, the fit times vs score curve.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
        "        An object of that type which is cloned for each validation.\n",
        "\n",
        "    title : string\n",
        "        Title for the chart.\n",
        "\n",
        "    X : array-like, shape (n_samples, n_features)\n",
        "        Training vector, where n_samples is the number of samples and\n",
        "        n_features is the number of features.\n",
        "\n",
        "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
        "        Target relative to X for classification or regression;\n",
        "        None for unsupervised learning.\n",
        "\n",
        "    axes : array of 3 axes, optional (default=None)\n",
        "        Axes to use for plotting the curves.\n",
        "\n",
        "    ylim : tuple, shape (ymin, ymax), optional\n",
        "        Defines minimum and maximum yvalues plotted.\n",
        "\n",
        "    cv : int, cross-validation generator or an iterable, optional\n",
        "        Determines the cross-validation splitting strategy.\n",
        "        Possible inputs for cv are:\n",
        "          - None, to use the default 5-fold cross-validation,\n",
        "          - integer, to specify the number of folds.\n",
        "          - :term:`CV splitter`,\n",
        "          - An iterable yielding (train, test) splits as arrays of indices.\n",
        "\n",
        "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
        "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
        "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
        "\n",
        "        Refer :ref:`User Guide <cross_validation>` for the various\n",
        "        cross-validators that can be used here.\n",
        "\n",
        "    n_jobs : int or None, optional (default=None)\n",
        "        Number of jobs to run in parallel.\n",
        "        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
        "        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
        "        for more details.\n",
        "\n",
        "    train_sizes : array-like, shape (n_ticks,), dtype float or int\n",
        "        Relative or absolute numbers of training examples that will be used to\n",
        "        generate the learning curve. If the dtype is float, it is regarded as a\n",
        "        fraction of the maximum size of the training set (that is determined\n",
        "        by the selected validation method), i.e. it has to be within (0, 1].\n",
        "        Otherwise it is interpreted as absolute sizes of the training sets.\n",
        "        Note that for classification the number of samples usually have to\n",
        "        be big enough to contain at least one sample from each class.\n",
        "        (default: np.linspace(0.1, 1.0, 5))\n",
        "    \"\"\"\n",
        "\n",
        "    axes.set_title(title)\n",
        "    if ylim is not None:\n",
        "        axes.set_ylim(*ylim)\n",
        "    axes.set_xlabel(\"Training examples\")\n",
        "    axes.set_ylabel(\"Score\")\n",
        "\n",
        "    train_sizes, train_scores, test_scores  = \\\n",
        "        model_selection.learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
        "                       train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    print(train_sizes, train_scores, test_scores)\n",
        "\n",
        "    # Plot learning curve\n",
        "    axes.grid()\n",
        "    axes.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                         train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                         color=\"r\")\n",
        "    axes.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                         test_scores_mean + test_scores_std, alpha=0.1,\n",
        "                         color=\"g\")\n",
        "    axes.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "                 label=\"Training score\")\n",
        "    axes.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "                 label=\"Cross-validation score\")\n",
        "    axes.legend(loc=\"best\")\n",
        "\n",
        "    return plt"
      ],
      "metadata": {
        "id": "NJtv5_0TuhEz"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEUJUe8plrxC"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "3dee60aa-2c96-4bad-ca2f-4be8d0529358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 115\n",
            "The number of columns: 494\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/TM10007_ML_g9/worclipo/Lipo_radiomicFeatures.csv', index_col=0)\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data in train and test set\n"
      ],
      "metadata": {
        "id": "LHslq_ZZZbW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['label']\n",
        "X = data.drop('label', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "P8f1SNKeZaB7"
      },
      "execution_count": 267,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling missing data \n",
        "### Throwing out features\n",
        "All features that exist of at least 50% zeros are deleted from the data. \n"
      ],
      "metadata": {
        "id": "gJLsBPlTZwAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = (X_train == 0).sum()\n",
        "threshold = 0.5 * len(y_train)\n",
        "print('Threshold = ', threshold)\n",
        "feature_del = zeros[zeros > threshold]\n",
        "\n",
        "X_train = X_train.drop(columns=feature_del.index)\n",
        "print(f'{len(data.columns)-len(X_train.columns)} features were deleted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWcI7Y3g7eDk",
        "outputId": "f8854507-5fe2-447a-e0b4-41e94bf3c196"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  43.0\n",
            "25 features were deleted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "more_zeros = (X_train == 0).sum()\n",
        "columns_zeros = more_zeros[more_zeros > 0].index\n",
        "print(f'Of the remaining features, {len(columns_zeros)} features have at least one zero')\n",
        "print(f'There is a total of {more_zeros.sum()} zeros left in the data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuoOrHuMAsFY",
        "outputId": "9c7d0d82-bdbd-442c-9dfd-f5d8c3ad5395"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of the remaining features, 10 features have at least one zero\n",
            "There is a total of 44 zeros left in the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate number of missing values per sample"
      ],
      "metadata": {
        "id": "pkM1c0vkq1YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_r = (X_train == 0).sum(axis=1)\n",
        "threshold = 0.005 * X_train.size / len(y_train)\n",
        "print('Threshold = ', threshold)\n",
        "feature_del = zeros_r[zeros_r > threshold]\n",
        "print(feature_del)"
      ],
      "metadata": {
        "id": "4gHFgkGMm3Nm",
        "outputId": "b7f1ee4f-117e-4243-82e4-f85c149c1b52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  2.345\n",
            "ID\n",
            "Lipo-090_0    5\n",
            "Lipo-095_0    3\n",
            "Lipo-076_0    3\n",
            "Lipo-003_0    3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aantal_normaal = 0\n",
        "\n",
        "for column in X_train.columns:\n",
        "    result = stats.shapiro(X_train[column])\n",
        "    # print(result.pvalue)\n",
        "    normaal = result.pvalue > 0.05\n",
        "    aantal_normaal += normaal\n",
        "    \n",
        "print(aantal_normaal, \" features zijn normaal verdeeld.\")"
      ],
      "metadata": {
        "id": "XKxZ6YRnm3Xr",
        "outputId": "9c71fb8c-7e92-472d-b2c6-f6049d319f8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74  features zijn normaal verdeeld.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/scipy/stats/_morestats.py:1813: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
            "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filling remaining zeros\n",
        "All remaining zeros are replaced by the mean of that feature. "
      ],
      "metadata": {
        "id": "KwXkbuDYqhoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mean = X_train\n",
        "X_train_median = X_train\n",
        "\n",
        "for column in columns_zeros[:]:\n",
        "    print('Kolom: ', column)\n",
        "    column_mean = X_train.loc[X_train[column]!=0, column].mean()\n",
        "    column_median = X_train.loc[X_train[column]!=0, column].median()\n",
        "    print('mean = ', column_mean)\n",
        "    print('median = ', column_median)\n",
        "\n",
        "    verschil2_percolumn = column_mean - column_median\n",
        "    print('Verschil tussen mean en median = ',verschil2_percolumn)\n",
        "\n",
        "    print('p-waarde normaalverdeling = ', stats.shapiro(X_train.loc[X_train[column]!=0, column]).pvalue)\n",
        "    print(' ')\n",
        "\n",
        "    X_train_mean[column].replace(0, column_mean)\n",
        "    X_train_median[column].replace(0, column_median)\n",
        "\n",
        "\n",
        "verschil = abs(X_train_mean - X_train_median)\n",
        "print('Totaal verschil = ', verschil.sum().sum())\n",
        "\n",
        "# We gaan voor de median\n",
        "X_train = X_train_median"
      ],
      "metadata": {
        "id": "EQudKLJth0sz",
        "outputId": "f1066527-ec72-482a-8997-3fc0f8cd08ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kolom:  PREDICT_original_sf_area_min_2.5D\n",
            "mean =  456.8698899846219\n",
            "median =  200.39520811289555\n",
            "Verschil tussen mean en median =  256.4746818717264\n",
            "p-waarde normaalverdeling =  3.05788068477586e-11\n",
            " \n",
            "Kolom:  PREDICT_original_tf_LBP_quartile_range_R8_P24\n",
            "mean =  9.301204819277109\n",
            "median =  11.0\n",
            "Verschil tussen mean en median =  -1.6987951807228914\n",
            "p-waarde normaalverdeling =  1.931198130478151e-05\n",
            " \n",
            "Kolom:  PREDICT_original_vf_Frangi_full_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "mean =  2.766293780856362e-07\n",
            "median =  4.602205232532876e-10\n",
            "Verschil tussen mean en median =  2.7616915756238295e-07\n",
            "p-waarde normaalverdeling =  9.707482768662333e-20\n",
            " \n",
            "Kolom:  PREDICT_original_vf_Frangi_edge_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "mean =  2.766293780856362e-07\n",
            "median =  4.602205232532876e-10\n",
            "Verschil tussen mean en median =  2.7616915756238295e-07\n",
            "p-waarde normaalverdeling =  9.707482768662333e-20\n",
            " \n",
            "Kolom:  PREDICT_original_vf_Frangi_inner_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "mean =  8.705055316112096e-08\n",
            "median =  3.671477515859718e-10\n",
            "Verschil tussen mean en median =  8.668340540953499e-08\n",
            "p-waarde normaalverdeling =  1.273425812214633e-19\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_monogenic_min_WL3_N5\n",
            "mean =  3.8185714285714285\n",
            "median =  3.0\n",
            "Verschil tussen mean en median =  0.8185714285714285\n",
            "p-waarde normaalverdeling =  4.080578648417432e-13\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_monogenic_peak_WL3_N5\n",
            "mean =  89.4116049382716\n",
            "median =  89.5\n",
            "Verschil tussen mean en median =  -0.08839506172840572\n",
            "p-waarde normaalverdeling =  0.0007248687325045466\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_monogenic_peak_position_WL3_N5\n",
            "mean =  24.97530864197531\n",
            "median =  25.0\n",
            "Verschil tussen mean en median =  -0.02469135802468969\n",
            "p-waarde normaalverdeling =  0.0007248687325045466\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_phasecong_quartile_range_WL3_N5\n",
            "mean =  0.029046637777023623\n",
            "median =  0.0166127963783\n",
            "Verschil tussen mean en median =  0.012433841398723621\n",
            "p-waarde normaalverdeling =  1.7549460148980067e-12\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_phasesym_quartile_range_WL3_N5\n",
            "mean =  0.20900926663690383\n",
            "median =  0.21420864221841113\n",
            "Verschil tussen mean en median =  -0.005199375581507293\n",
            "p-waarde normaalverdeling =  0.5642579197883606\n",
            " \n",
            "Totaal verschil =  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outliers eruit halen\n"
      ],
      "metadata": {
        "id": "Fui0tjwlW_9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Z_score = X_train.apply(stats.zscore)\n",
        "outliers_per_column = (np.abs(Z_score) > 3).sum()\n",
        "# outliers_per_row = (np.abs(Z_score) > 3).sum(axis=1)\n",
        "outliers_total = outliers_per_column.sum()\n",
        "columns_outliers = outliers_per_column[outliers_per_column > 0].index\n",
        "\n",
        "print(\"Het totaal aantal outliers in de data is \", outliers_total)\n",
        "\n",
        "for column in columns_outliers:\n",
        "    column_plus_3 = X_train[column].mean() + 3 * X_train[column].std()\n",
        "    column_min_3 = X_train[column].mean() - 3 * X_train[column].std()\n",
        "\n",
        "    X_train.loc[Z_score[column] > 3, column] = column_plus_3\n",
        "    X_train.loc[Z_score[column] < -3, column] = column_min_3\n",
        "\n",
        "    test2p = (X_train[column] > column_plus_3).sum()\n",
        "    test2m = (X_train[column] < column_min_3).sum()\n",
        "    # print(test2p, \" en \", test2m)\n",
        "\n",
        "print(\"De outliers zijn nu vervangen.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik_99Td7XECw",
        "outputId": "1ee73e74-0f1c-45f9-ebd8-abd942af6b9c"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Het totaal aantal outliers in de data is  601\n",
            "De outliers zijn nu vervangen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling"
      ],
      "metadata": {
        "id": "YQtVjjF2dX77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler().fit(X_train_median)\n",
        "X_train_scaled = scaler.transform(X_train_median)\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_median.columns)"
      ],
      "metadata": {
        "id": "iXgA9qGcc2eH"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "xOOLNJnlfLbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = decomposition.PCA()\n",
        "pca.fit(X_train_scaled_df)\n",
        "X_pca = pca.transform(X_train_scaled_df)\n",
        "\n",
        "component=0\n",
        "total_ratio = 0\n",
        "while total_ratio < 0.95:\n",
        "    total_ratio += pca.explained_variance_ratio_[component]\n",
        "    component+=1\n",
        "\n",
        "X_pca = X_pca[:,0:component]\n",
        "print(component)\n",
        "\n",
        "component2=0\n",
        "while pca.explained_variance_ratio_[component2] > 0.001:\n",
        "    component2+=1\n",
        "\n",
        "print(component2)"
      ],
      "metadata": {
        "id": "dU9UMzbtfNTE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af36da6-879a-4ee8-f0c8-e01f99313aa9"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "60\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Classification"
      ],
      "metadata": {
        "id": "i0cKvUmo2Uzj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set parameters\n",
        "parameters = {}\n",
        "\n",
        "# Specify the cross validation method to use, we use 10-fold stratified cross-validation\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# Create QDA object\n",
        "lda = model_selection.GridSearchCV(LinearDiscriminantAnalysis(), parameters, cv=cv_10fold, scoring='accuracy')\n",
        "\n",
        "# Fit the classifier\n",
        "lda.fit(X_pca, y_train)\n",
        "\n",
        "# Whole search\n",
        "y_pred  = lda.predict(X_pca)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "lda_df = pd.DataFrame(lda.cv_results_)\n",
        "display(lda_df)\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "lda.best_params_\n",
        "\n",
        "# Calculate AUC-score\n",
        "#if hasattr(lda, 'predict_proba'):\n",
        "#  y_score = lda.predict_proba(X_pca)[:, 1]\n",
        "#else:\n",
        "#  y_score = y_pred\n",
        "#auc=metrics.roc_auc_score(y_train, y_score)\n",
        "\n",
        "# Print\n",
        "#print(f'The AUC is {auc}')\n",
        "#print('Number of mislabeled points out of a total %d points : %d' % (X_pca.shape[0], (y_train != y_pred).sum()))\n",
        "#print(\"\\nThe Accuracy of our linear classifier is:\", metrics.accuracy_score(y_train, y_pred)*100)"
      ],
      "metadata": {
        "id": "TN9dumKg2ZJV",
        "outputId": "6face631-35f4-4e37-cc7f-5c1f7f7b8710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   mean_fit_time  std_fit_time  mean_score_time  std_score_time params  \\\n",
              "0       0.009215       0.00156         0.001691        0.000885     {}   \n",
              "\n",
              "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
              "0           0.555556           0.888889           0.333333           0.888889   \n",
              "\n",
              "   split4_test_score  split5_test_score  split6_test_score  split7_test_score  \\\n",
              "0           0.666667           0.333333              0.875                0.5   \n",
              "\n",
              "   split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
              "0              0.625                0.5         0.616667        0.202244   \n",
              "\n",
              "   rank_test_score  \n",
              "0                1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8329f40-c9e2-4766-8b71-5d0b0bf2ac20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009215</td>\n",
              "      <td>0.00156</td>\n",
              "      <td>0.001691</td>\n",
              "      <td>0.000885</td>\n",
              "      <td>{}</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.616667</td>\n",
              "      <td>0.202244</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8329f40-c9e2-4766-8b71-5d0b0bf2ac20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8329f40-c9e2-4766-8b71-5d0b0bf2ac20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8329f40-c9e2-4766-8b71-5d0b0bf2ac20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quadratic Discriminant Analysis"
      ],
      "metadata": {
        "id": "5pFcjNm_2ww9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set regularization parameter\n",
        "reg_param=[]\n",
        "i = 0.0\n",
        "while i <= 1.0:\n",
        "    reg_param.append(i) \n",
        "    i += 0.1\n",
        "\n",
        "# set parameters\n",
        "parameters = {'reg_param': reg_param}\n",
        "\n",
        "# Specify the cross validation method to use, we use 10-fold stratified cross-validation\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# Create QDA object\n",
        "qda = model_selection.RandomizedSearchCV(QuadraticDiscriminantAnalysis(), parameters, n_iter=11,\n",
        "                                   cv=cv_10fold, scoring='accuracy')\n",
        "\n",
        "# Fit the model\n",
        "qda.fit(X_pca, y_train)\n",
        "\n",
        "# Whole search\n",
        "y_pred  = qda.predict(X_pca)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "qda_df = pd.DataFrame(qda.cv_results_)\n",
        "display(qda_df)\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "qda.best_params_"
      ],
      "metadata": {
        "id": "K9MLj58j2zkJ",
        "outputId": "1cd3bffb-bd40-4378-d04e-0fe13d6c3ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/discriminant_analysis.py:926: UserWarning: Variables are collinear\n",
            "  warnings.warn(\"Variables are collinear\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
              "0        0.005290      0.003280         0.002173        0.001626   \n",
              "1        0.002668      0.000488         0.000992        0.000131   \n",
              "2        0.002920      0.000931         0.001255        0.000477   \n",
              "3        0.002372      0.000272         0.000943        0.000123   \n",
              "4        0.002936      0.001350         0.001101        0.000352   \n",
              "..            ...           ...              ...             ...   \n",
              "6        0.002816      0.000550         0.001117        0.000227   \n",
              "7        0.002806      0.000813         0.001159        0.000376   \n",
              "8        0.003122      0.000870         0.001072        0.000177   \n",
              "9        0.002808      0.000699         0.001315        0.000649   \n",
              "10       0.002648      0.000438         0.001035        0.000082   \n",
              "\n",
              "   param_reg_param                              params  split0_test_score  \\\n",
              "0              0.0                  {'reg_param': 0.0}           0.666667   \n",
              "1              0.1                  {'reg_param': 0.1}           0.777778   \n",
              "2              0.2                  {'reg_param': 0.2}           0.777778   \n",
              "3              0.3  {'reg_param': 0.30000000000000004}           0.777778   \n",
              "4              0.4                  {'reg_param': 0.4}           0.777778   \n",
              "..             ...                                 ...                ...   \n",
              "6              0.6                  {'reg_param': 0.6}           0.777778   \n",
              "7              0.7                  {'reg_param': 0.7}           0.777778   \n",
              "8              0.8   {'reg_param': 0.7999999999999999}           0.777778   \n",
              "9              0.9   {'reg_param': 0.8999999999999999}           0.777778   \n",
              "10             1.0   {'reg_param': 0.9999999999999999}           0.444444   \n",
              "\n",
              "    split1_test_score  split2_test_score  split3_test_score  \\\n",
              "0            0.777778           0.444444           0.333333   \n",
              "1            0.555556           0.666667           0.555556   \n",
              "2            0.555556           0.666667           0.666667   \n",
              "3            0.666667           0.666667           0.666667   \n",
              "4            0.666667           0.555556           0.777778   \n",
              "..                ...                ...                ...   \n",
              "6            0.444444           0.555556           0.777778   \n",
              "7            0.444444           0.555556           0.777778   \n",
              "8            0.444444           0.555556           0.666667   \n",
              "9            0.333333           0.555556           0.666667   \n",
              "10           0.555556           0.666667           0.777778   \n",
              "\n",
              "    split4_test_score  split5_test_score  split6_test_score  \\\n",
              "0            0.555556           0.555556              0.875   \n",
              "1            0.666667           0.666667              0.625   \n",
              "2            0.666667           0.666667              0.750   \n",
              "3            0.666667           0.555556              0.750   \n",
              "4            0.666667           0.555556              0.875   \n",
              "..                ...                ...                ...   \n",
              "6            0.666667           0.555556              0.750   \n",
              "7            0.666667           0.555556              0.750   \n",
              "8            0.777778           0.555556              0.750   \n",
              "9            0.777778           0.666667              0.750   \n",
              "10           0.666667           0.777778              0.375   \n",
              "\n",
              "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
              "0               0.250              0.375              0.750         0.558333   \n",
              "1               0.375              0.375              0.625         0.588889   \n",
              "2               0.375              0.375              0.750         0.625000   \n",
              "3               0.375              0.375              0.750         0.625000   \n",
              "4               0.375              0.375              0.625         0.625000   \n",
              "..                ...                ...                ...              ...   \n",
              "6               0.500              0.375              0.625         0.602778   \n",
              "7               0.625              0.375              0.625         0.615278   \n",
              "8               0.625              0.375              0.500         0.602778   \n",
              "9               0.625              0.500              0.500         0.615278   \n",
              "10              0.750              0.500              0.250         0.576389   \n",
              "\n",
              "    std_test_score  rank_test_score  \n",
              "0         0.197281               11  \n",
              "1         0.122537                9  \n",
              "2         0.138332                1  \n",
              "3         0.138332                1  \n",
              "4         0.157258                1  \n",
              "..             ...              ...  \n",
              "6         0.133968                7  \n",
              "7         0.129554                5  \n",
              "8         0.133968                7  \n",
              "9         0.136373                5  \n",
              "10        0.172720               10  \n",
              "\n",
              "[11 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-278ed84f-e178-4d46-8cdf-a5d4e77ddc30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_reg_param</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.005290</td>\n",
              "      <td>0.003280</td>\n",
              "      <td>0.002173</td>\n",
              "      <td>0.001626</td>\n",
              "      <td>0.0</td>\n",
              "      <td>{'reg_param': 0.0}</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.558333</td>\n",
              "      <td>0.197281</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.002668</td>\n",
              "      <td>0.000488</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>0.1</td>\n",
              "      <td>{'reg_param': 0.1}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.588889</td>\n",
              "      <td>0.122537</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.000931</td>\n",
              "      <td>0.001255</td>\n",
              "      <td>0.000477</td>\n",
              "      <td>0.2</td>\n",
              "      <td>{'reg_param': 0.2}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.138332</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.002372</td>\n",
              "      <td>0.000272</td>\n",
              "      <td>0.000943</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>0.3</td>\n",
              "      <td>{'reg_param': 0.30000000000000004}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.138332</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.002936</td>\n",
              "      <td>0.001350</td>\n",
              "      <td>0.001101</td>\n",
              "      <td>0.000352</td>\n",
              "      <td>0.4</td>\n",
              "      <td>{'reg_param': 0.4}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.157258</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.002816</td>\n",
              "      <td>0.000550</td>\n",
              "      <td>0.001117</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>0.6</td>\n",
              "      <td>{'reg_param': 0.6}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.602778</td>\n",
              "      <td>0.133968</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.002806</td>\n",
              "      <td>0.000813</td>\n",
              "      <td>0.001159</td>\n",
              "      <td>0.000376</td>\n",
              "      <td>0.7</td>\n",
              "      <td>{'reg_param': 0.7}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.615278</td>\n",
              "      <td>0.129554</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.003122</td>\n",
              "      <td>0.000870</td>\n",
              "      <td>0.001072</td>\n",
              "      <td>0.000177</td>\n",
              "      <td>0.8</td>\n",
              "      <td>{'reg_param': 0.7999999999999999}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.602778</td>\n",
              "      <td>0.133968</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.002808</td>\n",
              "      <td>0.000699</td>\n",
              "      <td>0.001315</td>\n",
              "      <td>0.000649</td>\n",
              "      <td>0.9</td>\n",
              "      <td>{'reg_param': 0.8999999999999999}</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.625</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.615278</td>\n",
              "      <td>0.136373</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.002648</td>\n",
              "      <td>0.000438</td>\n",
              "      <td>0.001035</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>1.0</td>\n",
              "      <td>{'reg_param': 0.9999999999999999}</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.500</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.576389</td>\n",
              "      <td>0.172720</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11 rows  19 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-278ed84f-e178-4d46-8cdf-a5d4e77ddc30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-278ed84f-e178-4d46-8cdf-a5d4e77ddc30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-278ed84f-e178-4d46-8cdf-a5d4e77ddc30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'reg_param': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 277
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-NN"
      ],
      "metadata": {
        "id": "xdjw0bA9zOle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "# Specify the search range, this could be multiple parameters for more complex classifiers\n",
        "parameters = {'n_neighbors': randint(1, 50),\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'p': randint(1, 5),\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "\n",
        "# Specify the cross validation method to use, we use 10-fold stratified cross-validation\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# Create the grid search method, use area under ROC curve as scoring metric\n",
        "# Too learn more about metrics see: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "clf = model_selection.RandomizedSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=cv_10fold, n_iter=500, scoring='accuracy')\n",
        "\n",
        "# Do the entire search\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "# Extract the best k \n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "optimal_k = clf_df['param_n_neighbors'].iloc[0]\n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "param = clf.best_params_\n",
        "knn_classifier = neighbors.KNeighborsClassifier(n_neighbors=param['n_neighbors'],p=param['p'],weights=param['weights'])\n",
        "print(knn_classifier)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make learning curve\n",
        "\n",
        "# cv = model_selection.ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
        "# model_selection.LearningCurveDisplay.from_estimator(knn_classifier, X_pca, y_train, train_sizes=[20, 45, 65], cv=cv)\n",
        "\n",
        "fig = plt.figure(figsize=(24,8))\n",
        "ax = fig.add_subplot(1, 3, 1)\n",
        "plot_learning_curve(knn_classifier, 'learning curve knn', X_pca, y_train, ax, ylim=(0.3, 1.01), cv=cv_10fold)\n"
      ],
      "metadata": {
        "id": "F2Mc-n3yzRIP",
        "outputId": "296c6863-9766-44cd-99fa-7126ed08bf45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'algorithm': 'kd_tree', 'n_neighbors': 12, 'p': 1, 'weights': 'distance'}\n",
            "0.6527777777777778\n",
            "KNeighborsClassifier(n_neighbors=12, p=1, weights='distance')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_scorer.py\", line 444, in _passthrough_scorer\n",
            "    return estimator.score(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/base.py\", line 668, in score\n",
            "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_classification.py\", line 237, in predict\n",
            "    neigh_dist, neigh_ind = self.kneighbors(X)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/sklearn/neighbors/_base.py\", line 810, in kneighbors\n",
            "    raise ValueError(\n",
            "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 7, n_neighbors = 12\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7 25 42 59 77] [[nan nan nan nan nan nan nan nan nan nan]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]] [[       nan        nan        nan        nan        nan        nan\n",
            "         nan        nan        nan        nan]\n",
            " [0.55555556 0.44444444 0.55555556 0.44444444 0.44444444 0.44444444\n",
            "  0.5        0.5        0.375      0.5       ]\n",
            " [0.66666667 0.44444444 0.55555556 0.55555556 0.44444444 0.66666667\n",
            "  0.5        0.625      0.375      0.5       ]\n",
            " [0.66666667 0.55555556 0.66666667 0.66666667 0.44444444 0.55555556\n",
            "  0.75       0.625      0.5        0.625     ]\n",
            " [0.55555556 0.33333333 0.55555556 0.66666667 0.77777778 0.88888889\n",
            "  0.875      0.625      0.75       0.5       ]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 278
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmoAAAK9CAYAAACU6UDoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACMcklEQVR4nOzdeVxVZeI/8M/dVy7gBogoipq7lgapuVQKZpm2ojWTWdlqWcw05XwnzfqVTU2m0zpTWTNlYZk5NZmBmpXpaGmW5pK7hqKyw13PPef5/UGcvIIKCpwDfN6vF6+6zzn33Oc+XODjeTaDEEKAiIiIiHTHqHUFiIiIiKhmDGpEREREOsWgRkRERKRTDGpEREREOsWgRkRERKRTDGpEREREOsWgRkRERKRTDGpEREREOsWgRkRERKRTDGpEhLfeegsGgwH79+/XuiqntXr1ahgMBqxevVrrqjR5t9xyC9xut9bVIKIzYFAjIiIi0imz1hUgIqqt4cOHw+/3w2q1al0VIqJGwTtqRKQZr9dbp/ONRiPsdjuMxub3q0sIAb/fr3U1iEhnmt9vOyKqN5999hmGDRsGl8uFqKgoXHHFFfjpp58izvnxxx9xyy23oEuXLrDb7YiPj8ett96KwsLCiPMee+wxGAwGbNu2DTfeeCNiY2Nx8cUXAwCSk5Nx5ZVXYs2aNUhNTYXdbkeXLl3w73//O+IaNY1RGzlyJPr06YNt27bhkksugdPpRGJiIp555plq7+fAgQO46qqr4HK50K5dOzz44IP4/PPPaz3uLS8vD7fddhvat28Pm82Gzp074+6770YoFIp4jyeraQxg1Xv+/PPPMWjQIDgcDvzjH/9Anz59cMkll1S7hqIoSExMxHXXXRdRNm/ePPTu3Rt2ux1xcXG48847UVxcfMb3UpPNmzejbdu2GDlyJCoqKiLqeabvTdV7/Oabb5CVlYW2bdvC5XLh6quvxvHjx8+qPkTEoEZEp/D222/jiiuugNvtxl//+lc8+uij2LZtGy6++OKIwJGbm4u9e/diypQpeOGFFzBx4kRkZ2dj7NixEEJUu+71118Pn8+Hp556ClOnTlXLd+/ejeuuuw6jR4/Gc889h9jYWNxyyy3VgmFNiouLMWbMGPTv3x/PPfccevTogYcffhifffaZeo7X68Wll16KFStW4P7778f//d//Ye3atXj44Ydr1R6HDx9GamoqsrOzkZmZib///e/4/e9/jy+//BI+n69W1zjZzp07MWnSJIwePRrz58/HgAEDkJmZia+++gr5+fkR565ZswaHDx/GxIkT1bI777wTDz30EIYOHYr58+djypQpWLhwITIyMiBJUp3q8u233+LSSy/F+eefj88++yxiokFdvjf33XcffvjhB8yaNQt33303PvnkE0ybNq2OLUNEKkFELd6bb74pAIh9+/YJIYQoLy8XMTExYurUqRHn5efni+jo6Ihyn89X7XrvvfeeACC++uortWzWrFkCgJg0aVK18zt16lTt/GPHjgmbzSb+8Ic/qGVffPGFACC++OILtWzEiBECgPj3v/+tlgWDQREfHy+uvfZatey5554TAMTSpUvVMr/fL3r06FHtmjW5+eabhdFoFN9++221Y4qiRLzHk53cvie+5+XLl0ecu3PnTgFAvPDCCxHl99xzj3C73Wp7f/311wKAWLhwYcR5y5cvr7H8ZJMnTxYul0sIIcSaNWuEx+MRV1xxhQgEAhHn1fZ7U/UeR40apbaHEEI8+OCDwmQyiZKSktPWh4hqxjtqRFRNbm4uSkpKMGnSJBQUFKhfJpMJaWlp+OKLL9RzHQ6H+v+BQAAFBQW46KKLAACbNm2qdu277rqrxtfs1asXhg0bpj5u27YtzjvvPOzdu/eM9XW73fjd736nPrZarUhNTY147vLly5GYmIirrrpKLbPb7RF39U5FURQsXboU48aNw6BBg6odr6m7szY6d+6MjIyMiLLu3btjwIABWLRokVomyzIWL16McePGqe39wQcfIDo6GqNHj474Hg0cOBButzvie3Q6X3zxBTIyMnDZZZdhyZIlsNls1c6py/fmjjvuiGiPYcOGQZZlHDhwoFb1IaJInPVJRNXs2rULAHDppZfWeNzj8aj/X1RUhNmzZyM7OxvHjh2LOK+0tLTaczt37lzjNTt27FitLDY2tlbjrTp06FAtLMXGxuLHH39UHx84cAApKSnVzuvatesZr3/8+HGUlZWhT58+Zzy3Lk7VFpmZmfjzn/+MvLw8JCYmYvXq1Th27BgyMzPVc3bt2oXS0lK0a9euxmuc/L2oSSAQwBVXXIGBAwfi/fffh9lc85+EunxvTj43NjYWAM563BxRS8egRkTVKIoCoHKcWnx8fLXjJ/5Bv+GGG7B27Vo89NBDGDBgANxuNxRFwZgxY9TrnOjEO3AnMplMNZaLGsa51edz69Op7qzJslxj+anaIjMzEzNmzMAHH3yABx54AO+//z6io6MxZswY9RxFUdCuXTssXLiwxmu0bdv2jPW12WwYO3Ys/vOf/2D58uW48sorazyvLu2rl+8FUXPBoEZE1aSkpAAA2rVrh1GjRp3yvOLiYqxcuRKzZ8/GzJkz1fKqO3J60qlTJ2zbtg1CiIhAtXv37jM+t23btvB4PNi6detpz6u6e1RSUoKYmBi1vK7dfp07d0ZqaioWLVqEadOmYcmSJZgwYUJEt2RKSgpWrFiBoUOHnjLwnYnBYMDChQsxfvx4XH/99fjss88wcuTIs7oWETUMjlEjomoyMjLg8Xjw1FNP1Th7sGq5haq7JyffLZk3b16D17GuMjIykJeXh48//lgtCwQCeO211874XKPRiAkTJuCTTz7Bd999V+141fuvCrhfffWVeszr9eJf//pXneubmZmJ//3vf1iwYAEKCgoiuj2ByjuZsizjiSeeqPbccDiMkpKSWr2O1WrFkiVLcOGFF2LcuHHYsGFDnetKRA2Hd9SIqBqPx4NXXnkFv//973HBBRdg4sSJaNu2LQ4ePIhPP/0UQ4cOxYsvvgiPx4Phw4fjmWeegSRJSExMRE5ODvbt26f1W6jmzjvvxIsvvohJkyZh+vTpSEhIwMKFC2G32wGceULAU089hZycHIwYMQJ33HEHevbsiSNHjuCDDz7AmjVrEBMTg/T0dHTs2BG33XYbHnroIZhMJixYsEBtu7q44YYb8Mc//hF//OMf0apVq2p3NkeMGIE777wTc+bMwebNm5Geng6LxYJdu3bhgw8+wPz58yPWXDsdh8OB//73v7j00ktx+eWX48svv6z38XhEdHYY1IioRjfeeCPat2+Pp59+Gs8++yyCwSASExMxbNgwTJkyRT3v3XffxX333YeXXnoJQgikp6fjs88+Q/v27TWsfXVutxurVq3Cfffdh/nz58PtduPmm2/GkCFDcO2116qB7VQSExOxfv16PProo1i4cCHKysqQmJiIyy+/HE6nEwBgsVjw0Ucf4Z577sGjjz6K+Ph4PPDAA4iNjY1os9ro0KEDhgwZgm+++Qa33347LBZLtXNeffVVDBw4EP/4xz/w5z//GWazGcnJyfjd736HoUOH1un1PB4PPv/8cwwfPhyjR4/G119/XauJFkTUsAyCIzyJqAWbN28eHnzwQfzyyy9ITEzUujpERBEY1IioxfD7/dXWfTv//PMhyzJ+/vlnDWtGRFQzdn0SUYtxzTXXoGPHjhgwYABKS0vxzjvvYMeOHadc4oKISGsMakTUYmRkZOD111/HwoULIcsyevXqpe7dSUSkR+z6JCIiItIprqNGREREpFMMakREREQ61eLGqCmKgsOHDyMqKuqMC1wSERER1TchBMrLy9G+fXsYjae/Z9bigtrhw4eRlJSkdTWIiIiohTt06BA6dOhw2nNaXFCLiooCUNk4Ho9H49rokyRJyMnJUbekocbF9tcO215bbH9tsf0bT1lZGZKSktRMcjotLqhVdXd6PB4GtVOQJAlOpxMej4c/rBpg+2uHba8ttr+22P6NrzZDsFpcUGtwsgx8/TVw5AiQkAAMGwaYTFrXiloifhZJD/g5pKZEh59XBrX6tGQJMH068Msvv5V16ADMnw9cc4129aKWh59F0gN+Dqkp0ennVdPlOb766iuMGzcO7du3h8FgwNKlS8/4nNWrV+OCCy6AzWZD165d8dZbbzV4PWtlyRLguusiv8EAkJdXWb5kiTb1opaHn0XSA34OqSnR8edV0ztqXq8X/fv3x6233oprapFW9+3bhyuuuAJ33XUXFi5ciJUrV+L2229HQkICMjIyGqHGpyDLlSm8pk0ehAAMhsrjo0Zpfgu1ViQJpkAA8HoBjlNofOfS/rIM3H9/8/ksNjZ+9uvH2X4O2f7aaqntX5vP6wMPAOPHa/J7UzdbSBkMBnz00UeYMGHCKc95+OGH8emnn2Lr1q1q2cSJE1FSUoLly5fX+JxgMIhgMKg+rpppUVBQUG+TCQxffgnz6NH1ci0iIiLSn3BuLsSIEfVyrbKyMrRp0walpaVnzCJNaozaunXrMGrUqIiyjIwMPPDAA6d8zpw5czB79uxq5Tk5OXA6nfVSr8SvvsKgerkSERER6dHmzz5DntdbL9fy+Xy1PrdJBbX8/HzExcVFlMXFxaGsrAx+vx8Oh6Pac2bMmIGsrCz1cdUdtfT09Pq7o+ZyAXPnnvG88OLFEEOG1MtrNiQpHMaqtWtx6ZAhsJib1EekWTiX9jesXQvzdded8bym8llsbPzs14+z/Ryy/bXVUtu/tp/XAZdfjv71eEettpr9d8Jms8Fms1Urt1gs9bdOzCWXVM4MycuruY/bYAA6dIB5woSmMS5IkiDb7bDEx3MtHS2cS/tPmNC8PouNjZ/9+nG2n0O2v7ZaavvX9vN6ySX19nuzLu3bpDZlj4+Px9GjRyPKjh49Co/HU+PdtEZjMlVO3wUqv6Enqno8bx7/MFLD42eR9ICfQ2pKdP55bVJBbfDgwVi5cmVEWW5uLgYPHqxRjU5wzTXA4sVAYmJkeYcOleVcM4gaCz+LpAf8HFJTouPPq6ZdnxUVFdi9e7f6eN++fdi8eTNatWqFjh07YsaMGcjLy8O///1vAMBdd92FF198EX/6059w6623YtWqVXj//ffx6aefavUWIl1zTeX0XZ2takwtED+LpAf8HFJTotPPq6ZB7bvvvsMll1yiPq4a9D958mS89dZbOHLkCA4ePKge79y5Mz799FM8+OCDmD9/Pjp06IDXX39d2zXUTmYyASNHal0LIn4WSR/4OaSmRIefV02D2siRI3G6Zdxq2nVg5MiR+P777xuwVkRERET60KTGqBERERG1JAxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkUwxqRERERDrFoEZERESkU5oHtZdeegnJycmw2+1IS0vDhg0bTnmuJEl4/PHHkZKSArvdjv79+2P58uWNWFsiIiKixqNpUFu0aBGysrIwa9YsbNq0Cf3790dGRgaOHTtW4/l/+ctf8I9//AMvvPACtm3bhrvuugtXX301vv/++0auOREREVHD0zSozZ07F1OnTsWUKVPQq1cvvPrqq3A6nViwYEGN57/99tv485//jLFjx6JLly64++67MXbsWDz33HONXHMiIiKihmfW6oVDoRA2btyIGTNmqGVGoxGjRo3CunXranxOMBiE3W6PKHM4HFizZs0pXycYDCIYDKqPy8rKAFR2o0qSdC5vodmqahe2jzbY/tph22uL7a8ttn/jqUsbaxbUCgoKIMsy4uLiIsrj4uKwY8eOGp+TkZGBuXPnYvjw4UhJScHKlSuxZMkSyLJ8yteZM2cOZs+eXa08JycHTqfz3N5EM5ebm6t1FVo0tr922PbaYvtri+3f8Hw+X63P1SyonY358+dj6tSp6NGjBwwGA1JSUjBlypRTdpUCwIwZM5CVlaU+LisrQ1JSEtLT0+HxeBqj2k2OJEnIzc3F6NGjYbFYtK5Oi8P21w7bXltsf22x/RtPVe9ebWgW1Nq0aQOTyYSjR49GlB89ehTx8fE1Pqdt27ZYunQpAoEACgsL0b59ezzyyCPo0qXLKV/HZrPBZrNVK7dYLPwgngHbSFtsf+2w7bXF9tcW27/h1aV9NZtMYLVaMXDgQKxcuVItUxQFK1euxODBg0/7XLvdjsTERITDYXz44YcYP358Q1eXiIiIqNFp2vWZlZWFyZMnY9CgQUhNTcW8efPg9XoxZcoUAMDNN9+MxMREzJkzBwCwfv165OXlYcCAAcjLy8Njjz0GRVHwpz/9Scu3QURERNQgNA1qmZmZOH78OGbOnIn8/HwMGDAAy5cvVycYHDx4EEbjbzf9AoEA/vKXv2Dv3r1wu90YO3Ys3n77bcTExGj0DoiIiIgajuaTCaZNm4Zp06bVeGz16tURj0eMGIFt27Y1Qq2IiIiItKf5FlJEREREVDMGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIiKdYlAjIiIi0ikGNSIiIqITBMIBSLKkdTUAMKgRERERAQDCShgF3gIcKDmAilCF1tUBAJi1rgARERGR1ipCFSjwFqAiVAFFKFpXR8WgRkRERC2WJEso8heh0FcIk9GEWEcsSgIlWldLxaBGRERELY4QAuWhchz3Hoc/7EeUNQoWk0XralXDoEZEREQtSjAcRKGvEMWBYlhNVsTaY2EwGLSuVo0Y1IiIiKhFUISC0kApCnwFCMkhRNmiYDbqOwrpu3ZERERE9cAv+VHgK0BpsBQOswOxjlitq1QrDGpERETUbMmKjGJ/MQr9hZCFjBh7DIyGprM6GYMaERERNUvqkhtSBZwWJ6LMUVpXqc4Y1IiIiKhZqVpyo8hfBIPBoOvJAmfCoEZERETNwslLbritblhNVq2rdU4Y1IiIiKjJC4aDKPIXoThQDLPR3KTvop1I89F0L730EpKTk2G325GWloYNGzac9vx58+bhvPPOg8PhQFJSEh588EEEAoFGqi0RERHpiSIUlARKcKj0EAr9hXBb3XBb3c0ipAEaB7VFixYhKysLs2bNwqZNm9C/f39kZGTg2LFjNZ7/7rvv4pFHHsGsWbOwfft2vPHGG1i0aBH+/Oc/N3LNiYiISGt+yY/D5YfxS9kvgAFo5Wil+3XR6krToDZ37lxMnToVU6ZMQa9evfDqq6/C6XRiwYIFNZ6/du1aDB06FDfeeCOSk5ORnp6OSZMmnfEuHBERETUfsiKj0FeIQ6WHUBYoQ7QtGk6LU+tqNQjNYmcoFMLGjRsxY8YMtcxoNGLUqFFYt25djc8ZMmQI3nnnHWzYsAGpqanYu3cvli1bht///venfJ1gMIhgMKg+LisrAwBIkgRJkurp3TQvVe3C9tEG2187bHttsf211VTa3xfyodBfiIpQBRwWB6IsUYBSGd7qixJWEA6HG6wt6nJdzYJaQUEBZFlGXFxcRHlcXBx27NhR43NuvPFGFBQU4OKLL4YQAuFwGHfddddpuz7nzJmD2bNnVyvPycmB09k803d9yc3N1boKLRrbXztse22x/bXF9q+0F3sb7No+n6/W5zapjtzVq1fjqaeewssvv4y0tDTs3r0b06dPxxNPPIFHH320xufMmDEDWVlZ6uOysjIkJSUhPT0dHo+nsarepEiShNzcXIwePRoWi0Xr6rQ4bH/tsO21xfbXll7bXwgBr+RFoa8QPskHl9XV4EtulPhLEB8Vjxh7TINcv6p3rzY0C2pt2rSByWTC0aNHI8qPHj2K+Pj4Gp/z6KOP4ve//z1uv/12AEDfvn3h9Xpxxx134P/+7/9gNFYfcmez2WCz2aqVWywWXX0Q9YhtpC22v3bY9tpi+2tLT+0fkkMo9BWiyF8Ei8mC1u7WjTKb02g2wmw2N1g71OW6mk0msFqtGDhwIFauXKmWKYqClStXYvDgwTU+x+fzVQtjJpMJQGXiJiIioqZPEQpKA6U4WHIQRf4iRNmimtWSG3WhaddnVlYWJk+ejEGDBiE1NRXz5s2D1+vFlClTAAA333wzEhMTMWfOHADAuHHjMHfuXJx//vlq1+ejjz6KcePGqYGNiIiImq5AOIBCXyGKA8Wwm+2IdcRqXSVNaRrUMjMzcfz4ccycORP5+fkYMGAAli9frk4wOHjwYMQdtL/85S8wGAz4y1/+gry8PLRt2xbjxo3Dk08+qdVbICIionogKzJKAiUo9BUirIQRbYuGycibMJpPJpg2bRqmTZtW47HVq1dHPDabzZg1axZmzZrVCDUjIiKixuCTfCjwFaAsWAaH2QG3za11lXRD86BGRERELVNYCaPYX4xCXyEEBGLsMTAaNN/dUlcY1IiIiKhRCSFQEapAga8AXskLl8UFm7n6Cg3EoEZERESNKCSHUOQvQpGvCCajCbH22BY5m7O2GNSIiIiowQkhUBYsQ4GvAP6wH1HWKFhM+livTc8Y1IiIiKhBVS25URIogdVkRStHK62r1GQwqBEREVGDqFq4tsBXgJAcgsfm4ZIbdcSgRkRERPXOJ/lQ6CtEabAUDrOjxS9ce7YY1IiIiKjehJUwSvwlKPQXQhYyl9w4RwxqREREdM6EEPBKXhR4C1ARqoDLyiU36gODGhEREZ0TSZZQ5C9Coa+wcskNB5fcqC8MakRERHRWhBAoD5XjuPc4l9xoIAxqREREVGfBcBCFvkIUB4phNVm5cG0DYVAjIiKiWjt5yY0oWxTMRsaJhsKWJSIiolrxS34U+Aq45EYjYlAjIiKi05IVGcX+Yi65oQEGNSIiIjqlilBF5ZIbUgWcFieizFFaV6lFYVAjIiKiaqqW3CjyF8FgMHCygEYY1IiIiEglhEBZsExdcsNtdcNqsmpdrRaLQY2IiIhUx7zHUBYug9lo5l00HWBQIyIiauEUoaA0WAoAKPIXIcYVwyU3dILfBSIiohbML/lR6C9EcUUxACDWEQuT0aRxragKgxoREVELJCsySgIlKPQVIqyEEWXjbE49YlAjIiJqYbwhLwp8BSgPlcNpccJtc0MOy1pXi2rAoEZERNRChJUwivxFKPQVwmAwcOHaJoBBjYiIqJkTQlQuXOsrgFfycsmNJoRBjYiIqBkLySEU+gpRHCjmkhtNEIMaERFRM6QIBeXBchz3HkdQDiLKFsUlN5ogfseIiIiamUA4oN5Fs5vtiHXEal0lOksMakRERM3EyUtuRNuiuSZaE8egRkRE1AycuOSGw+yA2+bWukpUDxjUiIiImrCwEkaxvxiFvkIICC650cwwqBERETVBJy+54bK4YDPbtK4W1TMGNSIioiYmJIdQ5C9Cka8IJqOJS240YwxqRERETYQQAmXBMhT4CuAP+xFljYLFZNG6WtSAGNSIiIiagKolN0oCJbCarGjlaKV1lagRMKgRERHpmCIUlAZKUeArQEgOwWPzcMmNFoRBjYiISKd8kg+FvkKUBkvhMDu4cG0LxKBGRESkM2EljBJ/CQp8BVxyo4VjUCMiItIJIQS8khcF3gJUhCrgsnLJjZaOQY2IiEgHJFlCkb8Ihb7CyiU3HFxygxjUiIiINCWEQHmoHMe9x7nkBlXDoEZERKSRYDiIQl8higPFsJqsXLiWqmFQIyIiamQnL7kRZYuC2cg/yVQdPxVERESNyC/5UeAr4JIbVCsMakRERI1AVmQU+4tR6C+ELGQuuUG1wqBGRETUwCpCFZVLbkgVcFqciDJHaV0laiIY1IiIiBpI1ZIbRf4iGAwGThagOmNQIyIiqmcnL7nhtrphNVm1rhY1QQxqRERE9SgYDqLIX4TiQDHMRjPvotE5YVAjIiKqB4pQUBYsQ4G3AAE5AI/NwyU36JzxE0RERHSO/JIfhf5ClAZKYTfb0crRSusqUTPBoEZERHSWZEVGSaAEhb5ChJUwPDYPTEaT1tWiZoRBjYiI6Cx4Q14U+ApQHiqH0+KE2+bWukrUDDGoERER1UFYCaPIX4RCXyEMBgMXrqUGxaBGRERUC0IIVIQqcNx3HD7JxyU3qFEwqBEREZ1BSA6h0FfIJTeo0TGoERERnQKX3CCt8dNGRERUg0A4oN5F45IbpBUGNSIiohOcvORGtC2aS26QZhjUiIiIfnXikhsOs4NLbpDmGNSIiKjFCythFPuLUegrhIDgkhukGwxqRETUYlUtuVHgK4BX8sJlccFmtmldLSIVgxoREbVIITmEIn8RinxFMBlNXHKDdIlBjYiIWhQhROWSG74C+MN+RFmjYDFZtK4WUY0Y1IiIqMWoWnKjJFACm9nGJTdI9xjUiIio2VOEgtJAKQp8BQjJIXhsHi65QU0CgxoRETVrPsmHQl8hSoOlcJgdiHXEal0lolpjUCMiomYprIRR4i9Bga+AS25Qk8WgRkREzYoQAl7JiwJvASpCFXBZueQGNV0MakRE1GxIsoQifxEKfYWVS244uOQGNW0MakRE1ORxyQ1qrhjUiIioSQuGgyj0FaI4UAyrycolN6hZYVAjIqIm6eQlN6JsUTAb+WeNmhd+oomIqMnxS34U+Aq45AY1ewxqRETUZMiKjGJ/MQr9hZCFzCU3qNljUCMioiahIlRRueSGVAGXhUtuUMugi3+GvPTSS0hOTobdbkdaWho2bNhwynNHjhwJg8FQ7euKK65oxBoTEVFjkWQJRyuO4lDpIQTkAGLtsQxp1GJoHtQWLVqErKwszJo1C5s2bUL//v2RkZGBY8eO1Xj+kiVLcOTIEfVr69atMJlMuP766xu55kRE1JCqltw4WHoQx33H4bA44LF5uC4atSiaB7W5c+di6tSpmDJlCnr16oVXX30VTqcTCxYsqPH8Vq1aIT4+Xv3Kzc2F0+lkUCMiakaC4SDyK/LxS9kvUISCWHssrCar1tUianSajlELhULYuHEjZsyYoZYZjUaMGjUK69atq9U13njjDUycOBEul6vG48FgEMFgUH1cVlYGAJAkCZIknUPtm6+qdmH7aIPtrx22vbaq2r3QW7mBelAOqktuKLKice2aPzksR/y3JVPCCsLhcIP9LqjLdTUNagUFBZBlGXFxcRHlcXFx2LFjxxmfv2HDBmzduhVvvPHGKc+ZM2cOZs+eXa08JycHTqez7pVuQXJzc7WuQovG9tcO215b679cr3UVWrQf1v6gdRV0YS/2Nti1fT5frc9t0rM+33jjDfTt2xepqamnPGfGjBnIyspSH5eVlSEpKQnp6enweDyNUc0mR5Ik5ObmYvTo0bBYuAVLY2P7a4dtrw1ZkVEaLMXxsuPYs3EP+lzUB1YruzkbmxyW8cPaH9B/SH+YzCatq6OpEn8J4qPiEWOPaZDrV/Xu1YamQa1NmzYwmUw4evRoRPnRo0cRHx9/2ud6vV5kZ2fj8ccfP+15NpsNNlv12UEWi4W/iM+AbaQttr922PaNxxvyosBfgPJQufq72mq1tvigoCWT2dTi299oNsJsNjfY74G6XFfTyQRWqxUDBw7EypUr1TJFUbBy5UoMHjz4tM/94IMPEAwG8bvf/a6hq0lERPVMkiUc8x7DwdKD8If9iLXHwm62a10tIt3RvOszKysLkydPxqBBg5Camop58+bB6/ViypQpAICbb74ZiYmJmDNnTsTz3njjDUyYMAGtW7fWotpERHQWhBCoCFXgmPcY/GE/3FY3Z3MSnYbmQS0zMxPHjx/HzJkzkZ+fjwEDBmD58uXqBIODBw/CaIy88bdz506sWbMGOTk5WlSZiIjOQkgOodBXiOJAMcxGM2LtsVwTjegMNA9qADBt2jRMmzatxmOrV6+uVnbeeedBCNHAtSIiovoQDAfhk3wo9BUiIAfgsXlgNurizw+R7vEnhYiI6l1IDsEv+VEeKoc35IUkS7Bb7GjlaKV11YiaFAY1IiKqF5IswR/2oyJYgYpQBUJKCGajGXazHVG2KK2rR9QkMagREdFZCyth+CU/KkK/hjM5BKPBCLvZDrfNrXX1iJo8BjUiIqoTWZHhD/vhDXlRHixHUA7CYDDAbrYjxhLDCQJE9YhBjYiIzkgRCvySHz7Jh7JgGYJyEBCAzWxDjJ3hjKihMKgREVGNhBDwh/3whXwoC5UhIAUgIGA32+GxeWA0aLpmOlGLwKBGREQqIQSCcuVyGmWBMvjDfshCrgxndoYzosbGoEZE1MIJIRCSQ2q3pl/yIyzCsJlscFvdMBlb9r6PRFpiUCMiaqGq1jorC5bBJ/kgKRKsJiucVicXpCXSCf4kEhG1IFVrnZUHKxeiDSkhWIyWyrXOTFzrjEhvGNSIiJq5k9c6C8pBdSFat4lrnRHpGYMaEVEzVNNaZ1UL0bqsLq2rR0S1xKBGRNRMyIqMQDgAr1QZzgLhABeiJWriGNSIiJowRSgIhAPwhXwoDZZyIVqiZoZBjYioiRFCVIYzqTKccSFaoubrnIJaKBTCvn37kJKSArOZmY+IqKFULUTrl/woDZTCH/ZDEQpsZhsXoiVqxs7qJ9vn8+G2226D0+lE7969cfDgQQDAfffdh6effrpeK0hE1JIFw0GUBEpwsPQg9hfvR155HiRFgtvqRqwjFk6LkyGNqBk7q5/uGTNm4IcffsDq1atht9vV8lGjRmHRokX1VjkiopYoJIdQGijFodJD2F+yH7+U/YKgHITT6kQrRyu4rC7uFkDUQpxVf+XSpUuxaNEiXHTRRREDVXv37o09e/bUW+WIiFoKLkRLRDU5q6B2/PhxtGvXrlq51+vlDCMiolriQrREdCZn1fU5aNAgfPrpp+rjqnD2+uuvY/DgwfVTMyKiZkhWZFSEKnC04ij2F+/HgdIDKAmUwGw0o5WjFTw2D6wmq9bVJCKdOKs7ak899RQuv/xybNu2DeFwGPPnz8e2bduwdu1afPnll/VdRyKiJk0RCvySv8aFaGMtseyJIKJTOqs7ahdffDF++OEHhMNh9O3bFzk5OWjXrh3WrVuHgQMH1ncdiYiaHEUo8Ek+FHgLsK94H/aX7EeBtwAAEGOPQYw9BnaznSGNiE6rznfUJEnCnXfeiUcffRSvvfZaQ9SJiKhJOnEh2rJgGfySX12INtoezWU0iKjO6vxbw2Kx4MMPP2yIuhARNTlV4azYX4wDJQewv2Q/8ivyIQsZUbYoxDpi4bA4GNKI6Kyc1W+OCRMmYOnSpfVcFSKipqNqIdpDZYdOuRAt1zojonN1VpMJunXrhscffxzffPMNBg4cCJfLFXH8/vvvr5fKERHpSUgOwS/5URYsg0/yQZIlWM1WOK1OmI3cRo+I6t9Z/WZ54403EBMTg40bN2Ljxo0RxwwGA4MaETUbp12I1saFaImoYZ1VUNu3b19914OISDfCShiBYIAL0RKR5s75Xr0QAgA4xZyImjRZkeENeQEAB0sOQjJIMBqMXOuMqAWRFRnr89ZjX/E+9GjTA2O7jdV8rOlZB7V///vfePbZZ7Fr1y4AQPfu3fHQQw/h97//fb1VjoioIVUtRFu1nIYv4ANQ+Q/PWDvDGVFLsmzXMsz8YiaOVBxRyzp4OmD+mPm4puc1mtXrrILa3Llz8eijj2LatGkYOnQoAGDNmjW46667UFBQgAcffLBeK0lEVF8UoVSudRbyoTRYikA4AADqWmcA4LA4GNKIWpBlu5bhjk/ugICIKM8ry8N171+HxTcs1iysnVVQe+GFF/DKK6/g5ptvVsuuuuoq9O7dG4899hiDGhHpStVaZ/6wH6WBUvglPxQo1RailcOyxjUlosYmKzJmfjGzWkgDAAEBAwx4YPkDGH/eeE26Qc8qqB05cgRDhgypVj5kyBAcOXKkhmcQETUuIQSCchB+qTKcBcIBhEUYNpMNUbYozcedEJH2AuEA3vnxnYjuzpMJCBwqO4SvD36NkckjG69yvzqroNa1a1e8//77+POf/xxRvmjRInTr1q1eKkZEdDaC4aC6nIZP8kFSJFhNXOuMiIDSQCm+O/wdNuRtwPq89fjh6A8IyaFaPfdIuTY3os7qt9bs2bORmZmJr776Sh2j9s0332DlypV4//3367WCRERnUrUQbUWoovpaZyaudUbUUuVX5GN93nps+KUymO0o2FGtizPGHoOSQMkZr5UQldBAtTy9swpq1157LdavX4/nn39e3UqqZ8+e2LBhA84///z6rB8RUY3CShg+yYeKYAW8kpdrnRG1cEII7C3Zq4ayDXkbcKD0QLXzkmOSkZaYhrTENKQmpiLJk4SL3rgI+RX5NY5TM8CADp4OGNZxWGO8jWrOuh9g4MCBeOedd+qzLkREpxVWwhF3zoJyUF3rzGV1nfkCRNRshJUwth3fpnZjbsjbgAJfQcQ5BhjQq22vylDWIRWp7VMR546rdq3HL3kcd3xyBwwwRIQ1Aypnf88bM0+zca1nFdSWLVsGk8mEjIyMiPLPP/8ciqLg8ssvr5fKERHJigx/uHKts/JgOQLhAAwGA+xmO2IsMVxGg6iF8Et+bM7frIayjUc2oiJUEXGOzWTDgPgBSE1MRWpiKga1HwSPzXPGa4/tNhb/HPfPGtdRmzdmXtNbR+2RRx7B008/Xa1cCIFHHnmEQY2IzsnJa50F5SAgAJvZhhg7wxlRS1AaKMW3h79V75j9ePTHagP/o6xRuLD9hUjtkIq0xDT0i+sHu9l+Vq83tttYZKRkNI+dCXbt2oVevXpVK+/Rowd27959zpUiopanaq0zn/TrQrRSAAICdrMdHptHXeuMiJqn2gz8b+dqh9TEVHV8Wc82Pes1SJmMJgxJGoKebXqifVR7zUMacJZBLTo6Gnv37kVycnJE+e7du+FycZwIEdXOyWud+cN+KEKBzWyDx85wRtRcCSGwp3hPxPiyg6UHq53XOaazGspSE1ORHJPc4u6on1VQGz9+PB544AF89NFHSElJAVAZ0v7whz/gqquuqtcKElHzIoSoXE7jhF0CqhaidVvduvgXLBHVr6qB/1V3zDYcrj7w32gw/jbw/9dg1s7VTqMa68dZBbVnnnkGY8aMQY8ePdChQwcAwKFDhzB8+HD87W9/q9cKElHzULXWWVmwjAvREjVzJw/8/+7wd/BK3ohzThz4n5aYhkHtByHKxnUPT3bWXZ9r165Fbm4ufvjhBzgcDvTv3x/DhmmzxggR6ZMkS+ouAVyIlqj5KgmUVA78//Vu2Q/5P0BSpIhzPDYPBrUfpN4x6x/XHzazTaMaNx11Cmrr1q1DYWEhrrzyShgMBqSnp+PIkSOYNWsWfD4fJkyYgBdeeAE2GxueqKU6ca2zilAFF6IlaoaOlB+JGF9W08D/OFfcbwP/O6SiR+seHNpwFuoU1B5//HGMHDkSV155JQBgy5YtmDp1KiZPnoyePXvi2WefRfv27fHYY481RF2JSKeq1jrzhrwoD5ZzIVqiZqTOA/9/XSqjU3SnFjfwvyHUKaht3rwZTzzxhPo4OzsbqampeO211wAASUlJmDVrFoMaUQugCAV+yQ+v5OVCtETNSFgJY2v+VqzPW49v87495cD/3m17q4P+OfC/4dQpqBUXFyMu7retF7788suIxW0vvPBCHDp0qP5qR0S6woVoiZofv+TH9/nf43+H/ocVe1Zg90+7axz4f378+erdsoEJAznwv5HUKajFxcVh3759SEpKQigUwqZNmzB79mz1eHl5OSwWS71Xkoi0c+JCtGXBMvglPxeiJWrCThz4X7Xi/+kG/let+M+B/9qoU1AbO3YsHnnkEfz1r3/F0qVL4XQ6I2Z6/vjjj+q6akTUdHEhWqLm43D5YWzI26B+nWrg/4XtL0SCLwHXDr8WveJ6ceC/TtQpqD3xxBO45pprMGLECLjdbvzrX/+C1WpVjy9YsADp6en1XkkiahzBcBD+8K9rnYV8XIiWqImpGvi//pf16sD/Q2XVhyR1ie2iLpORlpiGjtEdocgKNn21Cb3aMqTpSZ2CWps2bfDVV1+htLQUbrcbJlPkN/KDDz6A283p90RNCReiJWq6wkoYPx37SQ1lG/I2oNBfGHHOiQP/q8JZW1dbjWpMdXXWC97WpFWrVudUGSJqHFyIlqhpqhr4XxXMNh7eyIH/zRz/uUzUQnAhWqKmp9hfXDnw/9c1zLYc3VJt4H+0Lfq3Ff87pKJfOw78b04Y1IiaMUUo8Ek+dSHagByAyWCC3WyH0+LkchpEOlM18L9q8/IdhTuqnRPvilfvlqUmpqJHmx6c4NOMMagRNUOKUOANeVHkL0JFqEJdiDbWEstwRqQTQgjsLtodseJ/bQf+8+e45WBQI2pGhBDwSpUBrTxYDrPRjGh7NP+1TaQDYSWMrce2qnfLNhzegCJ/UcQ5RoMRfdr1qVztv30qB/4TgxpRcyCEgE/yVQa0UDmMBiMDGpHG/JIfm45sUu+YbTyyET7JF3GO3WTH+Qnnq3fLBrYfCLeVY0bpNwxqRE2YEAL+sB/F/mKUBkphMBgQZY3iGkhEGuDAf2oIDGpETZRf8qMkUIKSQAkEBNw2N9c9I2pEeeV56jZMG/I2YGfhzmrnxLvj1fFlHPhPZ4O/1YmamEA4UBnQ/CVQhAKX1QWLiXvsEjWkqoH/6/N+W/H/l7Jfqp2XEpui3i1LS0xDkieJA//pnDCoETURwXBQvYMWVsJwWV2wmqxnfiIR1VldB/5X3TVr42yjUY2puWJQI9K5kBxCaaAUxf5ihJQQ3FY3dw8gqmd+yY+NRzaq2zBx4D/pBYMakU5JsoTSUCmKA8UIykG4LC64bfyjQFQfqgb+V21evuXYFoSVcMQ50bZoXJh4oXq3rF9cP97FpkbHoEakM5JcOUvsUOkhSAYJTosTrazcR5foXNR14H9aYhrOa3MeB/6T5hjUiHQirIRRHizH8fLjAACDwYBWDgY0oroSQmBX0S41lHHgPzVlDGpEGpMVGeWhchT6CuEP+2FB5QxOh8Whcc2ImgZJln4b+P9rMCsOFEecYzKYqg38b+1srVGNiWqPQY1II4pQUB4sR5G/CF7JC5vJhlh7LBRZ0bpqRLp24sD/9XnrsfHwRvjD/ohzqgb+pyWmIa1DGi5IuIAD/6lJYlAjamSKUFARqkCRrzKgWUwWxNq5WTrRqRT5i/Bt3gkr/tcw8D/GFoNBiYM48J+aHQY1okYihKgMaP4iVIQqYDFZuB8nNXuyImN93noc8x5DO1c7pCWmnXGLs7zyPHyX/53alflz4c/VzklwJ0SML+veujt/lqhZYlAjamBCCHglL4r9xSgPlcNkMDGgUYuwbNcyzPxiJo5UHFHLEtwJePySxzG221gAkQP/1x9ajzV71+D45uPVrtW1VdeIGZkdPB14F5paBAY1ogYihIBP8qEkUILSQCmMRiM3TKcWY9muZbjjkzsgICLK8yvyMfWTqbiu13UoD5Zz4D/RGTCoETUAn+RDib8EpcFSbphOLY6syJj5xcxqIQ2AWrZ422K1zG6244KEC3BhwoVoVdgKN4y+AR6np9HqS6Rn/MtBVI/8kl+9g6YIhQGNWqT1eesjujtP5Xd9f4cbet+AvnF9YTVZIYdlbPpqE1xWVyPUkqhp4F8QonoQCAdQGihVN0x3W92wmCxaV4uoUSlCwdpDa/G3tX+r1fmDkwZjYPuBDVwroqZN89HML730EpKTk2G325GWloYNGzac9vySkhLce++9SEhIgM1mQ/fu3bFs2bJGqi1RpGA4iGPeYzhYchDHfcdhM9sQ64hlSKMWJa88D8//73kMXTAUmYsz8e3hb2v1vHaudg1cM6KmT9M7aosWLUJWVhZeffVVpKWlYd68ecjIyMDOnTvRrl31H+BQKITRo0ejXbt2WLx4MRITE3HgwAHExMQ0fuWpRQvJIZQFyrhhOrVYwXAQOXtzsGjrIqzev1odexZljcK488YhZ08OCn2FNY5TM8CAhKjK5TWI6PQ0DWpz587F1KlTMWXKFADAq6++ik8//RQLFizAI488Uu38BQsWoKioCGvXroXFUnnHIjk5+bSvEQwGEQwG1cdlZWUAAEmSIElSPb2T5qWqXdg+1UmyhPJQOUr8JQjKQTgsDkRbogEAcliul9eouk59XY9qj21/ZjsLdyL7p2ws2bEkYrbm4MTBuKHXDRjbdSwcFgdGJI3AXcvuggGGiLBmQOWSGrOGzQKUyokHVdj+2mL7/0YJKwiHww32d7Au1zUIIar/c6cRhEIhOJ1OLF68GBMmTFDLJ0+ejJKSEvznP/+p9pyxY8eiVatWcDqd+M9//oO2bdvixhtvxMMPPwyTqeYlDx577DHMnj27Wvm7774Lp9NZb++HiKi58sperClegxVFK7DLt0stb2VphUtbXYrLWl2GBFtCteetK1mH1/NeR6FUqJa1sbTBbYm3YXDM4EapO5Ee+Xw+3HjjjSgtLYXHc/oZzprdUSsoKIAsy4iLi4soj4uLw44dO2p8zt69e7Fq1SrcdNNNWLZsGXbv3o177rkHkiRh1qxZNT5nxowZyMrKUh+XlZUhKSkJ6enpZ2yclkqSJOTm5mL06NHqncuWSlZkVEiV2z0FwgHYzfYG3yxdDsv4Ye0P6D+kP0xmrrnWmNj2vxFCYH3eemRvy8ay3csQCAcAAGajGaM7j0Zm70wM7zj8tLOaL8AFuEu5CxsOb1B3Jkhtn3rKtQTZ/tpi+/+mxF+C+Kh4xNhjGuT6Vb17tdGkZn0qioJ27drhn//8J0wmEwYOHIi8vDw8++yzpwxqNpsNNputWrnFYmnxIeRMWnIbyYqsbvfklbywm+1obW/dqCuhm8ymFv/LUistue2PlB/BB9s+wKKti7C/dL9a3r11d0zsMxHX9rwWbZxtan09E0y4OPniOtWhJbe/HrD9AaPZCLPZ3GB/A+tyXc2CWps2bWAymXD06NGI8qNHjyI+Pr7G5yQkJMBisUR0c/bs2RP5+fkIhUKwWrkBL52bEzdMr5AqYDPZuGE6NXshOYQVe1fgva3vYfX+1VCEAgBwW90Yf954ZPbOxAUJF/DngEgDmgU1q9WKgQMHYuXKleoYNUVRsHLlSkybNq3G5wwdOhTvvvsuFEWB0Vi5ssjPP/+MhIQEhjQ6J4pQ4A15UeQvQnmoHFaTFTH2GO7HSc3az4U/I3trNhZvW4xC/2/jyNIS0zCxz0Rc2f1KOC0cy0ukJU27PrOysjB58mQMGjQIqampmDdvHrxerzoL9Oabb0ZiYiLmzJkDALj77rvx4osvYvr06bjvvvuwa9cuPPXUU7j//vu1fBvUhJ24YXpZsAxmo5kBjZq18mA5Pvn5E7y39T1sOrJJLW/naofre12PzD6ZSIlN0bCGRHQiTYNaZmYmjh8/jpkzZyI/Px8DBgzA8uXL1QkGBw8eVO+cAUBSUhI+//xzPPjgg+jXrx8SExMxffp0PPzww1q9BWqiqjZMLw5UBjSjwQiPzcMN06lZEkJgQ94GZP+UjU92fgJ/2A+gcvPzUV1GYWKfibi086Xc7oxIhzT/qZw2bdopuzpXr15drWzw4MH43//+18C1ouZKCAF/2I9ifzFKA6UwGAyIskYxoFGzdLTiKBZvW4zsn7Kxt3ivWp4Sm4JJfSbh2l7XcncAIp3TPKgRNZaqDdNLAiUQENwwnZolSZawat8qvLf1PazatwqyqFy81Glx4qruV2Fi34kYlDCIEwOImgj+laJmLxAOVAY0fwkUocBldXEvTmp2dhftVicGHPcdV8sHtR+ESX0mYVz3cXBZXRrWkIjOBoMaNVvBcFC9gxZWwnBZXbCaODuYmg9vyKtODPju8HdqeRtnm8qJAb0z0a11Nw1rSETnikGNmp2QHEJpoBTF/mJIigSnxYkoW5TW1SKqF0IIfHfkO2RvycbHP38Mn+QDUDkx4NLOl2JSn0m4tPOlvGtM1EwwqFGzIclSZUALFCMoB+G0OOG2ubWuFlG9OO49rk4M2F20Wy3vHNMZk/pMwnW9rkOcO+40VyCipohBjZq8sBJW76AF5AAcZgdaOVppXS2icxZWwli1bxUWbV2EFftWIKyEAQAOswPjzhuHib0nIjUxlRMDiJoxBjVqssJKGOXBchT5i+CX/HBYGNCoedhTvAfvb30fH2z7AEe9v22zd0HCBZjYeyKuOu8qducTtRAMatTkyIqM8lA5Cn2F8If9sJvtiHVwP05q2nySD//9+b/I3pqN9Xnr1fLWjta4tte1mNh7Is5rc56GNSQiLTCoUZOhCEW9g+aVvNwwnZo8IQS+z/8e2Vuz8Z+d/0FFqAIAYDQYMTJ5JCb1mYRRXUZxtjJRC8agRrqnCAUVoQoU+SoDmsVkYUCjJq3QV4jF2xdj0dZF2Fm4Uy1Pjk5GZp9MXN/reiREJWhYQyLSCwY10i0hBCpCFSgOFKM8WA6z0YxoezQ3TKcmSVZkrN6/Gtlbs5GzN0edGGA323FFtyswqc8kpHVI4+ebiCIwqJHuCCHglbwo9hejPFQOo8HIgEZN1v6S/cjemo0Ptn2A/Ip8tXxA3ABM7DsR488bD4/No2ENiUjPGNRIN4QQ8Ek+lARKuGE6NWl+yY9Pd32K7K3ZWPfLOrU81h6rTgzo2banhjUkoqaCQY10wSf5UOIvQWmwlBumU5MkhMAPR39A9tZsLN2xFOWhcgCAAQaMTB6JzD6ZSO+SDpvZpnFNiagp4V9C0pRf8qt30BShMKBRk1PkL8KS7UuQvTUb2wu2q+Udozviht434IbeNyAxKlHDGhJRU8a/iKSJQDiA0kCpumG62+rm3oTUZMiKjK8Pfo33tr6HnD05CMkhAIDdZMfYbmOR2ScTQ5KGcFwlEZ0zBjVqVMFwEGXBMhT7ixFSQnBb3YgycYV1ahoOlh7Eoq2L8P6293G4/LBa3rddX0zsMxETekxAjD1GuwoSUbPDoEaNIiSHUBYoUzdMd1lc3DCdmgS/5Mfy3cvx3tb38M2hb9TyGFsMrul5DTL7ZKJPuz4a1pCImjMGNWpQkiypd9ACcgBOixOtrNyPk/Rvy9EteG/re1i6YylKg6UAKicGDOs0DBP7TERGSgbsZrvGtSSi5o5BjRpExIbpYT8cZm6YTvpXEijBf4//F//37v/hp4Kf1PIOng7I7J2JG3rfgA6eDhrWkIhaGgY1qlcnb5juMDu43RPpmiIUrDm4Btlbs7F893IE5SAAwGqy4vKul2Nin4m4uOPFnBhARJpgUKN6ISty5X6cv26YbjfbGdBI134p+wXv//Q+Fv20CL+U/aKWJ9uTMSVtCq7tdS1iHbEa1pCIiEGNztGJG6ZXSBWwmWwMaKRbgXAAn+/+HNk/ZePrA19DQAAAom3RuLrH1bi+5/WQdki4oP8FMJm5IwYRaY9Bjc6KIhR4Q14U+YtQHiqH1WRFjD2G3UOkSz8d/wnZW7KxZPsSlARL1PKLO16Mib0nYkzXMXBYHJDDMjbt2KRdRYmITsKgRnVy4obpZcEymI1mBjTSpdJAKT7a8RGyt2Zjy7EtanmCOwGZvTOR2ScTHaM7alhDIqIzY1CjWqnaML04UIzSQClMRhM8Ng83TCddUYSCtYfWIntrNj7b9RkCcgAAYDFakNE1A5P6TMKwjsP4uSWiJoNBjc7IJ/lQ7K8MaAaDgQGNdCevPA/v//Q+3v/pfRwsPaiW92zTExP7TMQ1Pa/h8jBE1CQxqNEpBaQACgIFKAmUQEBww3TSlWA4iJy9Ocjeko0vD3ypTgyIskZhQo8JmNRnEvrF9ePEFiJq0vhXl6oJhivXkTpYehAGkwEuq4sbppNubD++Hdk/ZePDbR+iOFCslg/uMBiT+kzC2G5j4bA4NKwhEVH9YVAjVTAcREmgBIUVhQAAu8UOh41/8Eh7ZcEyLN2xFIu2LsLmo5vV8nh3PG7ofQNu6HUDOsd21q6CREQNhEGNEJJDKA2UothfDEmRYDPZAFSuzE6kFSEE1v2yDtlbs/Hprk8RCP82MWB0ymhM6jMJIzqN4HhJImrWGNRaMEmWKgNaoBhBOQinxQm3zQ05LGtdNWrBjpQfwQfbPsCirYuwv3S/Wt69dXdM7DMR1/W8Dq2drbWrIBFRI2JQa4HCSli9gxaQA9wwnTQXkkNYsXcF3tv6HlbvXw1FKAAAt9WN8eeNx8Q+E3F+/PmcGEBELQ6DWgsSVsIoD5ajyF8Ev+SHw8KARtr6ufBnvLf1PXy47UMU+gvV8osSL0Jmn0xc2f1KOC1ODWtIRKQtBrUWQFZklIfKUegrhD/sr9ww3cH9OEkb5cFyfLzzY7y39T18n/+9Wh7nisP1va5HZp9MdIntomENiYj0g0GtGVOEot5B80pebphOmhFCYEPeBry39T389+f/wh/2AwDMRjNGdR6FiX0n4pLkS7hOHxHRSfhbsRlShIKKUAWKfEWokCpgNVkZ0EgTRyuO4oNtHyB7azb2lexTy7u26opJfSbh2p7Xoq2rrYY1JCLSNwa1ZkQIgYpQBYoDxSgPlnPDdNKEJEtYuW8lsrdmY9W+VZBF5Sxil8WFq867Cpl9MjEoYRD/4UBEVAsMas2AEAJeyYtifzHKQ+UwGoyItkczoFGj2l20G9lbs7F422Ic9x1Xyy9sfyEm9ZmEK7tfCZfVpWENiYiaHga1JkwIAZ/kQ0mgRN0wPcoaxQVAqdF4Q1588vMneG/re/ju8HdqeVtnW3ViQNdWXTWsIRFR08ag1kT5JT+K/cUoDZZyw3RqVEIIfHfkO2RvycbHP38Mn+QDAJgMJlza+VJM6jMJl3a+lPvDEhHVA/5lb2L8kl+9g6YIhRumU6M57j2OxdsWI/unbOwu2q2Wd4ntgom9J+K6Xtchzh2nYQ2JiJofBrUmIhAOoDRQipJACcJKGG6rmwGNGlxYCWPVvlXI3pqNFXtXqBMDHGYHxp03DpP6TMKF7S/kxAAiogbCoKZzwXAQZcEyFPuLEVJCcFvdiDJFaV0taub2FO/Boq2L8MG2D3DMe0wtvyDhAkzqMwlXnXcV3Fa3hjUkImoZGNR0KiSHUBYoUzdMd1lccNv4h5Eajk/y4ZOfP8GirYuwPm+9Wt7a0RrX9boOE/tMRPfW3TWsIRFRy8OgpjOSLKl30AJyAE6LE62s3I+T6k5WZKzPW49j3mNo52qHtMS0ajOChRDYdGQTFv20CP/Z+R9UhCoAAEaDEZckX4JJfSbhsi6XwWqyavEWiIhaPAY1neCG6VSflu1ahplfzMSRiiNqWYI7AY9f8jjGdhuLAl8BFm9bjEU/LcLPhT+r5yTHJGNin4m4rud1SIhK0KLqRER0AgY1jZ28YbrD7OCG6XROlu1ahjs+uQMCIqI8vyIfUz+ZigviL8CPx35EWAkDAOxmO67sfiUm9p6IizpcxM8eEZGOMKhp5OQN0+1mO/fjpHMmKzJmfjGzWkgDoJZtyt8EADg//nxk9snE+PPGw2PzNGo9iYiodhjUGtmJG6Z7JS83TKd6tT5vfUR356k8l/4cJvaZ2Ag1IiKic8Gg1kiqNkwv8hehPFQOq8nK/Tip3ihCwfdHvsdrm16r1fl2s72Ba0RERPWBQa2BnbhhelmwDGajGTH2GAY0Omc+yYevD3yNnD05WLFvBQp8BbV+bjtXuwasGRER1RcGtQZStWF6caAYpYFSmIwmeGwebphO5yS/Ih8r9q5A7t5crDmwBgE5oB7z2DwY2Wkkvjr4FUoDpTWOUzPAgISoBKQlpjVmtYmI6CwxqDWQoxVHUeQvgsFgYECjsyaEwPaC7cjZk4PcPbnYfHRzxPEkTxLSU9KRnpKOtMQ0WEwWddanAYaIsGZA5TjI2SNn8/NIRNREMKg1gKruTpvZBofFoXV1qIkJySFsLt+MpauXIndfLvLK89RjBhhwfsL5GN1lNNJT0nFe6/OqTUQZ220s/jnun9XXUYtKwOyRszG229hGey9ERHRuGNSIdKDYX4xV+1Yhd28uvtj3BSqkCvWY3WzH8E7Dkd4lHZd1uaxW48vGdhuLjJSMM+5MQERE+sagRqSRvcV7kbs3F7l7crEhbwNkIavHYs2xGHPeGGR0y8DFSRef1Z1Zk9GEIUlD6rPKRETUyBjUiBqJrMjYdGQTcvbkIGdvDnYX7Y443rNNT4xOGY1RnUYhvDOMQSMGwWTmHTAiopaMQY2oAXlDXnx54Evk7MnByn0rUeQvUo+ZjWYM7jAY6SnpGN1lNJKikwAAcljGpp83aVVlIiLSEQY1onp2uPxw5RIae3Kx5tAahOSQeizaFo3LOl+G0SmjMTJ5JLduIiKi02JQIzpHQgj8dPynyi7NPTnYcmxLxPHk6GSkd628a3Zh+wthMVk0qikRETU1DGpEZyEYDmLtobXI2Vu5vtmJy2AYYMDA9gOR3qVyfbOurbpyL1ciIjorDGpEtVTkL1J3Bfhy/5fwSl71mMPswMjkkRidMhqXdb4MbZxtNKwpkb4IIRAIV+6iYTKaYDFa+I8XolpiUCM6jd1Fu5G7Jxc5e3Pw3eHvoAhFPRbvisfolNEY3WU0hnYcyo3OiU4SVsLwST7Iiqz+fITCIfgUn7prhslogtlohtlohkEwvBGdjEGN6ARhJYzvDn+njjfbV7Iv4njvtr3VLZv6tuvLuwJENQiGg/BJPhgNRritbkTbo+GyuGA0GBFWwggrYUiKhLASRiAcQCAcgCRLCIaCACoXgLZarTAbzTAZKoMcF2umlopBjVq88mA5Vh9Yjdw9uVi5byVKAiXqMYvRgqFJQ9U7Z4meRO0qSqRjilDU0GUz2dDG2QZRtig4zI6If9BYTBZYTBY48NsizkIIyEKGP+DHHuxBQlQCZMgIhANqmJOFDAMMMBqManCzGC0McNTsMahRi5RXlofcvbnI2ZODtYfWQlIk9ViMPQajuoxCepd0jEgeAbfVrWFNifTtxO5Nh8WBxKhEuKwuWE3WWl/DYDDAbDDDbqnsHo2xx8BisajXP/ErGA6qd+C8Ya+6o4fBYFC7UKvuxPGONzUHDGrUIihCwZajW9RdAbYd3xZxPCU2Rd3ofGD7gTAb+aNBdDqBcAB+yQ+TwQS3zY1oWzScFme93+GqCl4nkxU5ogs1JIfUAOeX/JCFDEUoMMAAi8midqGajWYGOGpS+NeImi2/5Mc3h76p3BVg70rke/PVY0aDERe2vxDpKekY1WUUurbqqmFNiZoGRSjwS34E5SBsJhvautoiyhoFu9ne6OHHZDTBZDTBBlu1Okqy9NtYOFlCIBxAUA6qXalV1LtvnIlKOsagRs3Kce9xrNy3Erl7cvHlgS/hD/vVYy6LCyOTRyI9JR2Xdr4UrRytNKwpUdMhyRJ8kg+KUOC0ONHW1RYui0uXizcbDUbYzLYaA9yJXaihcEgNbzXNRK0a/2Y2mmE0GLV4K0QAGNSoiRNCYFfRLnWW5qYjm9RftgDQPqq92qU5uMNg2My201yNiKpUrX0WCAdgMpjgsXkQba/s3myKwcVoMMJqsv42du7XXwVCiNPORK3qRgUQMf6NM1GpsTCoUZMjyRI25G1Azt4crNizAvtL90cc7xfXD+ld0jE6ZTR6t+3N7gyiOpAVGf6wHyE5BLvJjjhXHNw2d7NdJ9BgMJx2JuqJ3ahVExmqwlzVuoqciUoNiUGNmoTSQClW71+N3L25WLVvFUqDpeoxm8mGoR2HVo436zwKCVEJGtaUqGkKySH4JB8AwGl2Is4VB5fV1WIn1lTNRK3p/dc0E9Uv+RFWwpyJSvWuZf4EUpNwsPSguivA/375X8Qg4NaO1hjVZRRGdxmN4Z2Gw2V1aVhToqapqnvTH/bDYrQg1h6LKFtUk+3ebCxnOxM1rIQhIH67A8eZqFQLDGqkG4pQsDl/M3L2VG50vqNwR8Txbq26IT2lskvzgvgL2L1AdJZkRYZP8kFSJDjMDsS74pt192ZjqctM1Kru5VPNRGWAoyq6CGovvfQSnn32WeTn56N///544YUXkJqaWuO5b731FqZMmRJRZrPZEAgEGqOqVM/8kh9fH/waOXtysGLvChz3HVePmQwmpCamVoazLqPRObazhjUlavqquugAwGV1Id4e36K7NxvL2cxEDYaD8CpezkQl7YPaokWLkJWVhVdffRVpaWmYN28eMjIysHPnTrRr167G53g8HuzcuVN9zH9xNC3HvMewYu8K5OzJwdcHvkZA/i1kR1mjcEnnS5DeJR0jk0ci1hGrYU2Jmj4hBPxhPwLhAKxGK2IdsfDYPHBanPzdqTHORKXa0DyozZ07F1OnTlXvkr366qv49NNPsWDBAjzyyCM1PsdgMCA+Pr4xq0nnQAiBHQU7kLO3skvz+/zvI4538HRQZ2le1OGiOm09Q0Q1O3FrJ7vZjgR3AtxWN5eoaQLOZiaqpEicidpMaRrUQqEQNm7ciBkzZqhlRqMRo0aNwrp16075vIqKCnTq1AmKouCCCy7AU089hd69e9d4bjAYRDAYVB+XlZUBACRJgiRJNT7nXAkhIIcr/7UjG+QGeY2GpNY9fPZ1D8khrM9bj9x9lRudHyo7FHF8QNwAjO4yGqM7j8Z5rc/77V/24txetzmoj/ans9Mc2r6qe9NgMMBtdcPj8sBp/nVrJ4EG+71XH6rqpuc66oEZv05mMAJuc+VexGElHDGZISSHEJACkMIS/IofilAgICpD4AldqCd2ezeHz399UcIKwuFwg30W63JdTYNaQUEBZFlGXFxcRHlcXBx27NhR43POO+88LFiwAP369UNpaSn+9re/YciQIfjpp5/QoUOHaufPmTMHs2fPrlaek5MDp9NZP2+kmfph7Q91Or88XI5NZZvwbdm32FS2CT7Fpx6zGqzoH9UfqdGpGOgZiFaWVoAf8G3z4Xt8f5qrtlx1bX+qP2x7beXm5mpdhRaNn/9Ke7G3wa7t8/nOfNKvNO/6rKvBgwdj8ODB6uMhQ4agZ8+e+Mc//oEnnnii2vkzZsxAVlaW+risrAxJSUlIT0+Hx+NpkDoKIbC/ZD8AwGFxnP5kHZLDMn5Y+wP6D+kPk/n0t8v3l+zHin0rkLs3FxsOb1DHTQBAW2dbXJZ8GUZ1GYVhScOaZFtooS7tT/WrqbV9VfemoiiwW+yIscfAaXE22eEDkiQhNzcXo0ePhsWiv+2pmhNFKAjLv05kEJUzUb0BL7b+byu6DOwCnDBX4cS7by1lJmqJvwTxUfGIscc0yPWrevdqQ9Og1qZNG5hMJhw9ejSi/OjRo7Ueg2axWHD++edj9+7dNR632Wyw2aqPybBYLA32i0AIof6Sbwq/7E/FZDZVq7+syNiUv6lyfbM9OdhVtCvieI/WPTA6pXLLpgHxAzgz6RzU1P7UOPTe9oFwAH7JD5PBhGhnNKJtlVs7NZdxSA35+5l+c/IsVMkpYSu2okubLjCYDNVmolZNamgJM1GNZiPMZnODfQ7rcl1Ng5rVasXAgQOxcuVKTJgwAQCgKApWrlyJadOm1eoasixjy5YtGDt2bAPWtGXzhrz46sBXyN2bixV7V6DQX6geMxvNuKjDRepkgI7RHTWsKVHzpQgFfsmPoByE3WRHW1dbRFmjYDfbW8QdDmo8VpP1tyBRy5movpAPChQYYFCDG2ei1g/Nuz6zsrIwefJkDBo0CKmpqZg3bx68Xq86C/Tmm29GYmIi5syZAwB4/PHHcdFFF6Fr164oKSnBs88+iwMHDuD222/X8m00O4WhQryz5R2s2L8C3xz8BkH5twkZ0bZoXNr5UozuMhojk0ci2h6tYU2JmjdJliq7N4UCl8WFtq62cFlcsJh4x4kaz+lmop68pVbVOnCnmomqLinCAFcrmge1zMxMHD9+HDNnzkR+fj4GDBiA5cuXqxMMDh48CKPxt9upxcXFmDp1KvLz8xEbG4uBAwdi7dq16NWrl1ZvoVkQQuCn4z8hd08uPt/zObYc2wJs++14p+hOlV2aXdKRmpjKPxJEDahqa6dAOACTwQSPzYNoezS3diLdOTHAnezE8CbJlTNRq7bSCoaDkIWsbql1qpmopIOgBgDTpk07ZVfn6tWrIx4///zzeP755xuhVs1fMBzEul/WVW7ZtDcXh8sPq8cMMOCC+AuQ3jUd6Snp6NaqG7tXiBqYrMjq1kJ2kx1xrjhu7URNFvdErR+6CGrUeIr8RVi1bxVy9uRg9f7V8Epe9ZjD7MCITiNwWfJlaJvfFpdedqmuB1QTNRchOQSf5IMQAi6LC3GuOG7tRM0W90StG/4WaAH2FO9RZ2l+e/hbdbwAAMS54jCqyyikp6RjaNJQOCwOyGEZmwo3aVhjouavqnvTH/bDYrQg1l65tZPD4mD3JrVIddkTNRAOICgH1T1RqyYynDj+rbnMRGVQa4bCShgbD29UuzT3FO+JON6rbS+kd6ns0uwb17dZfJCJmgpZkeGTfJAUCQ6zA/GueHZvEp3GmfZErepCre1MVIvJ0qT+7jGoNRMVoQqs3r8auXtzsXLvShQHitVjFqMFQ5KGVG7ZlDIaHTzVd3AgooZVtbUTALisLsTb49m9SXQOTjWRobnNROVviCYsrzwPuXtykbsnF2t/WYuQHFKPxdhjcGnnS5Geko6RnUYiyhalYU2JWiYhBPxhPwLhAKxGK2Idld2bTouzWY+pIdJSXWaiVm1qf/JMVFnRz36nDGpNiBACW45tQc6eHOTsycFPx3+KOJ4ck4yMlAykp6RjUPtB/Jc6kUaqtnaSFRl2sx0J7gS4rW7YzNV3SSGixlOXmah62YqNf8l1LhAO4JuD3yB3by5y9+YivyJfPWY0GDGo/SB1V4CU2BT+K51IQ8FwED7JB6PBCLfVjWh7NFwWly67U4joN6eaiaoHDGo6VOgrrNzofE8uvjzwJXySTz3mtDgxstNIjE4Zjcs6X4bWztYa1pSIFKGoA5htJhvaONsgyhYFh9nBfzgR0TljUNMBIQR2F+2u7NLcm4ONhzeqm94CQLw7Hukp6Ujvko7BSYM5O4xIB07s3nRYHEiMSoTL6tJNdwkRNQ8MavVMVmR8deAr/HD0B7R1tsXwTsNr7PYIK2FsyNugLqGxv2R/xPG+7fpWhrOUdPRu25v/MifSiUA4AL/kh8lggtvmRrStcmsndm8SUUNgUKtHS7YvwfTl0/FL2S9qWYI7AY9f8jjGdhuLsmBZ5RIae3Kxat8qlARL1POsJisuTroYo1JGYVSXUUiMStTgHRBRTRShwC/5EZSDsJvsaOtqiyhrFOxmO/8RRUQNikGtnizZvgTXvX9dRJclABypOIKpn0xFzzY9satoV8QWGLH2WHVXgOGdhsNtdTd2tYnoNCRZgk/yQREKXBYX2rrawmVx1Tjtn4ioITCo1QNZkTF9+fRqIe1E2wu2AwC6tuqq7gpwQcIF7C4h0iG/5IckSTAZTPDYPIi2V3ZvNqXVzImoeWBQqwdfH/w6orvzVOaPmY/rel3XCDUiorqSFRkVoQoAlRN84txx3NqJiDTHoFYPjpQfqdV5XICWSH9Ccgg+yQchBOzGylDWMaYjHDaHxjUjImJQqxcJUQm1Oq+dq10D14SIakMIUTl7M+yHxWhBrL1yayczzNiKrfxHFRHpBn8b1YNhHYehg6cD8sryahynZoABCVEJSEtM06B2RFRFVmT4JB8kRYLD7EC8Kx5Rtih1aydJkjSuIRFRJI6MrQcmownzx8wHUBnKTlT1ePbI2Zw4QKSRYDiIEn8JyoPlsJvtSPIkoVNMJ7RxteH+m0Skawxq9eSantdg8Q2LkeiJXP8sISoB/xz3T4ztNlajmhG1TEII+CQfivxFkGQJrZyt0CmmEzpGd0S0PZrdm0TUJPA3VT26puc1GH/e+FrtTEBEDePErZ3sZjsS3AlwW928c0ZETRKDWj0zGU0YmTwSHaM7qo+JqOEFw0H4JB+MBiPcVjei7dFwWVz8GSSiJo1BjYiaLEUoCIQDCIQDsJlsaONsgyhbFBxmB7d2IqJmgUGNiJqcE7s3HRYHEqMS4bK6YDVZta4aEVG9YlAjoiYjEA7AL/lhMpjgtrkRbavc2ondm0TUXDGoEZGuKUKBX/IjKAdhN9nR1tUWUdYo2M12dm8SUbPHoEZEuiTJUuXWThBwmp1o62oLl8UFi8middWIiBoNgxoR6UbV1k6BcAAmgwkemwfR9sruTaOByz4SUcvDoEZEmpMVGf6wHyE5BLvJjjhXHNw2N+xmu9ZVIyLSFIMaEWkmJIcquzeFgMviQpwrDi6ri7sGEBH9ir8NiahRVXVv+sN+WIwWxNpj4bF54LA42L1JRHQSBjUiahSyIsMn+SApEhxmB+Jd8YiyRXFrJyKi02BQI6IGFQwH4Zf8AAC3zY14Wzy7N4mIaom/KYmo3gkh4A/7EQgHYDVa0crZClHWKDgtTq59RkRUBwxqRFRvTtzayW62I8GdALfVze5NIqKzxKBGROesamsno8EIt9WNaHs0XBYXt3YiIjpHDGpEdFYUoaiL09pMNrRxtkGULQoOs4Pdm0RE9YRBjYjq5MTuTYfFgcSoRLisLlhNVq2rRkTU7DCoEVGtVHVvmgwmuG1uRNsqt3Zi9yYRUcNhUCOiU1KEAr/kR1AOwm6yo62rLaKsUbCb7ezeJCJqBAxqRFSNJEuVWztBwGl2oq2rLVwWFywmi9ZVIyJqURjUiAjAb1s7BcIBmI1meGweRNsruze5tRMRkTYY1IhaOFmR4Q/7EZJDsJvsiHPFwW1zw262a101IqIWj0GNqIUKyaHK7k0h4LK4EOeK49ZOREQ6w9/IRC1IVfemP+yHxWhBrD0WHpsHDouD3ZtERDrEoEbUAsiKDJ/kg6RIcJgd3NqJiKiJYFAjakYUoUBWZChCUb8kWQIAuG1uJNgT4LQ42b1JRNRE8Lc1kY4JIdTAJQtZfSyLyjAmhICAgAGVa5oZDUaYDCYYDUYYDAZYjBZ4bB64rW44LU6ufUZE1MQwqBE1shPvdp38JSsylLACACj2F8NsNsNoMFYGMKMJBoMBNpMNFqMFFqMFJqMp4rj6/yeENSIiaroY1IjqQU1djid+nXjXywBDtVBlN9lhNporuyQFsBd70TG6I2xWm3peVRgjIqKWg0GNqAZn0+VYFbqquhwtpsovs9EccZfr5LtfJ8+2lKTKMWUuqwsWC3cCICJqyRjUqMUQQqhBq6YuxxMZYIgIUkajETaTDWajGRbjb+GLXY5ERNSQGNSoSYsY2/VrF+OJXZB16XI0GU01hq6qL4YvIiJqbAxqpCsndjlWu+v1axckADWAndzlaDaY4bA6TtnlePIdMCIiIj1jUKMGd7oux6rxXieKCFan6XKsqduRd72IiKg5YVCjs3KmLkfgt7teVXe+TgxVVUtMsMuRiIjo1BjUCEBkl6MUrpx16A15YZANp+1yrPoyG8ywW+zqTMeaQhe7HImIiOqGQa0Zq2lJiZO7IKsG2gO/dTkKpTKU2cw22Ky23wbbnyJ0scuRiIioYTCoNTE1dTme+Bg4dZejwWCA3WSH1WitscuxKnTJYRk7sAMdPB24jhcREZGGGNQ0drpZjieO9wIqA9jJ47fMBjPMJnP9djkqZz6FiIiIGh6DWgOShYxAOFCty/HkWY4nL5RqNVnV5SVO1+XI8V5ERETNG4NaA7EYLZDDlYPwq7ocT95I+1QzHTnei4iIiAAGtQZhMBjQ3tMeQgg1jBERERHVFYNaAzEb2bRERER0bnirh4iIiEinGNSIiIiIdIpBjYiIiEinGNSIiIiIdIpBjYiIiEinGNSIiIiIdIpBjYiIiEinGNSIiIiIdIpBjYiIiEinGNSIiIiIdIpBjYiIiEinGNSIiIiIdIpBjYiIiEindBHUXnrpJSQnJ8NutyMtLQ0bNmyo1fOys7NhMBgwYcKEhq0gERERkQY0D2qLFi1CVlYWZs2ahU2bNqF///7IyMjAsWPHTvu8/fv3449//COGDRvWSDUlIiIialyaB7W5c+di6tSpmDJlCnr16oVXX30VTqcTCxYsOOVzZFnGTTfdhNmzZ6NLly6NWFsiIiKixmPW8sVDoRA2btyIGTNmqGVGoxGjRo3CunXrTvm8xx9/HO3atcNtt92Gr7/++rSvEQwGEQwG1cdlZWUAAEmSIEnSOb6D5qmqXdg+2mD7a4dtry22v7bY/o2nLm2saVArKCiALMuIi4uLKI+Li8OOHTtqfM6aNWvwxhtvYPPmzbV6jTlz5mD27NnVynNycuB0Outc55YkNzdX6yq0aGx/7bDttcX21xbbv+H5fL5an6tpUKur8vJy/P73v8drr72GNm3a1Oo5M2bMQFZWlvq4rKwMSUlJSE9Ph8fjaaiqNmmSJCE3NxejR4+GxWLRujotDttfO2x7bbH9tcX2bzxVvXu1oWlQa9OmDUwmE44ePRpRfvToUcTHx1c7f8+ePdi/fz/GjRunlimKAgAwm83YuXMnUlJSIp5js9lgs9mqXctisfCDeAZsI22x/bXDttcW219bbP+GV5f21XQygdVqxcCBA7Fy5Uq1TFEUrFy5EoMHD652fo8ePbBlyxZs3rxZ/brqqqtwySWXYPPmzUhKSmrM6hMRERE1KM27PrOysjB58mQMGjQIqampmDdvHrxeL6ZMmQIAuPnmm5GYmIg5c+bAbrejT58+Ec+PiYkBgGrlRERERE2d5kEtMzMTx48fx8yZM5Gfn48BAwZg+fLl6gSDgwcPwmjUfBURIiIiokaneVADgGnTpmHatGk1Hlu9evVpn/vWW2/Vf4WIiIiIdIC3qoiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKcY1IiIiIh0ikGNiIiISKfMWldAr2RZhiRJWldDE5IkwWw2IxAIQJZlravT4ui9/S0WC0wmk9bVICJqERjUTiKEQH5+PkpKSrSuimaEEIiPj8ehQ4dgMBi0rk6L0xTaPyYmBvHx8bqtHxFRc8GgdpKqkNauXTs4nc4W+YdIURRUVFTA7XbDaGTveGPTc/sLIeDz+XDs2DEAQEJCgsY1IiJq3hjUTiDLshrSWrdurXV1NKMoCkKhEOx2u+6CQkug9/Z3OBwAgGPHjqFdu3bsBiUiakD6+yugoaoxaU6nU+OaEOlb1c9ISx3HSUTUWBjUatASuzuJ6oI/I0REjYNBjYiIiEinGNQaiiwDq1cD771X+V8dLrNwJl26dMG8efNqff7q1athMBha9IxZIiKi+sSg1hCWLAGSk4FLLgFuvLHyv8nJleUNwGAwnPbrscceO6vrrl+/HnfccUetzx8yZAiOHDmC6Ojos3o9IiIiisRZn/VtyRLguusAISLL8/IqyxcvBq65pl5f8siRI+r/L1q0CDNnzsTOnTvVMrfbrf6/EAKyLMNsPvO3vm3btnWadWi1WhEfH1/r85sKSZJgsVi0rgYREbVAvKN2JkIAXm/tvsrKgPvvrx7Sqq4DANOnV55Xm+vVdJ0axMfHq1/R0dEwGAzq4x07diAqKgqfffYZBg4cCJvNhjVr1mDPnj0YP3484uLi4Ha7ceGFF2LFihUR1z2569NgMOD111/H1VdfDafTiW7duuHjjz9Wj5/c9fnWW28hJiYGn3/+OXr27Am3240xY8ZEBMtwOIz7778fMTExaN26NR5++GFMnjwZEyZMOOX7PXDgAMaNG4fY2Fi4XC707t0by5YtU4//9NNPuPLKK+HxeBAVFYVhw4Zhz549ACqXvnj88cfRoUMH2Gw2DBgwAMuXL1efu3//fhgMBixatAgjRoyA3W7HwoULAQCvv/46evbsCbvdjh49euDll1+u1feHiIjobDGonYnPB7jdtfuKjq68c3YqQgC//FJ5Xm2u5/PV29t45JFH8PTTT2P79u3o168fKioqMHbsWKxcuRLff/89xowZg3HjxuHgwYOnvc7s2bNxww034Mcff8TYsWNx0003oaio6JTn+3w+/O1vf8Pbb7+Nr776CgcPHsQf//hH9fhf//pXLFy4EG+++Sa++eYblJWVYenSpaetw7333otgMIivvvoKW7ZswV//+lf1rmFeXh6GDx8Om82GVatWYePGjbj11lsRDocBAPPnz8dzzz2Hv/3tb/jxxx+RkZGBq666Crt27arWXtOnT8f27duRkZGBhQsXYubMmXjyySexfft2PPXUU3j00Ufxr3/967R1JSIiOieihSktLRUARGlpabVjfr9fbNu2Tfj9/t8KKyqEqIxYjf9VUVHn9/fmm2+K6Oho9fEXX3whAIilS5ee8bm9e/cWL7zwgpBlWRQXF4tOnTqJ559/Xj0OQPzlL385oWkqBADx2WefRbxWcXGxWhcAYvfu3epzXnrpJREXF6c+jouLE88++6z6OBwOi44dO4rx48efsp59+/YVjz32WI3HZsyYITp37ixCoVCNx9u3by+efPLJiLILL7xQ3HPPPUIIIfbt2ycAiHnz5kWck5KSIt59992IsieeeEIMHjz4lPU8W1XtL8tyvV+7vtT4s9IMhEIhsXTp0lN+fqhhsf21xfZvPKfLIifjGLUzcTqBioranfvVV8DYsWc+b9kyYPjw2r12PRk0aFDE44qKCjz22GP49NNPceTIEYTDYfj9/jPeUevXr5/6/y6XCx6PR91OqCZOpxMpKSnq44SEBPX80tJSHD16FKmpqepxk8mEgQMHQlGUU17z/vvvx913342cnByMGjUK1157rVqvzZs3Y9iwYTWOKSsrK8Phw4cxdOjQiPKhQ4fihx9+iCg7sb28Xi/27NmD2267DVOnTlXLw+EwJ04QEVGDYlA7E4MBcLlqd256OtChQ2X3Z03jywyGyuPp6UAjb7vjOuk9/PGPf0Rubi7+9re/oWvXrnA4HLjuuusQCoVOe52TA5DBYDhtqKrpfFHLsXencvvttyMjIwOffvopcnJyMGfOHDz33HO477771O2NztWJ7VXxa1B/7bXXkJaWFnEet08iIqKGxDFq9clkAubPr/z/k1dur3o8b16jh7SafPPNN7jllltw9dVXo2/fvoiPj8f+/fsbtQ7R0dGIi4vDt99+q5bJsoxNmzad8blJSUm46667sGTJEvzhD3/Aa6+9BqDyjt/XX39d49ZGHo8H7du3xzfffBNR/s0336BXr16nfK24uDi0b98ee/fuRdeuXSO+OnfuXNu3S0REVGe8o1bfrrmmcgmO6dMrJw5U6dChMqTV89IcZ6tbt25YsmQJxo0bB4PBgEcfffS0d8Yayn333Yc5c+aga9eu6NGjB1544QUUFxefdouiBx54AJdffjm6d++O4uJifPHFF+jZsycAYNq0aXjhhRcwceJEzJgxA9HR0fjf//6H1NRUnHfeeXjooYcwa9YspKSkYMCAAXjzzTexefNmdWbnqcyePRv3338/oqOjMWbMGASDQXz33XcoLi5GVlZWvbYJERFRFQa1hnDNNcD48cDXXwNHjgAJCcCwYbq4k1Zl7ty5uPXWWzFkyBC0adMGDz/8MMrKyhq9Hg8//DDy8/Nx8803w2Qy4Y477kBGRsZpuxRlWca9996LX375BR6PB2PGjMHzzz8PAGjdujVWrVqFhx56CCNGjIDJZMKAAQPUcWn3338/SktL8Yc//AHHjh1Dr1698PHHH6Nbt26nreftt98Op9OJZ599Fg899BBcLhf69u2LBx54oN7agoiI6GQGca4DhpqYsrIyREdHo7S0FB6PJ+JYIBDAvn370LlzZ9jtdo1qqD1FUVBWVgaPx1OnBW/r67V79uyJG264AU888USjvrZeaNn+tdVcf1YkScKyZcswduxYLnKsAba/ttj+jed0WeRkvKNGmjpw4ABycnIwYsQIBINBvPjii9i3bx9uvPFGratGRESkOX3+c51aDKPRiLfeegsXXnghhg4dii1btmDFihXqmDMiIqKWjHfUSFNJSUnVZmESERFRJd5RIyIiItIpBjUiIiIinWJQIyIiItIpBjUiIiIinWJQIyIiItIpBjUiIiIinWJQayCyImP1/tV4b8t7WL1/NWRF1rpKzcZbb72FmJgY9fFjjz2GAQMGnPY5t9xyCyZMmHDOr11f1yEiIqoNBrUGsGT7EiTPT8Yl/7oENy65EZf86xIkz0/Gku1LGvR18/Pzcd9996FLly6w2WxISkrCuHHjsHLlygZ9Xa398Y9/rPf3uH//fhgMBmzevDmifP78+Xjrrbfq9bWIiIhOhQve1rMl25fguvevg0DkFqp5ZXm47v3rsPiGxbim5zX1/rr79+/H0KFDERMTg2effRZ9+/aFJEn4/PPPce+992LHjh01Pk+SpCa/p5vb7Ybb7W6U14qOjm6U12lMoVAIVqtV62oQEVENeEftDIQQ8Ia8tfoqC5Th/s/urxbSAKhl0z+bjrJAWa2uJ0T165zKPffcA4PBgA0bNuDaa69F9+7d0bt3b2RlZeF///ufep7BYMArr7yCq666Ci6XC08++SQA4JVXXkFKSgqsVit69uyJ7OzsiDZ47LHH0LFjR9hsNrRv3x7333+/evzll19Gt27dYLfbERcXh+uuu67GOiqKgg4dOuCVV16JKP/+++9hNBpx4MABAMDcuXPRt29fuFwuJCUl4Z577kFFRcUp3/vJXZ+yLCMrKwsxMTFo3bo1/vSnP1Vry+XLl+Piiy9Wz7nyyiuxZ88e9Xjnzp0BAOeffz4MBgNGjhwJoHrXZzAYxP3334927drBbrfj4osvxrfffqseX716NQwGA1auXIlBgwbB6XRiyJAh2Llz5ynfTygUwkMPPYTExETY7XZ06tQJc+bMUY+XlJTgzjvvRFxcHOx2O/r06YP//ve/6vEPP/wQvXv3hs1mQ3JyMp577rmI6ycnJ+OJJ57AzTffDI/HgzvuuAMAsGbNGgwbNgwOhwNJSUm4//774fV6T1lPIiJqeLyjdgY+yQf3nPq5WyMg8Ev5L4j+a+3uylTMqIDL6jrjeUVFRVi+fDmefPJJuFzVzz9xPBdQGWyefvppzJs3D2azGR999BGmT5+OefPmYdSoUfjkk08wbdo0dOvWDZdddhk+/PBDPP/888jOzkbv3r2Rn5+PH374AQDw3Xff4f7778fbb7+NIUOGoKioCF9//XWN9TQajZg0aRLeffdd3H333Wr5woULMXToUHTq1Ek97+9//zs6d+6MvXv34p577sGf/vQnvPzyy7Vqt+eeew5vvfUWFixYgJ49e+K5557DRx99hEsvvVQ9x+v1IisrC/369UNFRQVmzpyJq6++Gps3b4bRaMSGDRuQmpqKFStWoHfv3qe84/SnP/0JH374If71r3+hU6dOeOaZZ5CRkYHdu3ejVatW6nn/93//h+eeew5t27bFXXfdhVtvvfWUW2e98MIL+Oyzz5CdnY3k5GQcOnQIhw4dAlAZdi+//HKUl5fjnXfeQUpKCrZt2waTyQQA2LhxI2644QY89thjyMzMxNq1a3HPPfegdevWuOWWW9TX+Nvf/oaZM2di1qxZAIA9e/ZgzJgx+H//7/9hwYIFOH78OKZNm4Zp06bhzTffrFW7ExFRAxAtTGlpqQAgSktLqx3z+/1i27Ztwu/3q2UVwQqBx6DJV0Wwolbvaf369QKAWLJkyRnPBSAeeOCBiLIhQ4aIqVOnqo9lWRYTJkwQl19+uRBCiOeee050795dhEKhatf78MMPhcfjEWVlZbWq6/fffy8MBoM4cOCA+lqJiYnilVdeOeVzPvjgA9G6dWv18Ztvvimio6PVx7NmzRL9+/dXHyckJIhnnnlGfSxJkujQoYMYP378KV/j+PHjAoDYsmWLEEKIffv2CQDi+++/jzhv8uTJ6nUqKiqExWIRCxcuVI+HQiHRvn179fW/+OILAUCsWLFCPefTTz8VACI+ZyeaNm2aGD58uAiHw9WOff7558JoNIqdO3fW+Nwbb7xRjB49OqLsoYceEr169VIfd+rUSUyYMCHinNtuu03ccccdEWVff/21MBqNNdazpp+V5iAUComlS5fW+Fmnhsf21xbbv/GcLoucjHfUzsBpcaJixqm73U701YGvMPbdsWc8b9mNyzC80/BavXZtiDp0kQLAoEGDIh5v375d7f6qkpaWhn/+858AgOuvvx7z5s1Dly5dMGbMGIwdOxbjxo2D2WzG6NGj0alTJ/XYmDFjcPXVV8PpdGLhwoW488471Wt+9tlnGDZsGHr27Il3330XjzzyCL788kscO3YM119/vXreihUrMGfOHOzYsQNlZWUIh8MIBALw+XxwOk/fJqWlpThy5AjS0tLUMrPZjEGDBkW0065duzBz5kysX78eBQUFUBQFAHDw4EH06dOnVu24Z88eSJKEoUOHqmUWiwWpqanYvn17xLn9+vVT/z8hIQEAcOzYMXTs2LHadSdPnoz09HT07NkTY8aMwZVXXon09HQAwObNm9GhQwd07969xjpt374d48ePjygbOnQo5s2bB1mW1TtvJ38GfvjhB/z4449YuHChWiaEgKIo2LdvH3r27HnG9iAiovrHMWpnYDAY4LK6avWVnpKODp4OMMBQ87VgQJInCekp6bW6nsFQ83VO1q1bNxgMhlNOGDhZTd2jp5OUlISdO3fi5ZdfhsPhwD333IPhw4dDkiRERUVh06ZNeO+995CQkICZM2eif//+KCkpwVVXXYXNmzerX1Xh4KabbsK7774LAHj33XcxZswYtG7dGkDlpIgrr7wS/fr1w4cffoiNGzfipZdeAlA5dqu+jBs3DkVFRXjttdewfv16rF+/vt5f40QnTtio+r5WhcOTXXDBBdi8eTNmz54Nv9+PG264QR3353A46qU+J38GKioqcOedd0Z8v3744Qfs2rULKSkp9fKaRERUdwxq9chkNGH+mPkAUC2sVT2eN2YeTEZTvb5uq1atkJGRgZdeeqnGwd8lJSWnfX7Pnj2rjZdav359xF0Uh8OBcePG4e9//ztWr16NdevWYcuWLQAq71iNGjUKzzzzDH788Ufs378fq1atQlRUFLp27ap+VYWMG2+8EVu3bsXGjRuxePFi3HTTTerrbNy4EYqi4LnnnsNFF12E7t274/Dhw7Vui+joaCQkJKjBCwDC4TA2btyoPi4sLMTOnTvxl7/8BZdddhl69uyJ4uLiiOtUjUmT5VOvf1c1+eLEtpMkCd9++y169epV6zrXxOPxIDMzE6+99hoWLVqEDz/8EEVFRejXrx9++eUX/PzzzzU+r6bv5TfffIPu3burd9NqcsEFF2Dbtm0R36+qL84IJSLSDrs+69k1Pa/B4hsWY/ry6fil7Be1vIOnA+aNmdcgS3MAwEsvvYShQ4ciNTUVjz/+OPr164dwOIzc3Fy88sor1briTvTQQw/hhhtuwPnnn49Ro0bh448/xieffIKcnBwAlQvMyrKMtLQ0OJ1OvPPOO3A4HOjUqRP++9//Yu/evRg+fDhiY2OxbNkyKIqC884775Svl5ycjCFDhuC2226DLMu46qqr1GNdu3aFJEl44YUXMG7cOHzzzTd49dVX69QW06dPx9NPP41u3bqhR48emDt3bkRYjY2NRevWrfHPf/4TCQkJOHjwIB555JGIa7Rr1w4OhwPLly9Hhw4dYLfbqy3N4XK5cPfdd+Ohhx5Cq1at0LFjRzzzzDPw+Xy47bbb6lTnEz3//POIjo7GkCFDYDab8cEHHyA+Ph4xMTEYMWIEhg8fjmuvvRZz585F165dsWPHDhgMBowZMwZ/+MMfcOGFF+KJJ55AZmYm1q1bhxdffPGMEzEefvhhXHTRRZg2bRpuv/12uFwubNu2Dbm5uXjxxRfP+r0QEdE5augBc3pT18kEZyssh8UX+74Q7/74rvhi3xciLFcfGF7fDh8+LO69917RqVMnYbVaRWJiorjqqqvEF198oZ4DQHz00UfVnvvyyy+LLl26CIvFIrp37y5eeeUVIcuyEEKIjz76SKSlpQmPxyNcLpe46KKL1MHxX3/9tRgxYoSIjY0VDodD9OvXTyxatOiMdX355ZcFAHHzzTdXOzZ37lyRkJAgHA6HyMjIEP/+978FAFFcXCyEOPNkAkmSxPTp04XH4xExMTEiKytL3HzzzRGTCXJzc0XPnj2FzWYT/fr1E6tXr67WNq+99ppISkoSRqNRjBgxQggROZlAiMrPzH333SfatGkjbDabGDp0qNiwYYN6vGoyQVXdhaicUAFA7Nu3r8a2efXVV0Xfvn2Fy+USHo9HXHbZZWLTpk3q8cLCQjFlyhTRunVrYbfbRZ8+fcR///tf9fjixYtFr169hMViER07dhTPPvtsxPU7deoknn/++Wqvu2HDBjF69GjhdruFy+US/fr1E08++WSNdeRkAmoIbH9tsf0bT10mExiEqONI9CaurKwM0dHRKC0thcfjiTgWCASwb98+dO7cGXa7XaMaak9RFJSVlcHj8cBoZO94Y2sK7d9cf1YkScKyZcswduzYJr8QdFPE9tcW27/xnC6LnEyffwWIiIiIiEGNiIiISK8Y1IiIiIh0ikGNiIiISKcY1GrQwuZXENUZf0aIiBoHg9oJqma5+Hw+jWtCpG9VPyOcGUZE1LC44O0JTCYTYmJicOzYMQCA0+ms9TZOzYmiKAiFQggEArpdHqI503P7CyHg8/lw7NgxxMTEnHa3AyIiOncMaieJj48HADWstURCCPj9fjgcjhYZVLXWFNo/JiZG/VkhIqKGw6B2EoPBgISEBLRr1w6SJGldHU1IkoSvvvoKw4cPZ9eWBvTe/haLhXfSiIgaCYPaKZhMphb7x8hkMiEcDsNut+syKDR3bH8iIqqiiwEwL730EpKTk2G325GWloYNGzac8twlS5Zg0KBBiImJgcvlwoABA/D22283Ym2JiIiIGofmQW3RokXIysrCrFmzsGnTJvTv3x8ZGRmnHCPWqlUr/N///R/WrVuHH3/8EVOmTMGUKVPw+eefN3LNiYiIiBqW5kFt7ty5mDp1KqZMmYJevXrh1VdfhdPpxIIFC2o8f+TIkbj66qvRs2dPpKSkYPr06ejXrx/WrFnTyDUnIiIialiajlELhULYuHEjZsyYoZYZjUaMGjUK69atO+PzhRBYtWoVdu7cib/+9a81nhMMBhEMBtXHpaWlAICioqIWO1ngTCRJgs/nQ2FhIcdIaYDtrx22vbbY/tpi+zee8vJyALVbPFzToFZQUABZlhEXFxdRHhcXhx07dpzyeaWlpUhMTEQwGITJZMLLL7+M0aNH13junDlzMHv27GrlnTt3PrfKExEREZ2D8vJyREdHn/acJjnrMyoqCps3b0ZFRQVWrlyJrKwsdOnSBSNHjqx27owZM5CVlaU+VhQFRUVFaN26tW7XqNJaWVkZkpKScOjQIXg8Hq2r0+Kw/bXDttcW219bbP/GI4RAeXk52rdvf8ZzNQ1qbdq0gclkwtGjRyPKjx49etrFNI1GI7p27QoAGDBgALZv3445c+bUGNRsNhtsNltEWUxMzDnXvSXweDz8YdUQ2187bHttsf21xfZvHGe6k1ZF08kEVqsVAwcOxMqVK9UyRVGwcuVKDB48uNbXURQlYhwaERERUXOgeddnVlYWJk+ejEGDBiE1NRXz5s2D1+vFlClTAAA333wzEhMTMWfOHACVY84GDRqElJQUBINBLFu2DG+//TZeeeUVLd8GERERUb3TPKhlZmbi+PHjmDlzJvLz8zFgwAAsX75cnWBw8ODBiI2pvV4v7rnnHvzyyy9wOBzo0aMH3nnnHWRmZmr1Fpodm82GWbNmVesypsbB9tcO215bbH9tsf31ySBqMzeUiIiIiBqd5gveEhEREVHNGNSIiIiIdIpBjYiIiEinGNSIiIiIdIpBrYV65ZVX0K9fP3Vhw8GDB+Ozzz5TjwcCAdx7771o3bo13G43rr322moLE1P9efrpp2EwGPDAAw+oZfweNJzHHnsMBoMh4qtHjx7qcbZ9w8rLy8Pvfvc7tG7dGg6HA3379sV3332nHhdCYObMmUhISIDD4cCoUaOwa9cuDWvcfCQnJ1f77BsMBtx7770A+NnXIwa1FqpDhw54+umnsXHjRnz33Xe49NJLMX78ePz0008AgAcffBCffPIJPvjgA3z55Zc4fPgwrrnmGo1r3Tx9++23+Mc//oF+/fpFlPN70LB69+6NI0eOqF9r1qxRj7HtG05xcTGGDh0Ki8WCzz77DNu2bcNzzz2H2NhY9ZxnnnkGf//73/Hqq69i/fr1cLlcyMjIQCAQ0LDmzcO3334b8bnPzc0FAFx//fUA+NnXJUH0q9jYWPH666+LkpISYbFYxAcffKAe2759uwAg1q1bp2ENm5/y8nLRrVs3kZubK0aMGCGmT58uhBD8HjSwWbNmif79+9d4jG3fsB5++GFx8cUXn/K4oigiPj5ePPvss2pZSUmJsNls4r333muMKrYo06dPFykpKUJRFH72dYp31AiyLCM7OxterxeDBw/Gxo0bIUkSRo0apZ7To0cPdOzYEevWrdOwps3PvffeiyuuuCKirQHwe9AIdu3ahfbt26NLly646aabcPDgQQBs+4b28ccfY9CgQbj++uvRrl07nH/++XjttdfU4/v27UN+fn5E+0dHRyMtLY3tX89CoRDeeecd3HrrrTAYDPzs6xSDWgu2ZcsWuN1u2Gw23HXXXfjoo4/Qq1cv5Ofnw2q1Vtu8Pi4uDvn5+dpUthnKzs7Gpk2b1O3RTsTvQcNKS0vDW2+9heXLl+OVV17Bvn37MGzYMJSXl7PtG9jevXvxyiuvoFu3bvj8889x99134/7778e//vUvAFDbuGp3mips//q3dOlSlJSU4JZbbgHA3zt6pfkWUqSd8847D5s3b0ZpaSkWL16MyZMn48svv9S6Wi3CoUOHMH36dOTm5sJut2tdnRbn8ssvV/+/X79+SEtLQ6dOnfD+++/D4XBoWLPmT1EUDBo0CE899RQA4Pzzz8fWrVvx6quvYvLkyRrXrmV54403cPnll6N9+/ZaV4VOg3fUWjCr1YquXbti4MCBmDNnDvr374/58+cjPj4eoVAIJSUlEecfPXoU8fHx2lS2mdm4cSOOHTuGCy64AGazGWazGV9++SX+/ve/w2w2Iy4ujt+DRhQTE4Pu3btj9+7d/Pw3sISEBPTq1SuirGfPnmrXc1UbnzzTkO1fvw4cOIAVK1bg9ttvV8v42dcnBjVSKYqCYDCIgQMHwmKxYOXKleqxnTt34uDBgxg8eLCGNWw+LrvsMmzZsgWbN29WvwYNGoSbbrpJ/X9+DxpPRUUF9uzZg4SEBH7+G9jQoUOxc+fOiLKff/4ZnTp1AgB07twZ8fHxEe1fVlaG9evXs/3r0Ztvvol27drhiiuuUMv42dcprWczkDYeeeQR8eWXX4p9+/aJH3/8UTzyyCPCYDCInJwcIYQQd911l+jYsaNYtWqV+O6778TgwYPF4MGDNa5183birE8h+D1oSH/4wx/E6tWrxb59+8Q333wjRo0aJdq0aSOOHTsmhGDbN6QNGzYIs9ksnnzySbFr1y6xcOFC4XQ6xTvvvKOe8/TTT4uYmBjxn//8R/z4449i/PjxonPnzsLv92tY8+ZDlmXRsWNH8fDDD1c7xs++/jCotVC33nqr6NSpk7BaraJt27bisssuU0OaEEL4/X5xzz33iNjYWOF0OsXVV18tjhw5omGNm7+Tgxq/Bw0nMzNTJCQkCKvVKhITE0VmZqbYvXu3epxt37A++eQT0adPH2Gz2USPHj3EP//5z4jjiqKIRx99VMTFxQmbzSYuu+wysXPnTo1q2/x8/vnnAkCNbcrPvv4YhBBC67t6RERERFQdx6gRERER6RSDGhEREZFOMagRERER6RSDGhEREZFOMagRERER6RSDGhEREZFOMagRERER6RSDGhEREZFOMagRke4kJydj3rx5tT5/9erVMBgM1TaTpkh1bVci0h6DGhGdNYPBcNqvxx577Kyu++233+KOO+6o9flDhgzBkSNHEB0dfVavR0SkV2atK0BETdeRI0fU/1+0aBFmzpyJnTt3qmVut1v9fyEEZFmG2XzmXztt27atUz2sVivi4+Pr9BwioqaAd9SI6KzFx8erX9HR0TAYDOrjHTt2ICoqCp999hkGDhwIm82GNWvWYM+ePRg/fjzi4uLgdrtx4YUXYsWKFRHXPbmLzmAw4PXXX8fVV18Np9OJbt264eOPP1aPn9z1+dZbbyEmJgaff/45ev7/9u4+pKn2jQP4d84CdZuGypTUIl9oRGJqkoUvmTATfLI3o0nLSpRibSTCJIsSyRcSe5kRgeFMVgkRWphkRubLqKblDDIxU9cfqaGWTu1Fdz9/PPwOLdPqecyfPM/1gcGuc+5zznWdf3Zx32ebRAKBQICYmBirxnJychJKpRJOTk5wdnaGWq3G3r17ER8fP2vNjY2NCAsLg52dHTw9PaFUKjE2NgYAuHLlCgQCATo7O7nxhw4dwsqVKzE+Pg4AKCsrQ3BwMIRCIdzc3CCTyTAwMDCtlrt372LNmjWws7NDVFQUBgYGUF1dDYlEApFIBJlMxp0TACIjI6FQKKBQKODo6AgXFxccP34cs/2d8/v375GcnAxXV1eIRCJERUXBaDRy+41GIzZu3AihUAiRSISgoCA0NzfPen8IIXOLGjVCyG+VkZGBvLw8tLe3w9/fH2azGbGxsbh//z6ePXuGmJgYxMXFwWQyzXqerKwsJCQkoK2tDbGxsUhMTMTQ0NCM48fHx1FQUICysjLU19fDZDIhPT2d25+fnw+dToeSkhI0NTVhZGQEFRUVs+bQ1dWFmJgYbN++HW1tbSgvL0djYyMUCgUAQC6Xc7lNTk6iqqoKxcXF0Ol0sLe3BwB8+fIF2dnZMBqNqKioQE9PD5KSkqZd6+TJkygqKoJer8ebN2+QkJCAs2fP4urVq6iqqkJNTQ00Go3VMaWlpbC1tcWTJ09w7tw5FBYWori4eMZ6du7cyTWALS0tCAwMxKZNm7j7mpiYCA8PDxgMBrS0tCAjIwOLFi2a9R4RQuYYI4SQOVBSUsIcHR25+MGDBwwAq6io+OGxq1atYhqNhouXLVvGzpw5w8UA2LFjx7jYbDYzAKy6utrqWsPDw1wuANirV6+4Yy5cuMDEYjEXi8Vidvr0aS6enJxkXl5ebMuWLTPmeeDAAZaSkmK1raGhgdnY2LCJiQnGGGNDQ0PMw8ODHTx4kInFYnbq1KlZazcYDAwAGx0dtaqltraWG5Obm8sAsK6uLm5bamoqk0qlXBwREcEkEgmzWCzcNrVazSQSCRd/fV8bGhqYSCRiHz9+tMrH29ubXbp0iTHGmFAoZFqtdtb8CSG/F82oEUJ+q+DgYKvYbDYjPT0dEokETk5OEAgEaG9v/+GMmr+/P/fewcEBIpHIasnwW/b29vD29uZid3d3bvyHDx/Q39+PkJAQbj+fz0dQUNCsORiNRmi1WggEAu4llUphsVjQ3d0NAFiyZAkuX76MixcvwtvbGxkZGVbnaGlpQVxcHLy8vCAUChEREQEA0+r/ul6xWAx7e3usWLHCatu39a9btw48Ho+LQ0ND0dnZiampqe/WYjab4ezsbFVPd3c3urq6AABpaWlITk5GdHQ08vLyuO2EkPlDXyYghPxWDg4OVnF6ejru3buHgoIC+Pj4wM7ODjt27MDnz59nPc+3S248Hg8Wi+WXxrNZntf6GWazGampqVAqldP2eXl5ce/r6+vB5/Px9u1bjI2NQSgUAgDGxsYglUohlUqh0+ng6uoKk8kEqVQ6rf6v8+fxeL9c/8/U4u7ujrq6umn7nJycAPy1/CqTyVBVVYXq6mqcOHEC169fx9atW//2dQkhv4YaNULIvGpqakJSUhL3YW82m9HT0zOvOTg6OkIsFsNgMCA8PBwAMDU1hadPnyIgIGDG4wIDA/HixQv4+PjMOEav1yM/Px+3b9+GWq2GQqFAaWkpAODly5cYHBxEXl4ePD09AWBOH85//PixVfzo0SP4+vqCz+d/t5a+vj7Y2tpi+fLlM57Tz88Pfn5+OHLkCHbv3o2SkhJq1AiZR7T0SQiZV76+vrh58yZaW1thNBohk8n+0czQ33X48GHk5uaisrISHR0dUKlUGB4etlo6/JZarYZer4dCoUBrays6OztRWVnJfZlgdHQUe/bsgVKpxObNm6HT6VBeXo4bN24A+GvWbfHixdBoNHj9+jVu3bqF7OzsOavJZDIhLS0NHR0duHbtGjQaDVQq1XfHRkdHIzQ0FPHx8aipqUFPTw/0ej0yMzPR3NyMiYkJKBQK1NXVobe3F01NTTAYDJBIJHOWLyHkx2hGjRAyrwoLC7F//36sX78eLi4uUKvVGBkZmfc81Go1+vr6IJfLwefzkZKSAqlU+t3Zp//x9/fHw4cPkZmZibCwMDDG4O3tjV27dgEAVCoVHBwckJOTAwBYvXo1cnJykJqaitDQUCxduhRarRZHjx7F+fPnERgYiIKCAvzxxx9zUpNcLsfExARCQkLA5/OhUqlm/OFgHo+HO3fuIDMzE/v27cO7d+/g5uaG8PBwiMVi8Pl8DA4OQi6Xo7+/Hy4uLti2bRuysrLmJFdCyM/hsX/60AYhhPwLWCwWSCQSJCQkzOks13yJjIxEQEAA/UUUIf8yNKNGCPlP6u3tRU1NDSIiIvDp0ycUFRWhu7sbMpns/50aIYRw6Bk1Qsh/ko2NDbRaLdauXYsNGzbg+fPnqK2tpWewCCELCi19EkIIIYQsUDSjRgghhBCyQFGjRgghhBCyQFGjRgghhBCyQFGjRgghhBCyQFGjRgghhBCyQFGjRgghhBCyQFGjRgghhBCyQFGjRgghhBCyQP0JNHJqzL/DeAQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "u_79CKvDLR_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the random grid\n",
        "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "# max_depth.append(None)\n",
        "\n",
        "parameters = {'n_estimators': np.arange(10, 400, 10),\n",
        "              'max_depth': [None, 5, 10, 15],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'max_features': [None, 'sqrt', 'log2'],\n",
        "              'min_samples_leaf': [1, 2, 4]}\n",
        "\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "clf = model_selection.RandomizedSearchCV(RandomForestClassifier(), parameters, cv=cv_10fold, n_iter=50, scoring='accuracy')\n",
        "    \n",
        "# Fit the classifier\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)\n"
      ],
      "metadata": {
        "id": "rpwtmKvoLTjD",
        "outputId": "c938b214-c388-4a88-d44f-7505d134397c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 15}\n",
            "0.6944444444444444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "_O8fWaFjCSl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {'C': loguniform(0.1, 100),\n",
        "              'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
        "              'degree': randint(1, 5),\n",
        "              'gamma': loguniform(1e-4, 1),\n",
        "              'class_weight':['balanced', None]}\n",
        " \n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "clf = model_selection.RandomizedSearchCV(SVC(), parameters, cv=cv_10fold, n_iter=500, scoring='accuracy')\n",
        "\n",
        "# Do the entire search\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "print(clf.best_score_)\n",
        "print(clf.best_params_)\n"
      ],
      "metadata": {
        "id": "5MwjArCFCZmH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43b5aa2-d848-482a-81a0-f2eee9458c41"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7222222222222222\n",
            "{'C': 44.561057573838696, 'class_weight': None, 'degree': 1, 'gamma': 0.00010537409989766666, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}