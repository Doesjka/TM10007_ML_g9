{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiDn2Sk-VWqE",
        "outputId": "77090737-163a-41ed-d641-028f85e7a203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TM10007_ML_g9'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (46/46), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 118 (delta 31), reused 17 (delta 17), pack-reused 72\u001b[K\n",
            "Receiving objects: 100% (118/118), 68.30 MiB | 21.89 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ],
      "source": [
        "# Run this to use from colab environment\n",
        "!git clone https://github.com/Doesjka/TM10007_ML_g9.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEUJUe8plrxC"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NE_fTbKGe5z",
        "outputId": "48b57ff4-da03-4809-e960-2de21622b2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of samples: 115\n",
            "The number of columns: 494\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn import model_selection\n",
        "from sklearn import decomposition\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.read_csv('/content/TM10007_ML_g9/worclipo/Lipo_radiomicFeatures.csv', index_col=0)\n",
        "print(f'The number of samples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting data in train and test set\n"
      ],
      "metadata": {
        "id": "LHslq_ZZZbW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = data['label']\n",
        "X = data.drop('label', axis=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "P8f1SNKeZaB7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling missing data \n",
        "### Throwing out features\n",
        "All features that exist of at least 50% zeros are deleted from the data. \n"
      ],
      "metadata": {
        "id": "gJLsBPlTZwAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = (X_train == 0).sum()\n",
        "threshold = 0.5 * len(y_train)\n",
        "print('Threshold = ', threshold)\n",
        "feature_del = zeros[zeros > threshold]\n",
        "\n",
        "X_train = X_train.drop(columns=feature_del.index)\n",
        "print(f'{len(data.columns)-len(X_train.columns)} features were deleted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWcI7Y3g7eDk",
        "outputId": "3b7aefa0-6215-4880-8390-bde8e35eccdf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  43.0\n",
            "25 features were deleted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "more_zeros = (X_train == 0).sum()\n",
        "columns_zeros = more_zeros[more_zeros > 0].index\n",
        "print(f'Of the remaining features, {len(columns_zeros)} features have at least one zero')\n",
        "print(f'There is a total of {more_zeros.sum()} zeros left in the data')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iuoOrHuMAsFY",
        "outputId": "76bede09-84c0-4c65-9024-4ecc186e72a9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Of the remaining features, 10 features have at least one zero\n",
            "There is a total of 44 zeros left in the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate number of missing values per sample"
      ],
      "metadata": {
        "id": "pkM1c0vkq1YB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_r = (X_train == 0).sum(axis=1)\n",
        "threshold = 0.005 * X_train.size / len(y_train)\n",
        "print('Threshold = ', threshold)\n",
        "feature_del = zeros_r[zeros_r > threshold]\n",
        "print(feature_del)"
      ],
      "metadata": {
        "id": "4gHFgkGMm3Nm",
        "outputId": "19c6e3d3-a62d-440b-8267-38c541765298",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold =  2.345\n",
            "ID\n",
            "Lipo-090_0    5\n",
            "Lipo-095_0    3\n",
            "Lipo-076_0    3\n",
            "Lipo-003_0    3\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import shapiro\n",
        "\n",
        "aantal_normaal = 0\n",
        "\n",
        "for column in X_train.columns:\n",
        "    result = shapiro(X_train[column])\n",
        "    # print(result.pvalue)\n",
        "    normaal = result.pvalue > 0.05\n",
        "    aantal_normaal += normaal\n",
        "    \n",
        "print(aantal_normaal)\n",
        "\n"
      ],
      "metadata": {
        "id": "XKxZ6YRnm3Xr",
        "outputId": "52818ba4-022f-443f-fd9b-7b3866f544de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/scipy/stats/_morestats.py:1813: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
            "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filling remaining zeros\n",
        "All remaining zeros are replaced by the mean of that feature. "
      ],
      "metadata": {
        "id": "KwXkbuDYqhoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_mean = X_train\n",
        "X_train_median = X_train\n",
        "\n",
        "for column in columns_zeros[:]:\n",
        "    print('Kolom: ', column)\n",
        "    column_mean = X_train.loc[X_train[column]!=0, column].mean()\n",
        "    column_median = X_train.loc[X_train[column]!=0, column].median()\n",
        "    print('mean = ', column_mean)\n",
        "    print('median = ', column_median)\n",
        "\n",
        "    verschil2_percolumn = column_mean - column_median\n",
        "    print('Verschil tussen mean en median = ',verschil2_percolumn)\n",
        "\n",
        "    # result = shapiro(X_train[column])\n",
        "    # result.pvalue\n",
        "    print('p-waarde normaalverdeling = ', shapiro(X_train.loc[X_train[column]!=0, column]).pvalue)\n",
        "\n",
        "    X_train_mean[column].replace(0, column_mean)\n",
        "    X_train_median[column].replace(0, column_median)\n",
        "\n",
        "    print(' ')\n",
        "\n",
        "verschil = abs(X_train_mean - X_train_median)\n",
        "print('Totaal verschil = ', verschil.sum().sum())\n",
        "\n",
        "# X_train.head()\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# print(X_train[columns_zeros[0]])\n",
        "# pd.set_option('display.max_rows', 10)\n"
      ],
      "metadata": {
        "id": "EQudKLJth0sz",
        "outputId": "0716802d-fab3-4de5-8780-943b5b9f36ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kolom:  PREDICT_original_sf_area_min_2.5D\n",
            "mean =  456.8698899846219\n",
            "median =  200.39520811289555\n",
            "Verschil tussen mean en median =  256.4746818717264\n",
            "p-waarde normaalverdeling =  3.05788068477586e-11\n",
            " \n",
            "Kolom:  PREDICT_original_tf_LBP_quartile_range_R8_P24\n",
            "mean =  9.301204819277109\n",
            "median =  11.0\n",
            "Verschil tussen mean en median =  -1.6987951807228914\n",
            "p-waarde normaalverdeling =  1.931198130478151e-05\n",
            " \n",
            "Kolom:  PREDICT_original_vf_Frangi_full_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "mean =  2.766293780856362e-07\n",
            "median =  4.602205232532876e-10\n",
            "Verschil tussen mean en median =  2.7616915756238295e-07\n",
            "p-waarde normaalverdeling =  9.707482768662333e-20\n",
            " \n",
            "Kolom:  PREDICT_original_vf_Frangi_edge_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "mean =  2.766293780856362e-07\n",
            "median =  4.602205232532876e-10\n",
            "Verschil tussen mean en median =  2.7616915756238295e-07\n",
            "p-waarde normaalverdeling =  9.707482768662333e-20\n",
            " \n",
            "Kolom:  PREDICT_original_vf_Frangi_inner_quartile_range_SR(1.0, 10.0)_SS2.0\n",
            "mean =  8.705055316112096e-08\n",
            "median =  3.671477515859718e-10\n",
            "Verschil tussen mean en median =  8.668340540953499e-08\n",
            "p-waarde normaalverdeling =  1.273425812214633e-19\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_monogenic_min_WL3_N5\n",
            "mean =  3.8185714285714285\n",
            "median =  3.0\n",
            "Verschil tussen mean en median =  0.8185714285714285\n",
            "p-waarde normaalverdeling =  4.080578648417432e-13\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_monogenic_peak_WL3_N5\n",
            "mean =  89.4116049382716\n",
            "median =  89.5\n",
            "Verschil tussen mean en median =  -0.08839506172840572\n",
            "p-waarde normaalverdeling =  0.0007248687325045466\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_monogenic_peak_position_WL3_N5\n",
            "mean =  24.97530864197531\n",
            "median =  25.0\n",
            "Verschil tussen mean en median =  -0.02469135802468969\n",
            "p-waarde normaalverdeling =  0.0007248687325045466\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_phasecong_quartile_range_WL3_N5\n",
            "mean =  0.029046637777023623\n",
            "median =  0.0166127963783\n",
            "Verschil tussen mean en median =  0.012433841398723621\n",
            "p-waarde normaalverdeling =  1.7549460148980067e-12\n",
            " \n",
            "Kolom:  PREDICT_original_phasef_phasesym_quartile_range_WL3_N5\n",
            "mean =  0.20900926663690383\n",
            "median =  0.21420864221841113\n",
            "Verschil tussen mean en median =  -0.005199375581507293\n",
            "p-waarde normaalverdeling =  0.5642579197883606\n",
            " \n",
            "Totaal verschil =  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling"
      ],
      "metadata": {
        "id": "YQtVjjF2dX77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = preprocessing.StandardScaler().fit(X_train_median)\n",
        "X_train_scaled = scaler.transform(X_train_median)\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_median.columns)\n",
        "\n",
        "# scaler = preprocessing.RobustScaler().fit(X_train_median)\n",
        "# X_train_scaled = scaler.transform(X_train_median)\n",
        "# X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_median.columns)\n",
        "\n",
        "# scaler = preprocessing.MinMaxScaler().fit(X_train_median)\n",
        "# X_train_scaled = scaler.transform(X_train_median)\n",
        "# X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_median.columns)"
      ],
      "metadata": {
        "id": "iXgA9qGcc2eH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "#pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_rows', 10)\n",
        "\n",
        "# stats.zscore(X_train)    # Dit is voor een array \n",
        "Z_score = X_train.apply(stats.zscore)    # Dit is voor een pandas dataframe \n",
        "\n",
        "num_outliers = (np.abs(Z_score) > 3).sum()\n",
        "outliers = num_outliers.sum()\n",
        "numb_columns_outliers = (num_outliers > 0).sum()\n",
        "\n",
        "print(num_outliers)\n",
        "print(numb_columns_outliers)\n",
        "print(outliers)"
      ],
      "metadata": {
        "id": "Spiz0wX0oCHE",
        "outputId": "1ee4f13e-7bdb-4aa7-f215-777f7270c27d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PREDICT_original_sf_compactness_avg_2.5D                  0\n",
            "PREDICT_original_sf_compactness_std_2.5D                  0\n",
            "PREDICT_original_sf_rad_dist_avg_2.5D                     0\n",
            "PREDICT_original_sf_rad_dist_std_2.5D                     1\n",
            "PREDICT_original_sf_roughness_avg_2.5D                    2\n",
            "                                                         ..\n",
            "PREDICT_original_phasef_phasesym_kurtosis_WL3_N5          1\n",
            "PREDICT_original_phasef_phasesym_range_WL3_N5             0\n",
            "PREDICT_original_phasef_phasesym_energy_WL3_N5            3\n",
            "PREDICT_original_phasef_phasesym_quartile_range_WL3_N5    0\n",
            "PREDICT_original_phasef_phasesym_entropy_WL3_N5           0\n",
            "Length: 469, dtype: int64\n",
            "333\n",
            "601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "xOOLNJnlfLbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pca = decomposition.PCA()\n",
        "pca.fit(X_train_scaled_df)\n",
        "X_pca = pca.transform(X_train_scaled_df)\n",
        "\n",
        "component=0\n",
        "total_ratio = 0\n",
        "while total_ratio < 0.9:\n",
        "    total_ratio += pca.explained_variance_ratio_[component]\n",
        "    component+=1\n",
        "\n",
        "X_pca = X_pca[:,0:component]"
      ],
      "metadata": {
        "id": "dU9UMzbtfNTE",
        "outputId": "6094c929-a799-45af-87c6-d125b8f52385",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## k-NN"
      ],
      "metadata": {
        "id": "xdjw0bA9zOle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import neighbors\n",
        "# Specify the search range, this could be multiple parameters for more complex classifiers\n",
        "parameters = {'n_neighbors': randint(1, 50),\n",
        "              'weights': ['uniform', 'distance'],\n",
        "              'p': randint(1, 5),\n",
        "              'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
        "\n",
        "# Specify the cross validation method to use, we use 10-fold stratified cross-validation\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "# Create the grid search method, use area under ROC curve as scoring metric\n",
        "# Too learn more about metrics see: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "clf = model_selection.RandomizedSearchCV(neighbors.KNeighborsClassifier(), parameters, cv=cv_10fold, n_iter=500, scoring='accuracy')\n",
        "\n",
        "# Do the entire search\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "\n",
        "# Extract the best k \n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "optimal_k = clf_df['param_n_neighbors'].iloc[0]\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)\n",
        "\n"
      ],
      "metadata": {
        "id": "F2Mc-n3yzRIP",
        "outputId": "a4e7fc3a-2079-40de-b1f5-2fa1f2260e40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'algorithm': 'ball_tree', 'n_neighbors': 31, 'p': 1, 'weights': 'distance'}\n",
            "0.6611111111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "u_79CKvDLR_p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import randint\n",
        "from sklearn import model_selection\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Create the random grid\n",
        "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "# max_depth.append(None)\n",
        "\n",
        "parameters = {'n_estimators': np.arange(10, 400, 10),\n",
        "              'max_depth': [None, 5, 10, 15],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'max_features': [None, 'sqrt', 'log2'],\n",
        "              'min_samples_leaf': [1, 2, 4]}\n",
        "\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "clf = model_selection.RandomizedSearchCV(RandomForestClassifier(), parameters, cv=cv_10fold, n_iter=50, scoring='accuracy')\n",
        "    \n",
        "# Fit the classifier\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)\n"
      ],
      "metadata": {
        "id": "rpwtmKvoLTjD",
        "outputId": "05936c4e-5969-48fb-ebb0-022edc9eaca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 340, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None}\n",
            "0.6583333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "_O8fWaFjCSl-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy \n",
        "from sklearn.svm import SVC\n",
        "from sklearn import model_selection\n",
        "from sklearn.utils.fixes import loguniform\n",
        "\n",
        "# parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
        "#              {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}]\n",
        "\n",
        "parameters = {'C': loguniform(0.1, 100),\n",
        "              'kernel': ['rbf', 'linear', 'poly', 'sigmoid'],\n",
        "              'degree': randint(1, 5),\n",
        "              'gamma': loguniform(1e-4, 1),\n",
        "              'class_weight':['balanced', None]}\n",
        " \n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "\n",
        "clf = model_selection.RandomizedSearchCV(SVC(), parameters, cv=cv_10fold, n_iter=500, scoring='accuracy')\n",
        "\n",
        "# Do the entire search\n",
        "clf.fit(X_pca, y_train)\n",
        "\n",
        "# Show the complete results of the cross validation\n",
        "clf_df = pd.DataFrame(clf.cv_results_)\n",
        "clf_df = clf_df.sort_values(by=['rank_test_score'])\n",
        "\n",
        "# Extract the best hyperparameters \n",
        "print(clf.best_score_)\n",
        "print(clf.best_params_)"
      ],
      "metadata": {
        "id": "5MwjArCFCZmH",
        "outputId": "fa048da4-3baa-4ea5-a5a5-e8bb909a9213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7694444444444445\n",
            "{'C': 3.4392592585305524, 'class_weight': 'balanced', 'degree': 1, 'gamma': 0.01143799983523973, 'kernel': 'poly'}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}